{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final 5-Year Data Assembly Script\n",
    "\n",
    "This master script orchestrates the full pipeline across all five years, producing the final consolidated dataset. As it loops through each calendar year, you’ll see:\n",
    "\n",
    "- **Annual GDP Trends & LOESS Decompositions**  \n",
    "  We update the GDP growth inputs and rerun the LOESS smoothing for each year, exactly as described in Script 1. This ensures that seasonal patterns and economic trajectories remain tailored to that year’s specific context.\n",
    "\n",
    "- **Satellite Imagery Integration & KNN Imputation**  \n",
    "  After generating the core variables, the script imports the Sentinel-2 land-cover metrics and applies a K-Nearest Neighbors algorithm to fill any remaining missing values. This two-step process merges remote-sensing data with spatial statistics to achieve a complete, high-resolution picture.\n",
    "\n",
    "> **Performance Note:**  \n",
    "> Because this script loads multi-year Sentinel-2 collections and executes memory-intensive KNN operations, it can easily consume tens of gigabytes of RAM when run end-to-end. To improve stability and speed:\n",
    "> 1. **Process by Year:** Break the script into individual year modules and run them sequentially.  \n",
    "> 2. **Use Cloud or Parallel Compute:** Leverage Google Earth Engine batch exports or parallel Python workers to distribute the load.  \n",
    "> 3. **Chunk & Cache Data:** Cache intermediate results (e.g., annual LOESS outputs, satellite masks) to disk or cloud storage to avoid repeated recalculations.  \n",
    "\n",
    "By following these best practices, you’ll maintain reproducibility while keeping resource usage within practical limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import numpy as np\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from geopy.distance import geodesic\n",
    "from pykrige.kriging_tools import write_asc_grid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Decoradores utiles\n",
    "\n",
    "def decorador_2(func):\n",
    "    def wrapped(*args):\n",
    "        time1 = time.time()\n",
    "        rta = func(*args)\n",
    "        time2 = time.time()\n",
    "        print('La funcion demoro' , time2-time1)\n",
    "        return rta \n",
    "    return wrapped \n",
    "\n",
    "\n",
    "# Funciones que vamos a utilizar en todo el script \n",
    "\n",
    "def eliminar_tildes(str):\n",
    "    return ''.join(\n",
    "        i for i in unicodedata.normalize('NFKD', str)\n",
    "        if unicodedata.category(i) != 'Mn')\n",
    "\n",
    "meses = {\n",
    "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\", \n",
    "    5: \"May\", 6: \"June\", 7: \"July\", 8: \"August\", \n",
    "    9: \"September\", 10: \"October\", 11: \"November\", 12: \"December\"\n",
    "}\n",
    "\n",
    "meses_esp = {\n",
    "    \"Enero\": \"January\", \"Febrero\": \"February\", \"Marzo\": \"March\", \"Abril\": \"April\", \n",
    "    \"Mayo\": \"May\", \"Junio\": \"June\", \"Julio\": \"July\", \"Agosto\": \"August\", \n",
    "    \"Septiembre\": \"September\", \"Octubre\": \"October\", \"Noviembre\": \"November\", \"Diciembre\": \"December\"\n",
    "}\n",
    "\n",
    "@decorador_2\n",
    "def arreglar_texto(df , variable , nombre):\n",
    "    if variable not in df.columns:\n",
    "        print('La columna' , variable ,'no existe en el DataFrame')\n",
    "        return df\n",
    "        \n",
    "    df[variable] = df[variable].str.lower()\n",
    "    df[variable] = df[variable].str.replace(' ', '', regex=False)\n",
    "    df[variable] = df[variable].str.replace(r'[^\\w\\s]', '', regex=True)   \n",
    "    df[variable] = df[variable].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "    df[variable] = df[variable].str.replace('ct$', '', regex=True)\n",
    "    df[variable] = df[variable].str.replace('bogotadc', 'bogota', regex=False)\n",
    "    df[variable] = df[variable].apply(eliminar_tildes)\n",
    "    df = df.rename(columns={variable: nombre})\n",
    "    return df\n",
    "\n",
    "@decorador_2\n",
    "def completar_meses(df , escala , mes , observaciones , operacion=0 ):\n",
    "    if operacion ==0:\n",
    "        #Hacer un groupby sacando la mediana de las observaciones por mes\n",
    "        df = df.groupby([escala, mes])[observaciones].median().reset_index()\n",
    "        municipios = df[escala].unique()\n",
    "        meses1 = range(1, 13)\n",
    "        df_combinaciones = pd.MultiIndex.from_product([municipios, meses1], names=[escala, mes]).to_frame(index=False)\n",
    "        df_combinaciones[mes] = df_combinaciones[mes].map(meses)\n",
    "        Final= pd.merge(df_combinaciones, df, on=[escala, mes], how='left')\n",
    "        return Final\n",
    "    else:\n",
    "        #Hacer un groupby sumando las observaciones por mes\n",
    "        conteo = df.groupby([escala, mes])[observaciones].sum().reset_index()\n",
    "        municipios = df[escala].unique()\n",
    "        meses1 = range(1, 13)\n",
    "        df_combinaciones = pd.MultiIndex.from_product([municipios, meses1], names=[escala, mes ]).to_frame(index=False)\n",
    "        df_completo = pd.merge(df_combinaciones, conteo, on=[escala, mes], how='left')\n",
    "        df_completo[observaciones] = df_completo[observaciones].fillna(0)\n",
    "        df_completo[mes] = df_completo[mes].map(meses)\n",
    "        return df_completo \n",
    "    \n",
    "\n",
    "def meses_a_numeros(df , mes):\n",
    "    meses_invertido = {i: k for k, i in meses.items()}\n",
    "    df[mes] = df[mes].map(meses_invertido)\n",
    "    return df\n",
    "\n",
    "def traducir(df , mes ):\n",
    "    df[mes] = df[mes].map(meses_esp)\n",
    "    return df\n",
    "\n",
    "@decorador_2\n",
    "def bases_crimenes(df , dia , cantidad , nombre):\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:].reset_index(drop=True)\n",
    "    df[dia] = pd.to_datetime(df[dia])\n",
    "    df['Mes'] = df[dia].dt.month_name()\n",
    "    df = arreglar_texto(df , 'MUNICIPIO', 'Ciudad')\n",
    "    df1= df.groupby(['Ciudad' , 'Mes'])[cantidad].sum().reset_index()\n",
    "    df1 = df1.rename(columns={cantidad: nombre})\n",
    "    return df1\n",
    "    \n",
    "def convertir_ubicacion(df , variable):\n",
    "    df['ubicacion'] = df[variable].str.strip('()')\n",
    "    df[['latitud', 'longitud']] = df['ubicacion'].str.split(',', expand=True)\n",
    "    df['latitud'] = df['latitud'].astype(float)\n",
    "    df['longitud'] = df['longitud'].astype(float)\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitud'], row['latitud']), axis=1)\n",
    "    df = df.drop([variable , 'ubicacion' , 'latitud' , 'longitud'] , axis=1)\n",
    "    return df\n",
    "\n",
    "Top_Colombia = {'Ciudad Amurallada' : [(10.423768016601226, -75.5502221481417) , 23267+1851 , 4.8] , \n",
    "                'Monserrate':[(4.606442657411985, -74.05488182882448) , 16061+10034 , 4.7],    \n",
    "                'Museo Oro': [(4.601863737486862, -74.07206921955388) , 14606+43837 , 4.8], \n",
    "                'Museo Pablo Escobar':[(6.210940942225721, -75.55666610034157) , 4041+2460 , 3.8],\n",
    "                'Castillo San Felipe': [(10.422674818711775, -75.53911007123797) , 13188+61752 , 4.7],\n",
    "                'La Candelaria': [(4.596356204217971, -74.07036887708271), 4790+35201 , 4.6 ],\n",
    "                'Museo Botero': [(4.596783977356232, -74.07317983196756) , 10511+21480 , 4.8],\n",
    "                'Piedra Penol': [(6.224293398570674, -75.17846180492857) , 2537+3722 , 4.7],\n",
    "                'Parque Tayrona':[(11.30661973931487, -74.06558444232788) , 6407+24124 , 4.7],\n",
    "                'Ciudad Perdida': [(10.69977509707966, -74.21719016507225) , 2129+10293 , 4.5],\n",
    "                'Johnny Cay': [(12.599844555163797, -81.68958552452854) , 6944+1193, 4.6 ],\n",
    "                'Mina sal': [(5.064130673191533, -73.87412723129202) , 4946+10681 , 4.8],\n",
    "                'Parque Explora': [(6.271873980048277, -75.56529352888349), 3290+6868 , 4.8],\n",
    "                'Parque del cafe': [(4.540472412992844, -75.7704120656708) , 2260+64813 , 4.8],\n",
    "                'Getsemani': [(10.420236347859726, -75.5457920284369) , 827+9890 , 4.7],\n",
    "                'Laguna Guatavita': [(4.978042131016031, -73.77411934630805) , 1641+760 , 4.6],\n",
    "                'Laguna Guatape': [(6.2625426509484585, -75.18889681059652) , 1667+1920 , 4.9],\n",
    "                'Zoo Cali': [(3.4483110753559307, -76.5567835595829) , 2505+30375 , 4.7],\n",
    "                'Jaime Duque':[(4.950933448804722, -73.96450197491808) , 608+5558 , 4.8],\n",
    "                'Museo Antioquia':[(6.252582668979805, -75.56902381539014) , 2037+8372 , 4.7],\n",
    "                'Bosque Palmas': [(4.642619785055463, -75.48545072059876) , 1999+6026 , 4.8],\n",
    "                'santuario san pedro claver' : [(10.421942528179812, -75.55101547480216) , 2344+2868 , 4.7],\n",
    "                'Santuario Las Lajas': [(0.8056145166329276, -77.58580465582233) , 868+10768 , 4.8],\n",
    "                'Medellin MetroCable': [(6.293713286896887, -75.54049102937564) , 2505+6768 , 4.7],\n",
    "                'Villa de leyva': [(5.636740186520528, -73.52642769258925) , 10523+2931 , 4.8],\n",
    "                'Salento': [(4.637632624472757, -75.57107751600738) , 935+1391 , 4,7 ],\n",
    "                'Islas Rosario': [(10.198113718483176, -75.75728109040843) , 1293+235 , 4.5],\n",
    "                'Cano cristales' : [(2.2654672947309984, -73.7904893534562) , 442+303 , 4.9],\n",
    "                'Cabo de la vela': [(12.19584280316732, -72.14670358044717) , 503 , 4.7],\n",
    "                'Parque Nacional Natural El Cocuy' :[(6.366594015120004, -72.32930605910018) , 1468,4.8],\n",
    "                'Jardin': [(5.599970208507919, -75.82197889439527) , 1923 , 4.7],\n",
    "                'Canon guejar': [(3.34558725490291, -74.00251320801074) , 223 , 5],\n",
    "                'Chingaza': [(4.736759401563025, -73.84183421964912) , 312+532 , 4.9],\n",
    "                'Selva Amazonas': [(-1.9373373758415269, -70.09301207031643) , 88 , 4.5],\n",
    "                'Rio miel': [(5.77684008762934, -74.68539501381262) , 42+33 , 4.2],\n",
    "                'Cerros de Mavecure': [(3.8685506255477473, -67.90980077915421) , 47+122 , 4.7],\n",
    "                'Desiero Tatacoa': [(3.233661252748834, -75.167678435162) , 844+2805 , 4.8],\n",
    "                'Parque Uramba': [(4.009359201162415, -77.24025001985369) , 51+2034 , 4.7],\n",
    "                'Naqui': [(5.711911987713407, -77.26317845045835) , 1239 , 4.6],\n",
    "                'San Jose Guaviare':[(2.5680632175041964, -72.6400738137754) , 4312 , 4.8],\n",
    "                'Cascada Fin del Mundo':[(1.1049043406387264, -76.61366052942371) , 138 , 4.8],\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import heavy databases first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alejo\\AppData\\Local\\Temp\\ipykernel_30804\\1820426153.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clima = pd.read_csv(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Datos_Hidrometeorol_gicos_Crudos_-_Red_de_Estaciones_IDEAM___Temperatura_20241001.csv\")\n"
     ]
    }
   ],
   "source": [
    "clima = pd.read_csv(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Datos_Hidrometeorol_gicos_Crudos_-_Red_de_Estaciones_IDEAM___Temperatura_20241001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alejo\\AppData\\Local\\Temp\\ipykernel_30804\\429284614.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  clima['FechaObservacion'] = pd.to_datetime(clima['FechaObservacion'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clima['FechaObservacion'] = pd.to_datetime(clima['FechaObservacion'])\n",
    "clima['Mes'] = clima['FechaObservacion'].dt.month_name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicio proceso\n",
    "df= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Visitantes_No_Residentes.csv')\n",
    "df1 = df[df[\"Año\"] == 2018]\n",
    "df1= arreglar_texto(df1 , 'Ciudad' , 'Ciudad')\n",
    "Homicidios= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\homicidios_2018_1.xlsx').dropna()\n",
    "Homicidos1 = bases_crimenes(Homicidios , 'FECHA HECHO' , 'CANTIDAD' , 'Homicidios')\n",
    "Hurto= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\hurto_a_personas_2018_1.xlsx').dropna()\n",
    "Hurto1 = bases_crimenes(Hurto , 'FECHA HECHO' , 'CANTIDAD' , 'Hurtos')\n",
    "sexuales= sexuales= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\delitos_sexuales_2018_0.xlsx').dropna()\n",
    "sexuales1 = bases_crimenes(sexuales , 'FECHA HECHO' , 'CANTIDAD' , 'Delitos Sexuales')\n",
    "ciudades= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\ciudades.csv')\n",
    "ciudades = arreglar_texto(ciudades, 'city' , \"Ciudad\")\n",
    "ciudades['admin_name'] = ciudades['admin_name'].astype(str)\n",
    "ciudades.at[68, 'admin_name'] = 'Atlantico'\n",
    "Total_18= completar_meses(df1 , 'Ciudad' , 'Mes' ,'Extranjeros no Residentes' , 1)\n",
    "Total_18 = pd.merge(Total_18, Homicidos1[['Ciudad', 'Homicidios' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, Hurto1[['Ciudad', 'Hurtos' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, sexuales1[['Ciudad', 'Delitos Sexuales' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18['Homicidios'] = Total_18['Homicidios'].fillna(0)\n",
    "Total_18['Hurtos'] = Total_18['Hurtos'].fillna(0)\n",
    "Total_18['Delitos Sexuales'] = Total_18['Delitos Sexuales'].fillna(0)\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('bogotadc', 'bogota', regex=False)\n",
    "\n",
    "#Seleccionar Ciudades que vamos a trabajar\n",
    "ciudades1= set(ciudades['Ciudad'])\n",
    "ciudades2= set(Total_18['Ciudad'])\n",
    "grandes_ciudades=list(ciudades1.intersection(ciudades2))\n",
    "l=['bogota' , 'tumaco']\n",
    "grandes_ciudades = grandes_ciudades + l\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "\n",
    "for i in Total_18['Ciudad']:\n",
    "    indice = Total_18[Total_18['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Total_18 = Total_18.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Poner Ubicaciones\n",
    "ciudades['geometry'] = ciudades.apply(lambda i: Point(i['lng'], i['lat']), axis=1)\n",
    "ciudades_geometry= gpd.GeoDataFrame(ciudades, geometry='geometry')\n",
    "Total_18_Geometry= pd.merge(Total_18, ciudades_geometry[['Ciudad', 'geometry']], on='Ciudad' , how='left')\n",
    "Total_18_Geometry= gpd.GeoDataFrame(Total_18_Geometry, geometry='geometry')\n",
    "\n",
    "# Poner departamentos\n",
    "Departamentos = gpd.read_file(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Colombia.json\")\n",
    "Departamentos = arreglar_texto(Departamentos, 'NOMBRE_DPT' , \"Departamento\")\n",
    "Departamentos[\"Departamento\"] = Departamentos[\"Departamento\"].str.replace('santafedebogota', 'bogotadc', regex=False)\n",
    "\n",
    "if Total_18_Geometry.crs is None:\n",
    "    Total_18_Geometry = Total_18_Geometry.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Total_18_Geometry = gpd.sjoin_nearest(Total_18_Geometry,  Departamentos, how='left', distance_col='distancia').drop(['AREA' , 'PERIMETER' , 'HECTARES' , 'DPTO','index_right' , 'distancia'] , axis=1)\n",
    "Total_18_Geometry\n",
    "Total_18_Geometry[Total_18_Geometry.isnull().any(axis=1)]\n",
    "\n",
    "#Agregar Clima\n",
    "clima_2018 = clima[clima['FechaObservacion'].dt.year == 2018]\n",
    "clima_2018 = arreglar_texto(clima_2018 , 'Municipio', 'Ciudad')\n",
    "clima_2018= completar_meses(clima_2018 , 'Ciudad' , 'Mes' ,'ValorObservado' , 0)\n",
    "Total_18_Clima= pd.merge(Total_18_Geometry, clima_2018[['Ciudad', 'ValorObservado' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18_Clima = Total_18_Clima.rename(columns={'ValorObservado': 'Temperatura'})\n",
    "\n",
    "#Krigging para el clima \n",
    "df_kriging = meses_a_numeros(Total_18_Clima , 'Mes')\n",
    "df_kriging.set_crs(epsg=4326, inplace=True)\n",
    "df_kriging=df_kriging.to_crs(epsg=32618)  \n",
    "\n",
    "meses_krig = df_kriging['Mes'].unique()\n",
    "\n",
    "for i in meses_krig:\n",
    "    print('Procesando Mes:' ,i)\n",
    "    \n",
    "    df_kriging_mes = df_kriging[df_kriging['Mes'] == i] # Vamos a realizar el kriging por mes\n",
    "    df_kriging_known = df_kriging_mes.dropna(subset=['Temperatura']) # Los datos para los que tenemos temperatura\n",
    "    df_kriging_missing = df_kriging_mes[df_kriging_mes ['Temperatura'].isna()] # Los datos para los NO que tenemos temperatura (Variable a predecir)\n",
    "    \n",
    "    if df_kriging_missing.empty:\n",
    "        print('No hay datos faltantes en el mes ' , i) # Si algun mes esta completo para todas las ciudades, no hacer nada \n",
    "        continue\n",
    "    \n",
    "    # Nuestras variables para predecir\n",
    "    x_known = df_kriging_known.geometry.x.values\n",
    "    y_known = df_kriging_known.geometry.y.values\n",
    "    z_known = df_kriging_known['Temperatura'].values\n",
    "    \n",
    "    # Nuestros datos a predecir\n",
    "    x_missing = df_kriging_missing.geometry.x.values\n",
    "    y_missing = df_kriging_missing.geometry.y.values\n",
    "    \n",
    "    # Crear el modelo \n",
    "    Krigg = OrdinaryKriging(\n",
    "        x_known, y_known, z_known,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False)\n",
    "    \n",
    "    # Realizar predicciones con el krigging\n",
    "    z_pred, ss = Krigg.execute('points', x_missing, y_missing)\n",
    "    \n",
    "    # Introducir en el DF los valores\n",
    "    df_kriging.loc[df_kriging_missing.index, 'Temperatura'] = z_pred\n",
    "\n",
    "#Agregar precio dolar\n",
    "Dolar = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Dolar.xlsx')\n",
    "Dolar['Fecha'] = pd.to_datetime(Dolar['Fecha'], errors='coerce')\n",
    "Dolar.set_index('Fecha', inplace=True)\n",
    "Dolar = Dolar.resample('M').median()\n",
    "Dolar = Dolar.reset_index()\n",
    "Dolar_2018=Dolar[Dolar['Fecha'].dt.year == 2018]\n",
    "Dolar_2018['Mes'] = range(1, 13)\n",
    "Base_2018=pd.merge(df_kriging, Dolar_2018, on= 'Mes', how='right').drop('Fecha' , axis=1)\n",
    "Base_2018\n",
    "\n",
    "#Interpolar PIB mensual\n",
    "\n",
    "PIB= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\PIB - Miles de millones de pesos  - 2018.xlsx')\n",
    "PIB= arreglar_texto(PIB, 'DEPARTAMENTO' , 'Departamento')\n",
    "PIB['VALOR (unidades)'] = PIB['VALOR (unidades)'].str.replace(',', '.')\n",
    "PIB['VALOR (unidades)'] = pd.to_numeric(PIB['VALOR (unidades)'], errors='coerce')\n",
    "\n",
    "# Usaremos el metodo de LOESS para descomponer el PIB mensualmente \n",
    "meses_loees= np.arange(1, 13)\n",
    "tendencia_mensual_inflacion = [3.68 ,3.37, 3.14 , 3.13 , 3.16 , 3.20 , 3.12 , 3.10 , 3.23 , 3.33 , 3.27 , 3.18] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual_inflacion) for valor in tendencia_mensual_inflacion]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "# La idea es crear algun tipo de ruido sobre nuestro patron, para asi tratar de simular efectos reales economicos.\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) #  Asegurarnos que todos las fulctuaciones sean positivas. \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "\n",
    "def descomponer_pib_loess(pib_anual, patron):\n",
    "    def asignar_pib_mensual(k, patron):\n",
    "        pib_mensual = patron * k['VALOR (unidades)']\n",
    "        return pib_mensual\n",
    "\n",
    "    df_mensual = pd.DataFrame()\n",
    "    \n",
    "    for i, k in pib_anual.iterrows():\n",
    "        pib_mensual = asignar_pib_mensual(k, patron)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Departamento': k['Departamento'],\n",
    "            'Mes': np.arange(1, 13),\n",
    "            'PIB_Mensual': pib_mensual\n",
    "        })\n",
    "        \n",
    "        df_mensual = pd.concat([df_mensual, df_temp], ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "pib_mensual = descomponer_pib_loess(PIB, patron_smooth)\n",
    "importancia_pesos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\importancia-municipal.xlsx')\n",
    "\n",
    "#Dado que encontrar una serie completa desde 2018 hasta 2024 de el valor del PIB por ciudad no es facil, primero usaremos la descomposicon por mes que hicimos departamental y la ponderaremos \n",
    "#por la importancia de cada ciudad en el departamento para encontrar un aproximando significativo. pdta= la base que nos pasaste profe no tenia todos los anos por eso hacemos esta aproximacion\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Municipio / Distrito' , 'Ciudad')\n",
    "importancia_pesos['Departamento'] = importancia_pesos['Departamento'].astype(str)\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Departamento' , 'Departamento')\n",
    "\n",
    "# Dejar solo las ciudades que estamos trabajando.\n",
    "for i in importancia_pesos['Ciudad']:\n",
    "    indice = importancia_pesos[importancia_pesos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        importancia_pesos = importancia_pesos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "importancia_pesos_mensual = importancia_pesos.loc[importancia_pesos.index.repeat(12)].reset_index(drop=True)\n",
    "importancia_pesos_mensual['Mes'] = (importancia_pesos_mensual.index % 12) + 1\n",
    "pib_pesos_ciudades1 = pd.merge(importancia_pesos_mensual, pib_mensual, on=['Departamento', 'Mes'], how='left')\n",
    "pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] /100\n",
    "pib_pesos_ciudades1['Pib Ponderado'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] * pib_pesos_ciudades1['PIB_Mensual']\n",
    "fusion_left = pd.merge(Base_2018, pib_pesos_ciudades1[['Pib Ponderado' , 'Ciudad', 'Mes']], on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Agregar puntos de llegadas internacionales\n",
    "entradas = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Entradas_de_extranjeros_a_Colombia_20241006.csv')\n",
    "entradas_2018= entradas[entradas['Año']==2018]\n",
    "entradas_2018 = entradas_2018[entradas_2018['Latitud - Longitud'] != 'No Aplica,No Aplica']\n",
    "entradas_2018 =traducir(entradas_2018 , 'Mes')\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "entradas_2018 =completar_meses(entradas_2018, 'Latitud - Longitud' , 'Mes' , 'Total' ,1 )\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "\n",
    "entradas_geometry = convertir_ubicacion(entradas_2018 , 'Latitud - Longitud')\n",
    "Entradas = gpd.GeoDataFrame(entradas_geometry, geometry='geometry')\n",
    "\n",
    "if Entradas.crs is None:\n",
    "    Entradas = Entradas.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Entradas = gpd.sjoin_nearest(Entradas,  Departamentos, how='left', distance_col='distancia').drop(['index_right' , 'DPTO' , 'AREA' , 'PERIMETER' , 'HECTARES' ,'distancia'] , axis=1)\n",
    "Entradas_Departamentos = Entradas.groupby(['Mes', 'Departamento'])['Total'].sum().reset_index()\n",
    "final = pd.merge(fusion_left, Entradas_Departamentos, on=['Departamento', 'Mes'], how='left').rename(columns={'Total': 'Entradas Extranjeros Zona'})\n",
    "final['Entradas Extranjeros Zona'] = final['Entradas Extranjeros Zona'].fillna(0)\n",
    "\n",
    "#Distancias desde los puntos de llegadas internacionales ponderadas \n",
    "for i in ciudades['Ciudad']:\n",
    "    indice = ciudades[ciudades['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_unico = ciudades.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unico = ciudades_unico.iloc[:, [0, -1]]\n",
    "ciudades_unico= gpd.GeoDataFrame(ciudades_unico, geometry='geometry')\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if Migracion_Unico.crs is None:\n",
    "    Migracion_Unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de Migracion_Unico: {Migracion_Unico.crs}\")\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "Migracion_Unico = Migracion_Unico.to_crs(epsg=32618)\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "Migracion_Unico['key'] = 1\n",
    "\n",
    "Distancia_combinado = pd.merge(ciudades_unico, Migracion_Unico, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "Distancia_combinado['distancia_km'] = Distancia_combinado.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_combinado['distancia_ponderada'] = Distancia_combinado['distancia_km'] * Distancia_combinado['Total']\n",
    "Distancia_ponderado = Distancia_combinado.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_migrantes=('Total', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "Distancia_ponderado['distancia_ponderada_km'] = Distancia_ponderado['suma_ponderada'] / Distancia_ponderado['suma_migrantes']\n",
    "Distancia_ponderado_final = Distancia_ponderado[['Ciudad' , 'distancia_ponderada_km']]\n",
    "\n",
    "Distancia_ciudades = ciudades_unico.merge(Distancia_ponderado_final, on='Ciudad')\n",
    "final1 = pd.merge(final, Distancia_ciudades, on='Ciudad', how='left').drop(['geometry_y' , 'key'] , axis=1)\\\n",
    "\n",
    "\n",
    "#Score de la importancia de los aeropuertos\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "columnas = ['geometry' , 'Departamento' ,'Total' ]\n",
    "Migracion_Unico_Dept = gpd.sjoin_nearest(Migracion_Unico, Departamentos, how='left', distance_col='distancia')[columnas]\n",
    "Total_Migracion = Migracion_Unico_Dept.groupby('Departamento').agg(\n",
    "    puntos=('Departamento', 'size'),  \n",
    "    total_personas=('Total', 'sum')  \n",
    ").reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "Total_Migracion[['puntos_norm', 'total_norm']] = scaler.fit_transform(Total_Migracion[['puntos', 'total_personas']])\n",
    "Total_Migracion['importancia accesos'] = 0.3 * Total_Migracion['puntos_norm'] + 0.7 * Total_Migracion['total_norm'] # Asumimos que es mas importante cuanta gente llega a que tantos puntos hay.\n",
    "final1 = pd.merge(final1, Total_Migracion, on='Departamento', how='left').drop(['puntos' , 'total_personas' , 'puntos_norm' , 'total_norm'] , axis=1)\n",
    "final1['importancia accesos'] = final1['importancia accesos'].fillna(0)\n",
    "\n",
    "#Numero establecimientos de turismo, camas y habitaciones para turistas.\n",
    "hoteles = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Hist_rico_Registro_Nacional_de_Turismo_-_RNT_20241007.csv')\n",
    "establecimientos_2018 = hoteles[hoteles['AÑO']==2018]\n",
    "\n",
    "Establecimientos = establecimientos_2018.groupby('NOMBRE-MUNI').agg({'CATEGORIA': 'count','HABITACIONES': 'sum', 'CAMAS': 'sum'}).reset_index().rename(columns={'CATEGORIA': 'Establecimientos'})\n",
    "Establecimientos = arreglar_texto(Establecimientos, 'NOMBRE-MUNI' , 'Municipios')\n",
    "for i in Establecimientos['Municipios']:\n",
    "    indice = Establecimientos[Establecimientos['Municipios'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Establecimientos = Establecimientos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "Establecimientos=Establecimientos.rename(columns={'Municipios': 'Ciudad'})\n",
    "meses_loees = np.arange(1, 13)\n",
    "patron_estacional = np.array([1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "def descomponer_variables_loess(df_anual, patron, variables):\n",
    "    def asignar_valores_mensuales(fila, patron, variables):\n",
    "        valores_mensuales = {}\n",
    "        for i in variables:\n",
    "            valores_mensuales[i] = patron * fila[i]\n",
    "        return valores_mensuales\n",
    "\n",
    "    data_mensual = []\n",
    "    for i, fila in df_anual.iterrows():\n",
    "        valores_mensuales = asignar_valores_mensuales(fila, patron, variables)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Ciudad': fila['Ciudad'],\n",
    "            'Mes': np.arange(1, 13)\n",
    "        })\n",
    "        \n",
    "        for k in variables:\n",
    "            df_temp[k] = valores_mensuales[k]\n",
    "        \n",
    "        data_mensual.append(df_temp)\n",
    "    \n",
    "    df_mensual = pd.concat(data_mensual, ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "Establecimientos_mensual = descomponer_variables_loess(Establecimientos, patron_smooth , ['Establecimientos' , 'HABITACIONES' , 'CAMAS'])\n",
    "final2 = pd.merge(final1, Establecimientos_mensual, on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Distancias al TOP de colombia \n",
    "\n",
    "df_TopColombia = pd.DataFrame.from_dict(Top_Colombia, orient='index', columns=['coordinates','Reviews', 'rating', 'eliminar'])\n",
    "df_TopColombia = df_TopColombia.reset_index().rename(columns={'index': 'lugar'}).drop('eliminar' , axis=1)\n",
    "df_TopColombia['geometry'] = df_TopColombia['coordinates'].apply(lambda x: Point(x[1], x[0]))\n",
    "df_TopColombia_gdp = gpd.GeoDataFrame(df_TopColombia, geometry='geometry').drop('coordinates' , axis=1)\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if df_TopColombia_gdp.crs is None:\n",
    "    df_TopColombia_gdp.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de df_TopColombia_gdp: {df_TopColombia_gdp.crs}\")\n",
    "\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "df_TopColombia_gdp = df_TopColombia_gdp.to_crs(epsg=32618)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "df_TopColombia_gdp['key'] = 1\n",
    "\n",
    "Distancia_Top = pd.merge(ciudades_unico, df_TopColombia_gdp, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "w_reviews = 0.6 # Vamos a asumir que las reviews tienen mas peso que la calificacion del lugar \n",
    "w_rating = 0.4\n",
    "\n",
    "Distancia_Top['distancia_km'] = Distancia_Top.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_Top[['distancia_km','Reviews', 'rating']] = scaler.fit_transform(\n",
    "    Distancia_Top[['distancia_km','Reviews', 'rating']]\n",
    ") # Normalizamos las variables para calcular una distancia ponderada con las mismas escalas\n",
    "\n",
    "Distancia_Top['distancia_ponderada'] = (Distancia_Top['distancia_km']) + ( w_reviews* Distancia_Top['Reviews']) + ( w_rating* Distancia_Top['rating'])\n",
    "\n",
    "Distancia_Ponderado_Top = Distancia_Top.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_reviews=('Reviews', 'sum'),\n",
    "    suma_rating=('rating', 'sum')).reset_index()\n",
    "\n",
    "Distancia_Ponderado_Top['distancia_ponderada_TOP'] = Distancia_Ponderado_Top['suma_ponderada'] / (Distancia_Ponderado_Top['suma_reviews']+Distancia_Ponderado_Top['suma_rating'])\n",
    "Distancia_Ponderado_Top_final = Distancia_Ponderado_Top[['Ciudad' , 'distancia_ponderada_TOP']]\n",
    "\n",
    "Distancia_Top = ciudades_unico.merge(Distancia_Ponderado_Top_final, on='Ciudad')\n",
    "final3 = pd.merge(final2, Distancia_Top, on='Ciudad', how='left').drop(['geometry_x' , 'key'] , axis=1)\n",
    "\n",
    "# Pobreza con proxy\n",
    "ciudades_poblacion = ciudades[['Ciudad' , 'population']]\n",
    "for i in ciudades_poblacion['Ciudad']:\n",
    "    indice = ciudades_poblacion[ciudades_poblacion['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_poblacion = ciudades_poblacion.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final4 = pd.merge(final3, ciudades_poblacion, on='Ciudad', how='left')\n",
    "final4['Proxy_Pobreza'] = final4['Pib Ponderado'] / final4['population']\n",
    "final4\n",
    "\n",
    "#Gasto promedio por dia de un turista\n",
    "gastos_diarios = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Gasto Promedio Diario 2019.xlsx')\n",
    "gastos_diarios = arreglar_texto(gastos_diarios , 'Ciudad', 'Ciudad')\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_diarios = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "inflacion_2019_promedio = 3.80 / 100\n",
    "inflacion_2019_aliemntos= 5.80 / 100\n",
    "inflacion_2019_transporte= 3.41 /100\n",
    "inflacion_2019_alojamiento = 3.46/100\n",
    "\n",
    "l2=[inflacion_2019_promedio, inflacion_2019_alojamiento,inflacion_2019_transporte,inflacion_2019_aliemntos,inflacion_2019_promedio]\n",
    "c=-1\n",
    "for i in gastos_diarios.iloc[: ,1:-1]:\n",
    "    c=c+1\n",
    "    gastos_diarios[i] = gastos_diarios[i] / (1+ l2[c])\n",
    "\n",
    "\n",
    "gastos_diarios_Nan = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_diarios_Nan = gpd.GeoDataFrame(pd.merge(gastos_diarios_Nan, ciudades_geometry, on='Ciudad', how='left').drop('geometry_x' , axis=1) , geometry='geometry')\n",
    "gastos_diarios_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_diarios_Nan=gastos_diarios_Nan.to_crs(epsg=32618)  \n",
    "variables = [i for i in gastos_diarios_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_diarios_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_diarios_Nan[gastos_diarios_Nan[variables].isnull().any(axis=1)]\n",
    "\n",
    "def kriging(df_con_info, variable, grid_size=100):\n",
    "    coords = np.array(list(zip(df_con_info.geometry.x, df_con_info.geometry.y)))\n",
    "    valores = df_con_info[variable].values\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = gastos_diarios_Nan.total_bounds\n",
    "    gridx = np.linspace(min_x, max_x, grid_size)\n",
    "    gridy = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    Krigg_O = OrdinaryKriging(\n",
    "        coords[:,0], coords[:,1], valores,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False\n",
    "    )\n",
    "    \n",
    "    z1, ss1 = Krigg_O.execute('grid', gridx, gridy)\n",
    "    \n",
    "    return Krigg_O, gridx, gridy, z1\n",
    "\n",
    "def estimar(Krigg, puntos):\n",
    "    x = puntos.geometry.x.values\n",
    "    y = puntos.geometry.y.values\n",
    "    estimados, ss = Krigg.execute('points', x, y)\n",
    "    return estimados\n",
    "\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual['Mes'] = (gastos_krigg_mensual.index % 12) + 1\n",
    "final5 = pd.merge(final4, gastos_krigg_mensual, on=['Mes', 'Ciudad'], how='left').drop('population' , axis=1)\n",
    "\n",
    "# Gastos de todo el viaje \n",
    "gastos_viaje = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Gasto Promedio Viaje 2019.xlsx')\n",
    "gastos_viaje = arreglar_texto(gastos_viaje , 'Ciudad', 'Ciudad')\n",
    "\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_viaje = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "\n",
    "l2=[inflacion_2019_promedio, inflacion_2019_alojamiento,inflacion_2019_transporte,inflacion_2019_aliemntos,inflacion_2019_promedio]\n",
    "c=-1\n",
    "for i in gastos_viaje.iloc[: ,1:-1]:\n",
    "    c=c+1\n",
    "    gastos_viaje[i] = gastos_viaje[i] / (1+ l2[c])\n",
    "\n",
    "gastos_viaje_Nan = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_viaje_Nan = gpd.GeoDataFrame(pd.merge(gastos_viaje_Nan, ciudades_geometry, on='Ciudad', how='left') , geometry='geometry')\n",
    "gastos_viaje_Nan = gastos_viaje_Nan.drop('geometry_x' , axis=1)\n",
    "\n",
    "gastos_viaje_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_viaje_Nan=gastos_viaje_Nan.to_crs(epsg=32618) \n",
    "variables = [i for i in gastos_viaje_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_viaje_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_viaje_Nan[gastos_viaje_Nan[variables].isnull().any(axis=1)]\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual_viaje = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual_viaje['Mes'] = (gastos_krigg_mensual_viaje.index % 12) + 1\n",
    "gastos_krigg_mensual_viaje\n",
    "Base_2018_Final = pd.merge(final5, gastos_krigg_mensual_viaje, on=['Mes', 'Ciudad'], how='left').drop('geometry_y' , axis=1)\n",
    "\n",
    "# Agregar inflacion \n",
    "inflacion = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Inflacion.xlsx')\n",
    "inflacion['Fecha'] = pd.to_datetime(inflacion['Fecha'])\n",
    "inflacion = inflacion[inflacion['Fecha'].dt.year == 2018].rename(columns={'Fecha':'Mes'})\n",
    "inflacion['Mes'] = inflacion['Mes'].dt.month\n",
    "Base_2018_Final = pd.merge(Base_2018_Final, inflacion, on='Mes', how='left')\n",
    "\n",
    "#Agregar Vias\n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2018_Final = pd.merge(Base_2018_Final , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "# Agregar los eventos\n",
    "eventos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Eventos Turisticos\\\\Eventos 2018.xlsx').fillna(0)\n",
    "eventos = arreglar_texto(eventos ,'Departamento' , 'Departamento')\n",
    "eventos['Departamento'] = eventos['Departamento'].str.replace('sanandres', 'archipielagodesanandresprovidenciaysantacatalina', regex=False)\n",
    "Base_2018_Final = pd.merge(Base_2018_Final , eventos , on=['Departamento' ,'Mes'] , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see 2018 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto  Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pitalito</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>huila</td>\n",
       "      <td>18.055550</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>151.999238</td>\n",
       "      <td>...</td>\n",
       "      <td>22348.735798</td>\n",
       "      <td>338814.831038</td>\n",
       "      <td>51427.415415</td>\n",
       "      <td>83910.734197</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>129164.039202</td>\n",
       "      <td>POINT (384119.441 209921.192)</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>riohacha</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>laguajira</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>245.473018</td>\n",
       "      <td>...</td>\n",
       "      <td>25608.302505</td>\n",
       "      <td>407012.594412</td>\n",
       "      <td>44746.452735</td>\n",
       "      <td>105537.118267</td>\n",
       "      <td>85981.834594</td>\n",
       "      <td>169633.602119</td>\n",
       "      <td>POINT (728275.629 1276987.69)</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rionegro</td>\n",
       "      <td>1</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>antioquia</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>343.717029</td>\n",
       "      <td>...</td>\n",
       "      <td>23317.813823</td>\n",
       "      <td>300105.482181</td>\n",
       "      <td>51759.383143</td>\n",
       "      <td>56151.273165</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>88352.122091</td>\n",
       "      <td>POINT (458587.876 680187.339)</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bogota</td>\n",
       "      <td>1</td>\n",
       "      <td>99767.0</td>\n",
       "      <td>83</td>\n",
       "      <td>7149</td>\n",
       "      <td>426</td>\n",
       "      <td>bogotadc</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>23953.819812</td>\n",
       "      <td>...</td>\n",
       "      <td>33676.461464</td>\n",
       "      <td>459819.807322</td>\n",
       "      <td>95874.495457</td>\n",
       "      <td>75289.853012</td>\n",
       "      <td>116471.723062</td>\n",
       "      <td>170536.499037</td>\n",
       "      <td>POINT (602898.9 520798.299)</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>piedecuesta</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>santander</td>\n",
       "      <td>22.523648</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>258.755835</td>\n",
       "      <td>...</td>\n",
       "      <td>23450.014915</td>\n",
       "      <td>316598.313028</td>\n",
       "      <td>59438.480482</td>\n",
       "      <td>63676.087723</td>\n",
       "      <td>86267.558458</td>\n",
       "      <td>96363.989201</td>\n",
       "      <td>POINT (720906.443 783432.99)</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>aguachica</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>cesar</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>3198.45</td>\n",
       "      <td>73.597907</td>\n",
       "      <td>...</td>\n",
       "      <td>24460.519917</td>\n",
       "      <td>333762.080665</td>\n",
       "      <td>59294.963216</td>\n",
       "      <td>67266.228511</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>110529.693825</td>\n",
       "      <td>POINT (650504.481 919569.475)</td>\n",
       "      <td>3.178001</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>sanjosedelguaviare</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>guaviare</td>\n",
       "      <td>21.841149</td>\n",
       "      <td>3198.45</td>\n",
       "      <td>38.317074</td>\n",
       "      <td>...</td>\n",
       "      <td>27668.564574</td>\n",
       "      <td>395447.494787</td>\n",
       "      <td>45450.965582</td>\n",
       "      <td>88726.234789</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>192305.361801</td>\n",
       "      <td>POINT (763167.066 283942.885)</td>\n",
       "      <td>3.178001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>palermo</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>huila</td>\n",
       "      <td>21.841149</td>\n",
       "      <td>3198.45</td>\n",
       "      <td>48.387369</td>\n",
       "      <td>...</td>\n",
       "      <td>22631.547867</td>\n",
       "      <td>307163.189741</td>\n",
       "      <td>38876.115932</td>\n",
       "      <td>67538.785887</td>\n",
       "      <td>86615.106081</td>\n",
       "      <td>103876.913144</td>\n",
       "      <td>POINT (451378.305 319631.823)</td>\n",
       "      <td>3.178001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>mitu</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>vaupes</td>\n",
       "      <td>21.841149</td>\n",
       "      <td>3198.45</td>\n",
       "      <td>14.093870</td>\n",
       "      <td>...</td>\n",
       "      <td>28137.854413</td>\n",
       "      <td>399306.017324</td>\n",
       "      <td>41051.943230</td>\n",
       "      <td>79640.264317</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>208543.305296</td>\n",
       "      <td>POINT (1037614.182 132922.769)</td>\n",
       "      <td>3.178001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>magangue</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>21.841149</td>\n",
       "      <td>3198.45</td>\n",
       "      <td>110.430674</td>\n",
       "      <td>...</td>\n",
       "      <td>26188.647835</td>\n",
       "      <td>357816.583211</td>\n",
       "      <td>58745.586428</td>\n",
       "      <td>80104.388875</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>124367.068268</td>\n",
       "      <td>POINT (525625.153 1022500.055)</td>\n",
       "      <td>3.178001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ciudad  Mes  Extranjeros no Residentes  Homicidios  Hurtos  \\\n",
       "0              pitalito    1                       33.0           2      61   \n",
       "1              riohacha    1                      108.0           4      49   \n",
       "2              rionegro    1                      271.0           2      51   \n",
       "3                bogota    1                    99767.0          83    7149   \n",
       "4           piedecuesta    1                       28.0           1      66   \n",
       "..                  ...  ...                        ...         ...     ...   \n",
       "967           aguachica   12                       14.0           2      28   \n",
       "968  sanjosedelguaviare   12                        8.0           1      12   \n",
       "969             palermo   12                        1.0           0       8   \n",
       "970                mitu   12                        0.0           0       0   \n",
       "971            magangue   12                       11.0           1      22   \n",
       "\n",
       "     Delitos Sexuales Departamento  Temperatura    Dolar  Pib Ponderado  ...  \\\n",
       "0                  15        huila    18.055550  2855.86     151.999238  ...   \n",
       "1                   8    laguajira    26.700000  2855.86     245.473018  ...   \n",
       "2                   7    antioquia    15.500000  2855.86     343.717029  ...   \n",
       "3                 426     bogotadc    12.600000  2855.86   23953.819812  ...   \n",
       "4                  13    santander    22.523648  2855.86     258.755835  ...   \n",
       "..                ...          ...          ...      ...            ...  ...   \n",
       "967                 4        cesar    27.550000  3198.45      73.597907  ...   \n",
       "968                11     guaviare    21.841149  3198.45      38.317074  ...   \n",
       "969                 0        huila    21.841149  3198.45      48.387369  ...   \n",
       "970                 4       vaupes    21.841149  3198.45      14.093870  ...   \n",
       "971                 3      bolivar    21.841149  3198.45     110.430674  ...   \n",
       "\n",
       "     Otros Gastos  Diario  Gasto Promedio Viaje  Gasto  Alojamiento Viaje  \\\n",
       "0            22348.735798         338814.831038              51427.415415   \n",
       "1            25608.302505         407012.594412              44746.452735   \n",
       "2            23317.813823         300105.482181              51759.383143   \n",
       "3            33676.461464         459819.807322              95874.495457   \n",
       "4            23450.014915         316598.313028              59438.480482   \n",
       "..                    ...                   ...                       ...   \n",
       "967          24460.519917         333762.080665              59294.963216   \n",
       "968          27668.564574         395447.494787              45450.965582   \n",
       "969          22631.547867         307163.189741              38876.115932   \n",
       "970          28137.854413         399306.017324              41051.943230   \n",
       "971          26188.647835         357816.583211              58745.586428   \n",
       "\n",
       "     Gasto Transporte Viaje  Gasto alimetos Viaje  Otros Gastos Viaje  \\\n",
       "0              83910.734197          86719.142328       129164.039202   \n",
       "1             105537.118267          85981.834594       169633.602119   \n",
       "2              56151.273165          86719.142328        88352.122091   \n",
       "3              75289.853012         116471.723062       170536.499037   \n",
       "4              63676.087723          86267.558458        96363.989201   \n",
       "..                      ...                   ...                 ...   \n",
       "967            67266.228511          86719.142328       110529.693825   \n",
       "968            88726.234789          86719.142328       192305.361801   \n",
       "969            67538.785887          86615.106081       103876.913144   \n",
       "970            79640.264317          86719.142328       208543.305296   \n",
       "971            80104.388875          86719.142328       124367.068268   \n",
       "\n",
       "                           geometry  Inflacion  carreteras_cercanas  Eventos  \n",
       "0     POINT (384119.441 209921.192)   3.679528                    6      0.0  \n",
       "1     POINT (728275.629 1276987.69)   3.679528                    2      0.0  \n",
       "2     POINT (458587.876 680187.339)   3.679528                   12      3.0  \n",
       "3       POINT (602898.9 520798.299)   3.679528                   13      0.0  \n",
       "4      POINT (720906.443 783432.99)   3.679528                    4      3.0  \n",
       "..                              ...        ...                  ...      ...  \n",
       "967   POINT (650504.481 919569.475)   3.178001                   13      0.0  \n",
       "968   POINT (763167.066 283942.885)   3.178001                    2      0.0  \n",
       "969   POINT (451378.305 319631.823)   3.178001                    2      0.0  \n",
       "970  POINT (1037614.182 132922.769)   3.178001                    0      0.0  \n",
       "971  POINT (525625.153 1022500.055)   3.178001                    2      0.0  \n",
       "\n",
       "[972 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2018_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto  Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [Ciudad, Mes, Extranjeros no Residentes, Homicidios, Hurtos, Delitos Sexuales, Departamento, Temperatura, Dolar, Pib Ponderado, Entradas Extranjeros Zona, distancia_ponderada_km, importancia accesos, Establecimientos, HABITACIONES, CAMAS, geometry_x, distancia_ponderada_TOP, Proxy_Pobreza, Gasto Promedio Diario, Gasto Alojamiento Diario, Gasto Transporte  Diario, Gasto alimetos  Diario, Otros Gastos  Diario, Gasto Promedio Viaje, Gasto  Alojamiento Viaje, Gasto Transporte Viaje, Gasto alimetos Viaje, Otros Gastos Viaje, geometry, Inflacion, carreteras_cercanas, Eventos]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2018_Final[Base_2018_Final.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Visitantes_No_Residentes.csv')\n",
    "df1 = df[df[\"Año\"] == 2019]\n",
    "df1= arreglar_texto(df1 , 'Ciudad' , 'Ciudad')\n",
    "Homicidios= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2019\\\\homicidios_2019_3.xlsx').dropna()\n",
    "Homicidos1 = bases_crimenes(Homicidios , 'FECHA HECHO' , 'CANTIDAD' , 'Homicidios')\n",
    "Hurto= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2019\\\\hurto_a_personas_2019_0.xlsx').dropna()\n",
    "Hurto1 = bases_crimenes(Hurto , 'FECHA HECHO' , 'CANTIDAD' , 'Hurtos')\n",
    "sexuales= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2019\\\\delitos_sexuales_2019_0.xlsx').dropna()\n",
    "sexuales1 = bases_crimenes(sexuales , 'FECHA HECHO' , 'CANTIDAD' , 'Delitos Sexuales')\n",
    "ciudades= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\ciudades.csv')\n",
    "ciudades = arreglar_texto(ciudades, 'city' , \"Ciudad\")\n",
    "ciudades['admin_name'] = ciudades['admin_name'].astype(str)\n",
    "ciudades.at[68, 'admin_name'] = 'Atlantico'\n",
    "Total_18= completar_meses(df1 , 'Ciudad' , 'Mes' ,'Extranjeros no Residentes' , 1)\n",
    "Total_18 = pd.merge(Total_18, Homicidos1[['Ciudad', 'Homicidios' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, Hurto1[['Ciudad', 'Hurtos' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, sexuales1[['Ciudad', 'Delitos Sexuales' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18['Homicidios'] = Total_18['Homicidios'].fillna(0)\n",
    "Total_18['Hurtos'] = Total_18['Hurtos'].fillna(0)\n",
    "Total_18['Delitos Sexuales'] = Total_18['Delitos Sexuales'].fillna(0)\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('bogotadc', 'bogota', regex=False)\n",
    "\n",
    "#Seleccionar Ciudades que vamos a trabajar\n",
    "ciudades1= set(ciudades['Ciudad'])\n",
    "ciudades2= set(Total_18['Ciudad'])\n",
    "grandes_ciudades=list(ciudades1.intersection(ciudades2))\n",
    "l=['bogota' , 'tumaco']\n",
    "grandes_ciudades = grandes_ciudades + l\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "for i in Total_18['Ciudad']:\n",
    "    indice = Total_18[Total_18['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Total_18 = Total_18.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Poner Ubicaciones\n",
    "ciudades['geometry'] = ciudades.apply(lambda i: Point(i['lng'], i['lat']), axis=1)\n",
    "ciudades_geometry= gpd.GeoDataFrame(ciudades, geometry='geometry')\n",
    "Total_18_Geometry= pd.merge(Total_18, ciudades_geometry[['Ciudad', 'geometry']], on='Ciudad' , how='left')\n",
    "Total_18_Geometry= gpd.GeoDataFrame(Total_18_Geometry, geometry='geometry')\n",
    "\n",
    "# Poner departamentos\n",
    "Departamentos = gpd.read_file(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Colombia.json\")\n",
    "Departamentos = arreglar_texto(Departamentos, 'NOMBRE_DPT' , \"Departamento\")\n",
    "Departamentos[\"Departamento\"] = Departamentos[\"Departamento\"].str.replace('santafedebogota', 'bogotadc', regex=False)\n",
    "\n",
    "if Total_18_Geometry.crs is None:\n",
    "    Total_18_Geometry = Total_18_Geometry.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Total_18_Geometry = gpd.sjoin_nearest(Total_18_Geometry,  Departamentos, how='left', distance_col='distancia').drop(['AREA' , 'PERIMETER' , 'HECTARES' , 'DPTO','index_right' , 'distancia'] , axis=1)\n",
    "Total_18_Geometry\n",
    "Total_18_Geometry[Total_18_Geometry.isnull().any(axis=1)]\n",
    "\n",
    "#Agregar Clima\n",
    "clima_2018 = clima[clima['FechaObservacion'].dt.year == 2019]\n",
    "clima_2018 = arreglar_texto(clima_2018 , 'Municipio', 'Ciudad')\n",
    "clima_2018= completar_meses(clima_2018 , 'Ciudad' , 'Mes' ,'ValorObservado' , 0)\n",
    "Total_18_Clima= pd.merge(Total_18_Geometry, clima_2018[['Ciudad', 'ValorObservado' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18_Clima = Total_18_Clima.rename(columns={'ValorObservado': 'Temperatura'})\n",
    "\n",
    "#Krigging para el clima \n",
    "df_kriging = meses_a_numeros(Total_18_Clima , 'Mes')\n",
    "df_kriging.set_crs(epsg=4326, inplace=True)\n",
    "df_kriging=df_kriging.to_crs(epsg=32618)  \n",
    "\n",
    "meses_krig = df_kriging['Mes'].unique()\n",
    "\n",
    "for i in meses_krig:\n",
    "    print('Procesando Mes:' ,i)\n",
    "    \n",
    "    df_kriging_mes = df_kriging[df_kriging['Mes'] == i] # Vamos a realizar el kriging por mes\n",
    "    df_kriging_known = df_kriging_mes.dropna(subset=['Temperatura']) # Los datos para los que tenemos temperatura\n",
    "    df_kriging_missing = df_kriging_mes[df_kriging_mes ['Temperatura'].isna()] # Los datos para los NO que tenemos temperatura (Variable a predecir)\n",
    "    \n",
    "    if df_kriging_missing.empty:\n",
    "        print('No hay datos faltantes en el mes ' , i) # Si algun mes esta completo para todas las ciudades, no hacer nada \n",
    "        continue\n",
    "    \n",
    "    # Nuestras variables para predecir\n",
    "    x_known = df_kriging_known.geometry.x.values\n",
    "    y_known = df_kriging_known.geometry.y.values\n",
    "    z_known = df_kriging_known['Temperatura'].values\n",
    "    \n",
    "    # Nuestros datos a predecir\n",
    "    x_missing = df_kriging_missing.geometry.x.values\n",
    "    y_missing = df_kriging_missing.geometry.y.values\n",
    "    \n",
    "    # Crear el modelo \n",
    "    Krigg = OrdinaryKriging(\n",
    "        x_known, y_known, z_known,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False)\n",
    "    \n",
    "    # Realizar predicciones con el krigging\n",
    "    z_pred, ss = Krigg.execute('points', x_missing, y_missing)\n",
    "    \n",
    "    # Introducir en el DF los valores\n",
    "    df_kriging.loc[df_kriging_missing.index, 'Temperatura'] = z_pred\n",
    "\n",
    "#Agregar precio dolar\n",
    "Dolar = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Dolar.xlsx')\n",
    "Dolar['Fecha'] = pd.to_datetime(Dolar['Fecha'], errors='coerce')\n",
    "Dolar.set_index('Fecha', inplace=True)\n",
    "Dolar = Dolar.resample('M').median()\n",
    "Dolar = Dolar.reset_index()\n",
    "Dolar_2018=Dolar[Dolar['Fecha'].dt.year == 2019]\n",
    "Dolar_2018['Mes'] = range(1, 13)\n",
    "Base_2018=pd.merge(df_kriging, Dolar_2018, on= 'Mes', how='right').drop('Fecha' , axis=1)\n",
    "Base_2018\n",
    "\n",
    "#Interpolar PIB mensual\n",
    "\n",
    "PIB= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2019\\\\PIB - Miles de millones de pesos  - 2019.xlsx')\n",
    "PIB= arreglar_texto(PIB, 'DEPARTAMENTO' , 'Departamento')\n",
    "PIB['VALOR (unidades)'] = PIB['VALOR (unidades)'].str.replace(',', '.')\n",
    "PIB['VALOR (unidades)'] = pd.to_numeric(PIB['VALOR (unidades)'], errors='coerce')\n",
    "\n",
    "# Usaremos el metodo de LOESS para descomponer el PIB mensualmente \n",
    "meses_loees= np.arange(1, 13)\n",
    "tendencia_mensual_inflacion = [3.15 ,3.01, 3.21 , 3.25 , 3.31 , 3.43 , 3.79 , 3.75 , 3.82 , 3.86 , 3.84 , 3.80] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual_inflacion) for valor in tendencia_mensual_inflacion]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "# La idea es crear algun tipo de ruido sobre nuestro patron, para asi tratar de simular efectos reales economicos.\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) #  Asegurarnos que todos las fulctuaciones sean positivas. \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "\n",
    "def descomponer_pib_loess(pib_anual, patron):\n",
    "    def asignar_pib_mensual(k, patron):\n",
    "        pib_mensual = patron * k['VALOR (unidades)']\n",
    "        return pib_mensual\n",
    "\n",
    "    df_mensual = pd.DataFrame()\n",
    "    \n",
    "    for i, k in pib_anual.iterrows():\n",
    "        pib_mensual = asignar_pib_mensual(k, patron)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Departamento': k['Departamento'],\n",
    "            'Mes': np.arange(1, 13),\n",
    "            'PIB_Mensual': pib_mensual\n",
    "        })\n",
    "        \n",
    "        df_mensual = pd.concat([df_mensual, df_temp], ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "pib_mensual = descomponer_pib_loess(PIB, patron_smooth)\n",
    "importancia_pesos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\importancia-municipal.xlsx')\n",
    "\n",
    "#Dado que encontrar una serie completa desde 2018 hasta 2024 de el valor del PIB por ciudad no es facil, primero usaremos la descomposicon por mes que hicimos departamental y la ponderaremos \n",
    "#por la importancia de cada ciudad en el departamento para encontrar un aproximando significativo. pdta= la base que nos pasaste profe no tenia todos los anos por eso hacemos esta aproximacion\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Municipio / Distrito' , 'Ciudad')\n",
    "importancia_pesos['Departamento'] = importancia_pesos['Departamento'].astype(str)\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Departamento' , 'Departamento')\n",
    "\n",
    "# Dejar solo las ciudades que estamos trabajando.\n",
    "for i in importancia_pesos['Ciudad']:\n",
    "    indice = importancia_pesos[importancia_pesos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        importancia_pesos = importancia_pesos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "importancia_pesos_mensual = importancia_pesos.loc[importancia_pesos.index.repeat(12)].reset_index(drop=True)\n",
    "importancia_pesos_mensual['Mes'] = (importancia_pesos_mensual.index % 12) + 1\n",
    "pib_pesos_ciudades1 = pd.merge(importancia_pesos_mensual, pib_mensual, on=['Departamento', 'Mes'], how='left')\n",
    "pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] /100\n",
    "pib_pesos_ciudades1['Pib Ponderado'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] * pib_pesos_ciudades1['PIB_Mensual']\n",
    "fusion_left = pd.merge(Base_2018, pib_pesos_ciudades1[['Pib Ponderado' , 'Ciudad', 'Mes']], on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Agregar puntos de llegadas internacionales\n",
    "entradas = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Entradas_de_extranjeros_a_Colombia_20241006.csv')\n",
    "entradas_2018= entradas[entradas['Año']==2019]\n",
    "entradas_2018 = entradas_2018[entradas_2018['Latitud - Longitud'] != 'No Aplica,No Aplica']\n",
    "entradas_2018 =traducir(entradas_2018 , 'Mes')\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "entradas_2018 =completar_meses(entradas_2018, 'Latitud - Longitud' , 'Mes' , 'Total' ,1 )\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "\n",
    "entradas_geometry = convertir_ubicacion(entradas_2018 , 'Latitud - Longitud')\n",
    "Entradas = gpd.GeoDataFrame(entradas_geometry, geometry='geometry')\n",
    "\n",
    "if Entradas.crs is None:\n",
    "    Entradas = Entradas.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Entradas = gpd.sjoin_nearest(Entradas,  Departamentos, how='left', distance_col='distancia').drop(['index_right' , 'DPTO' , 'AREA' , 'PERIMETER' , 'HECTARES' ,'distancia'] , axis=1)\n",
    "Entradas_Departamentos = Entradas.groupby(['Mes', 'Departamento'])['Total'].sum().reset_index()\n",
    "final = pd.merge(fusion_left, Entradas_Departamentos, on=['Departamento', 'Mes'], how='left').rename(columns={'Total': 'Entradas Extranjeros Zona'})\n",
    "final['Entradas Extranjeros Zona'] = final['Entradas Extranjeros Zona'].fillna(0)\n",
    "final[final['Ciudad'] == 'medellin']\n",
    "\n",
    "#Distancias desde los puntos de llegadas internacionales ponderadas \n",
    "for i in ciudades['Ciudad']:\n",
    "    indice = ciudades[ciudades['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_unico = ciudades.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unico = ciudades_unico.iloc[:, [0, -1]]\n",
    "ciudades_unico= gpd.GeoDataFrame(ciudades_unico, geometry='geometry')\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if Migracion_Unico.crs is None:\n",
    "    Migracion_Unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de Migracion_Unico: {Migracion_Unico.crs}\")\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "Migracion_Unico = Migracion_Unico.to_crs(epsg=32618)\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "Migracion_Unico['key'] = 1\n",
    "\n",
    "Distancia_combinado = pd.merge(ciudades_unico, Migracion_Unico, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "Distancia_combinado['distancia_km'] = Distancia_combinado.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_combinado['distancia_ponderada'] = Distancia_combinado['distancia_km'] * Distancia_combinado['Total']\n",
    "Distancia_ponderado = Distancia_combinado.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_migrantes=('Total', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "Distancia_ponderado['distancia_ponderada_km'] = Distancia_ponderado['suma_ponderada'] / Distancia_ponderado['suma_migrantes']\n",
    "Distancia_ponderado_final = Distancia_ponderado[['Ciudad' , 'distancia_ponderada_km']]\n",
    "\n",
    "Distancia_ciudades = ciudades_unico.merge(Distancia_ponderado_final, on='Ciudad')\n",
    "final1 = pd.merge(final, Distancia_ciudades, on='Ciudad', how='left').drop(['geometry_y' , 'key'] , axis=1)\n",
    "\n",
    "#Score de la importancia de los aeropuertos\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "columnas = ['geometry' , 'Departamento' ,'Total' ]\n",
    "Migracion_Unico_Dept = gpd.sjoin_nearest(Migracion_Unico, Departamentos, how='left', distance_col='distancia')[columnas]\n",
    "Total_Migracion = Migracion_Unico_Dept.groupby('Departamento').agg(\n",
    "    puntos=('Departamento', 'size'),  \n",
    "    total_personas=('Total', 'sum')  \n",
    ").reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "Total_Migracion[['puntos_norm', 'total_norm']] = scaler.fit_transform(Total_Migracion[['puntos', 'total_personas']])\n",
    "Total_Migracion['importancia accesos'] = 0.3 * Total_Migracion['puntos_norm'] + 0.7 * Total_Migracion['total_norm'] # Asumimos que es mas importante cuanta gente llega a que tantos puntos hay.\n",
    "final1 = pd.merge(final1, Total_Migracion, on='Departamento', how='left').drop(['puntos' , 'total_personas' , 'puntos_norm' , 'total_norm'] , axis=1)\n",
    "final1['importancia accesos'] = final1['importancia accesos'].fillna(0)\n",
    "\n",
    "#Numero establecimientos de turismo, camas y habitaciones para turistas.\n",
    "hoteles = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Hist_rico_Registro_Nacional_de_Turismo_-_RNT_20241007.csv')\n",
    "establecimientos_2018 = hoteles[hoteles['AÑO']==2019]\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('PUERTO INIRIDA', 'Inirida', regex=False)\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('BUGA', 'guadalajaradebuga', regex=False)\n",
    "\n",
    "Establecimientos = establecimientos_2018.groupby('NOMBRE-MUNI').agg({'CATEGORIA': 'count','HABITACIONES': 'sum', 'CAMAS': 'sum'}).reset_index().rename(columns={'CATEGORIA': 'Establecimientos'})\n",
    "Establecimientos = arreglar_texto(Establecimientos, 'NOMBRE-MUNI' , 'Municipios')\n",
    "for i in Establecimientos['Municipios']:\n",
    "    indice = Establecimientos[Establecimientos['Municipios'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Establecimientos = Establecimientos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "Establecimientos=Establecimientos.rename(columns={'Municipios': 'Ciudad'})\n",
    "meses_loees = np.arange(1, 13)\n",
    "tendencia_mensual = [30,33,36,35,36,38,39,40,41,42,43,43] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual) for valor in tendencia_mensual]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "def descomponer_variables_loess(df_anual, patron, variables):\n",
    "    def asignar_valores_mensuales(fila, patron, variables):\n",
    "        valores_mensuales = {}\n",
    "        for i in variables:\n",
    "            valores_mensuales[i] = patron * fila[i]\n",
    "        return valores_mensuales\n",
    "\n",
    "    data_mensual = []\n",
    "    for i, fila in df_anual.iterrows():\n",
    "        valores_mensuales = asignar_valores_mensuales(fila, patron, variables)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Ciudad': fila['Ciudad'],\n",
    "            'Mes': np.arange(1, 13)\n",
    "        })\n",
    "        \n",
    "        for k in variables:\n",
    "            df_temp[k] = valores_mensuales[k]\n",
    "        \n",
    "        data_mensual.append(df_temp)\n",
    "    \n",
    "    df_mensual = pd.concat(data_mensual, ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "Establecimientos_mensual = descomponer_variables_loess(Establecimientos, patron_smooth , ['Establecimientos' , 'HABITACIONES' , 'CAMAS'])\n",
    "final2 = pd.merge(final1, Establecimientos_mensual, on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Distancias al TOP de colombia \n",
    "\n",
    "df_TopColombia = pd.DataFrame.from_dict(Top_Colombia, orient='index', columns=['coordinates','Reviews', 'rating', 'eliminar'])\n",
    "df_TopColombia = df_TopColombia.reset_index().rename(columns={'index': 'lugar'}).drop('eliminar' , axis=1)\n",
    "df_TopColombia['geometry'] = df_TopColombia['coordinates'].apply(lambda x: Point(x[1], x[0]))\n",
    "df_TopColombia_gdp = gpd.GeoDataFrame(df_TopColombia, geometry='geometry').drop('coordinates' , axis=1)\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if df_TopColombia_gdp.crs is None:\n",
    "    df_TopColombia_gdp.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de df_TopColombia_gdp: {df_TopColombia_gdp.crs}\")\n",
    "\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "df_TopColombia_gdp = df_TopColombia_gdp.to_crs(epsg=32618)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "df_TopColombia_gdp['key'] = 1\n",
    "\n",
    "Distancia_Top = pd.merge(ciudades_unico, df_TopColombia_gdp, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "w_reviews = 0.6 # Vamos a asumir que las reviews tienen mas peso que la calificacion del lugar \n",
    "w_rating = 0.4\n",
    "\n",
    "Distancia_Top['distancia_km'] = Distancia_Top.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_Top[['distancia_km','Reviews', 'rating']] = scaler.fit_transform(\n",
    "    Distancia_Top[['distancia_km','Reviews', 'rating']]\n",
    ") # Normalizamos las variables para calcular una distancia ponderada con las mismas escalas\n",
    "\n",
    "Distancia_Top['distancia_ponderada'] = (Distancia_Top['distancia_km']) + ( w_reviews* Distancia_Top['Reviews']) + ( w_rating* Distancia_Top['rating'])\n",
    "\n",
    "Distancia_Ponderado_Top = Distancia_Top.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_reviews=('Reviews', 'sum'),\n",
    "    suma_rating=('rating', 'sum')).reset_index()\n",
    "\n",
    "Distancia_Ponderado_Top['distancia_ponderada_TOP'] = Distancia_Ponderado_Top['suma_ponderada'] / (Distancia_Ponderado_Top['suma_reviews']+Distancia_Ponderado_Top['suma_rating'])\n",
    "Distancia_Ponderado_Top_final = Distancia_Ponderado_Top[['Ciudad' , 'distancia_ponderada_TOP']]\n",
    "\n",
    "Distancia_Top = ciudades_unico.merge(Distancia_Ponderado_Top_final, on='Ciudad')\n",
    "final3 = pd.merge(final2, Distancia_Top, on='Ciudad', how='left').drop(['geometry_x' , 'key'] , axis=1)\n",
    "\n",
    "# Pobreza con proxy\n",
    "ciudades_poblacion = ciudades[['Ciudad' , 'population']]\n",
    "for i in ciudades_poblacion['Ciudad']:\n",
    "    indice = ciudades_poblacion[ciudades_poblacion['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_poblacion = ciudades_poblacion.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final4 = pd.merge(final3, ciudades_poblacion, on='Ciudad', how='left')\n",
    "final4['Proxy_Pobreza'] = final4['Pib Ponderado'] / final4['population']\n",
    "final4\n",
    "\n",
    "#Gasto promedio por dia de un turista\n",
    "gastos_diarios = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Gasto Promedio Diario 2019.xlsx')\n",
    "gastos_diarios = arreglar_texto(gastos_diarios , 'Ciudad', 'Ciudad')\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_diarios = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "gastos_diarios_Nan = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_diarios_Nan = gpd.GeoDataFrame(pd.merge(gastos_diarios_Nan, ciudades_geometry, on='Ciudad', how='left').drop('geometry_x' , axis=1) , geometry='geometry')\n",
    "gastos_diarios_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_diarios_Nan=gastos_diarios_Nan.to_crs(epsg=32618)  \n",
    "variables = [i for i in gastos_diarios_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_diarios_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_diarios_Nan[gastos_diarios_Nan[variables].isnull().any(axis=1)]\n",
    "\n",
    "def kriging(df_con_info, variable, grid_size=100):\n",
    "    coords = np.array(list(zip(df_con_info.geometry.x, df_con_info.geometry.y)))\n",
    "    valores = df_con_info[variable].values\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = gastos_diarios_Nan.total_bounds\n",
    "    gridx = np.linspace(min_x, max_x, grid_size)\n",
    "    gridy = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    Krigg_O = OrdinaryKriging(\n",
    "        coords[:,0], coords[:,1], valores,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False\n",
    "    )\n",
    "    \n",
    "    z1, ss1 = Krigg_O.execute('grid', gridx, gridy)\n",
    "    \n",
    "    return Krigg_O, gridx, gridy, z1\n",
    "\n",
    "def estimar(Krigg, puntos):\n",
    "    x = puntos.geometry.x.values\n",
    "    y = puntos.geometry.y.values\n",
    "    estimados, ss = Krigg.execute('points', x, y)\n",
    "    return estimados\n",
    "\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual['Mes'] = (gastos_krigg_mensual.index % 12) + 1\n",
    "final5 = pd.merge(final4, gastos_krigg_mensual, on=['Mes', 'Ciudad'], how='left').drop(['geometry_x','population'] , axis=1)\n",
    "\n",
    "# Gastos de todo el viaje \n",
    "gastos_viaje = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Gasto Promedio Viaje 2019.xlsx')\n",
    "gastos_viaje = arreglar_texto(gastos_viaje , 'Ciudad', 'Ciudad')\n",
    "\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_viaje = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='left')\n",
    "gastos_viaje_Nan = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_viaje_Nan = gpd.GeoDataFrame(pd.merge(gastos_viaje_Nan, ciudades_geometry, on='Ciudad', how='left') , geometry='geometry')\n",
    "gastos_viaje_Nan = gastos_viaje_Nan.drop('geometry_x' , axis=1)\n",
    "\n",
    "gastos_viaje_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_viaje_Nan=gastos_viaje_Nan.to_crs(epsg=32618) \n",
    "variables = [i for i in gastos_viaje_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_viaje_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_viaje_Nan[gastos_viaje_Nan[variables].isnull().any(axis=1)]\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual_viaje = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual_viaje['Mes'] = (gastos_krigg_mensual_viaje.index % 12) + 1\n",
    "gastos_krigg_mensual_viaje\n",
    "Base_2019 = pd.merge(final5, gastos_krigg_mensual_viaje, on=['Mes', 'Ciudad'], how='left').drop('geometry_y' , axis=1)\n",
    "\n",
    "# Agregar inflacion\n",
    "inflacion = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Inflacion.xlsx')\n",
    "inflacion['Fecha'] = pd.to_datetime(inflacion['Fecha'])\n",
    "inflacion = inflacion[inflacion['Fecha'].dt.year == 2019].rename(columns={'Fecha':'Mes'})\n",
    "inflacion['Mes'] = inflacion['Mes'].dt.month\n",
    "Base_2019 = pd.merge(Base_2019, inflacion, on='Mes', how='left')\n",
    "\n",
    "#Agregar Vias\n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2019 = pd.merge(Base_2019 , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "# Agregar Eventos\n",
    "eventos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Eventos Turisticos\\\\Eventos 2018.xlsx').fillna(0)\n",
    "eventos = arreglar_texto(eventos ,'Departamento' , 'Departamento')\n",
    "eventos['Departamento'] = eventos['Departamento'].str.replace('sanandres', 'archipielagodesanandresprovidenciaysantacatalina', regex=False)\n",
    "Base_2019 = pd.merge(Base_2019 , eventos , on=['Departamento' ,'Mes'] , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see 2019 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto  Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girardot</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>cundinamarca</td>\n",
       "      <td>28.700000</td>\n",
       "      <td>3150.58</td>\n",
       "      <td>121.451194</td>\n",
       "      <td>...</td>\n",
       "      <td>25988.446737</td>\n",
       "      <td>357933.270016</td>\n",
       "      <td>56527.540955</td>\n",
       "      <td>81846.745115</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>140826.671904</td>\n",
       "      <td>POINT (522004.027 475843.689)</td>\n",
       "      <td>3.1500</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>popayan</td>\n",
       "      <td>1</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7</td>\n",
       "      <td>257</td>\n",
       "      <td>31</td>\n",
       "      <td>cauca</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>3150.58</td>\n",
       "      <td>357.165903</td>\n",
       "      <td>...</td>\n",
       "      <td>31928.992000</td>\n",
       "      <td>439015.379000</td>\n",
       "      <td>46166.826000</td>\n",
       "      <td>92300.690000</td>\n",
       "      <td>140487.972000</td>\n",
       "      <td>160059.891000</td>\n",
       "      <td>POINT (321075.878 271372.118)</td>\n",
       "      <td>3.1500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maicao</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>laguajira</td>\n",
       "      <td>21.829001</td>\n",
       "      <td>3150.58</td>\n",
       "      <td>88.008349</td>\n",
       "      <td>...</td>\n",
       "      <td>26593.785064</td>\n",
       "      <td>385184.040015</td>\n",
       "      <td>51688.611118</td>\n",
       "      <td>94016.628038</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>167410.817311</td>\n",
       "      <td>POINT (801350.843 1259186.753)</td>\n",
       "      <td>3.1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fusagasuga</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>cundinamarca</td>\n",
       "      <td>21.829001</td>\n",
       "      <td>3150.58</td>\n",
       "      <td>148.135521</td>\n",
       "      <td>...</td>\n",
       "      <td>27638.508499</td>\n",
       "      <td>386477.528213</td>\n",
       "      <td>64397.503747</td>\n",
       "      <td>84766.242979</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>171105.701543</td>\n",
       "      <td>POINT (570814.377 480314.274)</td>\n",
       "      <td>3.1500</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barranquilla</td>\n",
       "      <td>1</td>\n",
       "      <td>4487.0</td>\n",
       "      <td>25</td>\n",
       "      <td>879</td>\n",
       "      <td>72</td>\n",
       "      <td>atlantico</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>3150.58</td>\n",
       "      <td>2365.517791</td>\n",
       "      <td>...</td>\n",
       "      <td>32911.341000</td>\n",
       "      <td>416462.359000</td>\n",
       "      <td>85596.957000</td>\n",
       "      <td>77403.016000</td>\n",
       "      <td>107659.272000</td>\n",
       "      <td>145803.114000</td>\n",
       "      <td>POINT (521642.463 1214140.036)</td>\n",
       "      <td>3.1500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>turbaco</td>\n",
       "      <td>12</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>21.529886</td>\n",
       "      <td>3364.24</td>\n",
       "      <td>68.413769</td>\n",
       "      <td>...</td>\n",
       "      <td>28376.075240</td>\n",
       "      <td>385025.774591</td>\n",
       "      <td>58880.717603</td>\n",
       "      <td>78301.672584</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>152516.873607</td>\n",
       "      <td>POINT (463511.39 1144129.202)</td>\n",
       "      <td>3.8043</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>magangue</td>\n",
       "      <td>12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>21.529886</td>\n",
       "      <td>3364.24</td>\n",
       "      <td>132.044220</td>\n",
       "      <td>...</td>\n",
       "      <td>27183.813357</td>\n",
       "      <td>371202.047827</td>\n",
       "      <td>60773.505977</td>\n",
       "      <td>83144.027852</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>128300.836444</td>\n",
       "      <td>POINT (525625.153 1022500.055)</td>\n",
       "      <td>3.8043</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>uribia</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>laguajira</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>3364.24</td>\n",
       "      <td>62.083220</td>\n",
       "      <td>...</td>\n",
       "      <td>26664.730192</td>\n",
       "      <td>386623.688304</td>\n",
       "      <td>49480.398965</td>\n",
       "      <td>94124.673761</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>172041.263678</td>\n",
       "      <td>POINT (826814.742 1319110.428)</td>\n",
       "      <td>3.8043</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>palermo</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>huila</td>\n",
       "      <td>21.529886</td>\n",
       "      <td>3364.24</td>\n",
       "      <td>57.558129</td>\n",
       "      <td>...</td>\n",
       "      <td>23492.093992</td>\n",
       "      <td>319443.333857</td>\n",
       "      <td>40252.245211</td>\n",
       "      <td>69580.193582</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>91297.020176</td>\n",
       "      <td>POINT (451378.305 319631.823)</td>\n",
       "      <td>3.8043</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>mitu</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>vaupes</td>\n",
       "      <td>21.529886</td>\n",
       "      <td>3364.24</td>\n",
       "      <td>16.787675</td>\n",
       "      <td>...</td>\n",
       "      <td>29205.860391</td>\n",
       "      <td>413695.445141</td>\n",
       "      <td>42426.195624</td>\n",
       "      <td>82576.009628</td>\n",
       "      <td>91748.852583</td>\n",
       "      <td>233438.097609</td>\n",
       "      <td>POINT (1037614.182 132922.769)</td>\n",
       "      <td>3.8043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ciudad  Mes  Extranjeros no Residentes  Homicidios  Hurtos  \\\n",
       "0        girardot    1                       27.0           3      58   \n",
       "1         popayan    1                      320.0           7     257   \n",
       "2          maicao    1                       40.0           7      35   \n",
       "3      fusagasuga    1                       58.0           1      31   \n",
       "4    barranquilla    1                     4487.0          25     879   \n",
       "..            ...  ...                        ...         ...     ...   \n",
       "967       turbaco   12                       33.0           5      40   \n",
       "968      magangue   12                       15.0           2      18   \n",
       "969        uribia   12                        0.0           0       4   \n",
       "970       palermo   12                        1.0           2       5   \n",
       "971          mitu   12                        0.0           0       5   \n",
       "\n",
       "     Delitos Sexuales  Departamento  Temperatura    Dolar  Pib Ponderado  ...  \\\n",
       "0                   8  cundinamarca    28.700000  3150.58     121.451194  ...   \n",
       "1                  31         cauca    16.300000  3150.58     357.165903  ...   \n",
       "2                   3     laguajira    21.829001  3150.58      88.008349  ...   \n",
       "3                  12  cundinamarca    21.829001  3150.58     148.135521  ...   \n",
       "4                  72     atlantico    25.600000  3150.58    2365.517791  ...   \n",
       "..                ...           ...          ...      ...            ...  ...   \n",
       "967                 6       bolivar    21.529886  3364.24      68.413769  ...   \n",
       "968                 6       bolivar    21.529886  3364.24     132.044220  ...   \n",
       "969                 0     laguajira    29.900000  3364.24      62.083220  ...   \n",
       "970                 3         huila    21.529886  3364.24      57.558129  ...   \n",
       "971                 3        vaupes    21.529886  3364.24      16.787675  ...   \n",
       "\n",
       "     Otros Gastos  Diario  Gasto Promedio Viaje  Gasto  Alojamiento Viaje  \\\n",
       "0            25988.446737         357933.270016              56527.540955   \n",
       "1            31928.992000         439015.379000              46166.826000   \n",
       "2            26593.785064         385184.040015              51688.611118   \n",
       "3            27638.508499         386477.528213              64397.503747   \n",
       "4            32911.341000         416462.359000              85596.957000   \n",
       "..                    ...                   ...                       ...   \n",
       "967          28376.075240         385025.774591              58880.717603   \n",
       "968          27183.813357         371202.047827              60773.505977   \n",
       "969          26664.730192         386623.688304              49480.398965   \n",
       "970          23492.093992         319443.333857              40252.245211   \n",
       "971          29205.860391         413695.445141              42426.195624   \n",
       "\n",
       "     Gasto Transporte Viaje  Gasto alimetos Viaje  Otros Gastos Viaje  \\\n",
       "0              81846.745115          91748.852583       140826.671904   \n",
       "1              92300.690000         140487.972000       160059.891000   \n",
       "2              94016.628038          91748.852583       167410.817311   \n",
       "3              84766.242979          91748.852583       171105.701543   \n",
       "4              77403.016000         107659.272000       145803.114000   \n",
       "..                      ...                   ...                 ...   \n",
       "967            78301.672584          91748.852583       152516.873607   \n",
       "968            83144.027852          91748.852583       128300.836444   \n",
       "969            94124.673761          91748.852583       172041.263678   \n",
       "970            69580.193582          91748.852583        91297.020176   \n",
       "971            82576.009628          91748.852583       233438.097609   \n",
       "\n",
       "                           geometry  Inflacion  carreteras_cercanas  Eventos  \n",
       "0     POINT (522004.027 475843.689)     3.1500                    9      1.0  \n",
       "1     POINT (321075.878 271372.118)     3.1500                    8      0.0  \n",
       "2    POINT (801350.843 1259186.753)     3.1500                    2      0.0  \n",
       "3     POINT (570814.377 480314.274)     3.1500                    3      1.0  \n",
       "4    POINT (521642.463 1214140.036)     3.1500                   10      0.0  \n",
       "..                              ...        ...                  ...      ...  \n",
       "967   POINT (463511.39 1144129.202)     3.8043                    4      0.0  \n",
       "968  POINT (525625.153 1022500.055)     3.8043                    2      0.0  \n",
       "969  POINT (826814.742 1319110.428)     3.8043                    0      1.0  \n",
       "970   POINT (451378.305 319631.823)     3.8043                    2      0.0  \n",
       "971  POINT (1037614.182 132922.769)     3.8043                    0      0.0  \n",
       "\n",
       "[972 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto  Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [Ciudad, Mes, Extranjeros no Residentes, Homicidios, Hurtos, Delitos Sexuales, Departamento, Temperatura, Dolar, Pib Ponderado, Entradas Extranjeros Zona, distancia_ponderada_km, importancia accesos, Establecimientos, HABITACIONES, CAMAS, distancia_ponderada_TOP, Proxy_Pobreza, Gasto Promedio Diario, Gasto Alojamiento Diario, Gasto Transporte  Diario, Gasto alimetos  Diario, Otros Gastos  Diario, Gasto Promedio Viaje, Gasto  Alojamiento Viaje, Gasto Transporte Viaje, Gasto alimetos Viaje, Otros Gastos Viaje, geometry, Inflacion, carreteras_cercanas, Eventos]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2019[Base_2019.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicio proceso\n",
    "df= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Visitantes_No_Residentes.csv')\n",
    "df1 = df[df[\"Año\"] == 2021]\n",
    "df1= arreglar_texto(df1 , 'Ciudad' , 'Ciudad')\n",
    "Homicidios= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\homicidios_9.xls').dropna()\n",
    "Homicidos1 = bases_crimenes(Homicidios , 'FECHA ' , 'CANTIDAD ' , 'Homicidios')\n",
    "Hurto= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\hurto_a_personas_9.xlsx').dropna()\n",
    "Hurto1 = bases_crimenes(Hurto , 'FECHA  HECHO ' , 'CANTIDAD ' , 'Hurtos')\n",
    "sexuales= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\delitos_sexuales_9.xls').dropna()\n",
    "sexuales1 = bases_crimenes(sexuales , 'FECHA ' , 'CANTIDAD ' , 'Delitos Sexuales')\n",
    "ciudades= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\ciudades.csv')\n",
    "ciudades = arreglar_texto(ciudades, 'city' , \"Ciudad\")\n",
    "ciudades['admin_name'] = ciudades['admin_name'].astype(str)\n",
    "ciudades.at[68, 'admin_name'] = 'Atlantico'\n",
    "Total_18= completar_meses(df1 , 'Ciudad' , 'Mes' ,'Extranjeros no Residentes' , 1)\n",
    "Total_18 = pd.merge(Total_18, Homicidos1[['Ciudad', 'Homicidios' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, Hurto1[['Ciudad', 'Hurtos' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, sexuales1[['Ciudad', 'Delitos Sexuales' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18['Homicidios'] = Total_18['Homicidios'].fillna(0)\n",
    "Total_18['Hurtos'] = Total_18['Hurtos'].fillna(0)\n",
    "Total_18['Delitos Sexuales'] = Total_18['Delitos Sexuales'].fillna(0)\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('bogotadc', 'bogota', regex=False)\n",
    "\n",
    "#Seleccionar Ciudades que vamos a trabajar\n",
    "ciudades1= set(ciudades['Ciudad'])\n",
    "ciudades2= set(Total_18['Ciudad'])\n",
    "grandes_ciudades=list(ciudades1.intersection(ciudades2))\n",
    "l=['bogota' , 'tumaco']\n",
    "grandes_ciudades = grandes_ciudades + l\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "for i in Total_18['Ciudad']:\n",
    "    indice = Total_18[Total_18['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Total_18 = Total_18.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Poner Ubicaciones\n",
    "ciudades['geometry'] = ciudades.apply(lambda i: Point(i['lng'], i['lat']), axis=1)\n",
    "ciudades_geometry= gpd.GeoDataFrame(ciudades, geometry='geometry')\n",
    "Total_18_Geometry= pd.merge(Total_18, ciudades_geometry[['Ciudad', 'geometry']], on='Ciudad' , how='left')\n",
    "Total_18_Geometry= gpd.GeoDataFrame(Total_18_Geometry, geometry='geometry')\n",
    "\n",
    "# Poner departamentos\n",
    "Departamentos = gpd.read_file(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Colombia.json\")\n",
    "Departamentos = arreglar_texto(Departamentos, 'NOMBRE_DPT' , \"Departamento\")\n",
    "Departamentos[\"Departamento\"] = Departamentos[\"Departamento\"].str.replace('santafedebogota', 'bogotadc', regex=False)\n",
    "\n",
    "if Total_18_Geometry.crs is None:\n",
    "    Total_18_Geometry = Total_18_Geometry.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Total_18_Geometry = gpd.sjoin_nearest(Total_18_Geometry,  Departamentos, how='left', distance_col='distancia').drop(['AREA' , 'PERIMETER' , 'HECTARES' , 'DPTO','index_right' , 'distancia'] , axis=1)\n",
    "Total_18_Geometry\n",
    "Total_18_Geometry[Total_18_Geometry.isnull().any(axis=1)]\n",
    "\n",
    "#Agregar Clima\n",
    "clima_2018 = clima[clima['FechaObservacion'].dt.year == 2021]\n",
    "clima_2018 = arreglar_texto(clima_2018 , 'Municipio', 'Ciudad')\n",
    "clima_2018= completar_meses(clima_2018 , 'Ciudad' , 'Mes' ,'ValorObservado' , 0)\n",
    "Total_18_Clima= pd.merge(Total_18_Geometry, clima_2018[['Ciudad', 'ValorObservado' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18_Clima = Total_18_Clima.rename(columns={'ValorObservado': 'Temperatura'})\n",
    "\n",
    "#Krigging para el clima \n",
    "df_kriging = meses_a_numeros(Total_18_Clima , 'Mes')\n",
    "df_kriging.set_crs(epsg=4326, inplace=True)\n",
    "df_kriging=df_kriging.to_crs(epsg=32618)  \n",
    "\n",
    "meses_krig = df_kriging['Mes'].unique()\n",
    "\n",
    "for i in meses_krig:\n",
    "    print('Procesando Mes:' ,i)\n",
    "    \n",
    "    df_kriging_mes = df_kriging[df_kriging['Mes'] == i] # Vamos a realizar el kriging por mes\n",
    "    df_kriging_known = df_kriging_mes.dropna(subset=['Temperatura']) # Los datos para los que tenemos temperatura\n",
    "    df_kriging_missing = df_kriging_mes[df_kriging_mes ['Temperatura'].isna()] # Los datos para los NO que tenemos temperatura (Variable a predecir)\n",
    "    \n",
    "    if df_kriging_missing.empty:\n",
    "        print('No hay datos faltantes en el mes ' , i) # Si algun mes esta completo para todas las ciudades, no hacer nada \n",
    "        continue\n",
    "    \n",
    "    # Nuestras variables para predecir\n",
    "    x_known = df_kriging_known.geometry.x.values\n",
    "    y_known = df_kriging_known.geometry.y.values\n",
    "    z_known = df_kriging_known['Temperatura'].values\n",
    "    \n",
    "    # Nuestros datos a predecir\n",
    "    x_missing = df_kriging_missing.geometry.x.values\n",
    "    y_missing = df_kriging_missing.geometry.y.values\n",
    "    \n",
    "    # Crear el modelo \n",
    "    Krigg = OrdinaryKriging(\n",
    "        x_known, y_known, z_known,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False)\n",
    "    \n",
    "    # Realizar predicciones con el krigging\n",
    "    z_pred, ss = Krigg.execute('points', x_missing, y_missing)\n",
    "    \n",
    "    # Introducir en el DF los valores\n",
    "    df_kriging.loc[df_kriging_missing.index, 'Temperatura'] = z_pred\n",
    "\n",
    "#Agregar precio dolar\n",
    "Dolar = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Dolar.xlsx')\n",
    "Dolar['Fecha'] = pd.to_datetime(Dolar['Fecha'], errors='coerce')\n",
    "Dolar.set_index('Fecha', inplace=True)\n",
    "Dolar = Dolar.resample('M').median()\n",
    "Dolar = Dolar.reset_index()\n",
    "Dolar_2018=Dolar[Dolar['Fecha'].dt.year == 2021]\n",
    "Dolar_2018['Mes'] = range(1, 13)\n",
    "Base_2018=pd.merge(df_kriging, Dolar_2018, on= 'Mes', how='right').drop('Fecha' , axis=1)\n",
    "Base_2018\n",
    "\n",
    "#Interpolar PIB mensual\n",
    "\n",
    "PIB = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\PIB - Miles de millones de pesos  - 2021p.xlsx')\n",
    "PIB= arreglar_texto(PIB, 'DEPARTAMENTO' , 'Departamento')\n",
    "PIB['VALOR (unidades)'] = PIB['VALOR (unidades)'].str.replace(',', '.')\n",
    "PIB['VALOR (unidades)'] = pd.to_numeric(PIB['VALOR (unidades)'], errors='coerce')\n",
    "# Usaremos el metodo de LOESS para descomponer el PIB mensualmente \n",
    "meses_loees= np.arange(1, 13)\n",
    "tendencia_mensual_inflacion = [1.6 ,1.56, 1.51 , 1.95 , 3.3 , 3.63 , 3.97 , 4.44 , 4.51 , 4.58 , 5.26 , 5.62] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual_inflacion) for valor in tendencia_mensual_inflacion]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "# La idea es crear algun tipo de ruido sobre nuestro patron, para asi tratar de simular efectos reales economicos.\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) #  Asegurarnos que todos las fulctuaciones sean positivas. \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "\n",
    "def descomponer_pib_loess(pib_anual, patron):\n",
    "    def asignar_pib_mensual(k, patron):\n",
    "        pib_mensual = patron * k['VALOR (unidades)']\n",
    "        return pib_mensual\n",
    "\n",
    "    df_mensual = pd.DataFrame()\n",
    "    \n",
    "    for i, k in pib_anual.iterrows():\n",
    "        pib_mensual = asignar_pib_mensual(k, patron)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Departamento': k['Departamento'],\n",
    "            'Mes': np.arange(1, 13),\n",
    "            'PIB_Mensual': pib_mensual\n",
    "        })\n",
    "        \n",
    "        df_mensual = pd.concat([df_mensual, df_temp], ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "pib_mensual = descomponer_pib_loess(PIB, patron_smooth)\n",
    "importancia_pesos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\importancia-municipal.xlsx')\n",
    "\n",
    "#Dado que encontrar una serie completa desde 2018 hasta 2024 de el valor del PIB por ciudad no es facil, primero usaremos la descomposicon por mes que hicimos departamental y la ponderaremos \n",
    "#por la importancia de cada ciudad en el departamento para encontrar un aproximando significativo. pdta= la base que nos pasaste profe no tenia todos los anos por eso hacemos esta aproximacion\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Municipio / Distrito' , 'Ciudad')\n",
    "importancia_pesos['Departamento'] = importancia_pesos['Departamento'].astype(str)\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Departamento' , 'Departamento')\n",
    "\n",
    "# Dejar solo las ciudades que estamos trabajando.\n",
    "for i in importancia_pesos['Ciudad']:\n",
    "    indice = importancia_pesos[importancia_pesos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        importancia_pesos = importancia_pesos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "importancia_pesos_mensual = importancia_pesos.loc[importancia_pesos.index.repeat(12)].reset_index(drop=True)\n",
    "importancia_pesos_mensual['Mes'] = (importancia_pesos_mensual.index % 12) + 1\n",
    "pib_pesos_ciudades1 = pd.merge(importancia_pesos_mensual, pib_mensual, on=['Departamento', 'Mes'], how='left')\n",
    "pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] /100\n",
    "pib_pesos_ciudades1['Pib Ponderado'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] * pib_pesos_ciudades1['PIB_Mensual']\n",
    "fusion_left = pd.merge(Base_2018, pib_pesos_ciudades1[['Pib Ponderado' , 'Ciudad', 'Mes']], on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Agregar puntos de llegadas internacionales\n",
    "entradas = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Entradas_de_extranjeros_a_Colombia_20241006.csv')\n",
    "entradas_2018= entradas[entradas['Año']==2021]\n",
    "entradas_2018 = entradas_2018[entradas_2018['Latitud - Longitud'] != 'No Aplica,No Aplica']\n",
    "entradas_2018 =traducir(entradas_2018 , 'Mes')\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "entradas_2018 =completar_meses(entradas_2018, 'Latitud - Longitud' , 'Mes' , 'Total' ,1 )\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "\n",
    "entradas_geometry = convertir_ubicacion(entradas_2018 , 'Latitud - Longitud')\n",
    "Entradas = gpd.GeoDataFrame(entradas_geometry, geometry='geometry')\n",
    "\n",
    "if Entradas.crs is None:\n",
    "    Entradas = Entradas.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Entradas = gpd.sjoin_nearest(Entradas,  Departamentos, how='left', distance_col='distancia').drop(['index_right' , 'DPTO' , 'AREA' , 'PERIMETER' , 'HECTARES' ,'distancia'] , axis=1)\n",
    "Entradas_Departamentos = Entradas.groupby(['Mes', 'Departamento'])['Total'].sum().reset_index()\n",
    "final = pd.merge(fusion_left, Entradas_Departamentos, on=['Departamento', 'Mes'], how='left').rename(columns={'Total': 'Entradas Extranjeros Zona'})\n",
    "final['Entradas Extranjeros Zona'] = final['Entradas Extranjeros Zona'].fillna(0)\n",
    "final[final['Ciudad'] == 'medellin']\n",
    "\n",
    "#Distancias desde los puntos de llegadas internacionales ponderadas \n",
    "for i in ciudades['Ciudad']:\n",
    "    indice = ciudades[ciudades['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_unico = ciudades.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unico = ciudades_unico.iloc[:, [0, -1]]\n",
    "ciudades_unico= gpd.GeoDataFrame(ciudades_unico, geometry='geometry')\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if Migracion_Unico.crs is None:\n",
    "    Migracion_Unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de Migracion_Unico: {Migracion_Unico.crs}\")\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "Migracion_Unico = Migracion_Unico.to_crs(epsg=32618)\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "Migracion_Unico['key'] = 1\n",
    "\n",
    "Distancia_combinado = pd.merge(ciudades_unico, Migracion_Unico, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "Distancia_combinado['distancia_km'] = Distancia_combinado.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_combinado['distancia_ponderada'] = Distancia_combinado['distancia_km'] * Distancia_combinado['Total']\n",
    "Distancia_ponderado = Distancia_combinado.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_migrantes=('Total', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "Distancia_ponderado['distancia_ponderada_km'] = Distancia_ponderado['suma_ponderada'] / Distancia_ponderado['suma_migrantes']\n",
    "Distancia_ponderado_final = Distancia_ponderado[['Ciudad' , 'distancia_ponderada_km']]\n",
    "\n",
    "Distancia_ciudades = ciudades_unico.merge(Distancia_ponderado_final, on='Ciudad')\n",
    "final1 = pd.merge(final, Distancia_ciudades, on='Ciudad', how='left').drop(['geometry_y' , 'key'] , axis=1)\n",
    "\n",
    "# Score importancia puntos entrada\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "columnas = ['geometry' , 'Departamento' ,'Total' ]\n",
    "Migracion_Unico_Dept = gpd.sjoin_nearest(Migracion_Unico, Departamentos, how='left', distance_col='distancia')[columnas]\n",
    "Total_Migracion = Migracion_Unico_Dept.groupby('Departamento').agg(\n",
    "    puntos=('Departamento', 'size'),  \n",
    "    total_personas=('Total', 'sum')  \n",
    ").reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "Total_Migracion[['puntos_norm', 'total_norm']] = scaler.fit_transform(Total_Migracion[['puntos', 'total_personas']])\n",
    "Total_Migracion['importancia accesos'] = 0.3 * Total_Migracion['puntos_norm'] + 0.7 * Total_Migracion['total_norm'] # Asumimos que es mas importante cuanta gente llega a que tantos puntos hay.\n",
    "final1 = pd.merge(final1, Total_Migracion, on='Departamento', how='left').drop(['puntos' , 'total_personas' , 'puntos_norm' , 'total_norm'] , axis=1)\n",
    "final1['importancia accesos'] = final1['importancia accesos'].fillna(0)\n",
    "\n",
    "\n",
    "#Numero establecimientos de turismo, camas y habitaciones para turistas.\n",
    "hoteles = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Hist_rico_Registro_Nacional_de_Turismo_-_RNT_20241007.csv')\n",
    "establecimientos_2018 = hoteles[hoteles['AÑO']==2021]\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('PUERTO INIRIDA', 'Inirida', regex=False)\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('BUGA', 'guadalajaradebuga', regex=False)\n",
    "\n",
    "Establecimientos = establecimientos_2018.groupby('NOMBRE-MUNI').agg({'CATEGORIA': 'count','HABITACIONES': 'sum', 'CAMAS': 'sum'}).reset_index().rename(columns={'CATEGORIA': 'Establecimientos'})\n",
    "Establecimientos = arreglar_texto(Establecimientos, 'NOMBRE-MUNI' , 'Municipios')\n",
    "for i in Establecimientos['Municipios']:\n",
    "    indice = Establecimientos[Establecimientos['Municipios'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Establecimientos = Establecimientos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "Establecimientos=Establecimientos.rename(columns={'Municipios': 'Ciudad'})\n",
    "meses_loees = np.arange(1, 13)\n",
    "tendencia_mensual = [42,43,47,40,41,42,43,45,46,47,50,54] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual) for valor in tendencia_mensual]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "def descomponer_variables_loess(df_anual, patron, variables):\n",
    "    def asignar_valores_mensuales(fila, patron, variables):\n",
    "        valores_mensuales = {}\n",
    "        for i in variables:\n",
    "            valores_mensuales[i] = patron * fila[i]\n",
    "        return valores_mensuales\n",
    "\n",
    "    data_mensual = []\n",
    "    for i, fila in df_anual.iterrows():\n",
    "        valores_mensuales = asignar_valores_mensuales(fila, patron, variables)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Ciudad': fila['Ciudad'],\n",
    "            'Mes': np.arange(1, 13)\n",
    "        })\n",
    "        \n",
    "        for k in variables:\n",
    "            df_temp[k] = valores_mensuales[k]\n",
    "        \n",
    "        data_mensual.append(df_temp)\n",
    "    \n",
    "    df_mensual = pd.concat(data_mensual, ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "Establecimientos_mensual = descomponer_variables_loess(Establecimientos, patron_smooth , ['Establecimientos' , 'HABITACIONES' , 'CAMAS'])\n",
    "final2 = pd.merge(final1, Establecimientos_mensual, on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Distancias al TOP de colombia \n",
    "df_TopColombia = pd.DataFrame.from_dict(Top_Colombia, orient='index', columns=['coordinates','Reviews', 'rating', 'eliminar'])\n",
    "df_TopColombia = df_TopColombia.reset_index().rename(columns={'index': 'lugar'}).drop('eliminar' , axis=1)\n",
    "df_TopColombia['geometry'] = df_TopColombia['coordinates'].apply(lambda x: Point(x[1], x[0]))\n",
    "df_TopColombia_gdp = gpd.GeoDataFrame(df_TopColombia, geometry='geometry').drop('coordinates' , axis=1)\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if df_TopColombia_gdp.crs is None:\n",
    "    df_TopColombia_gdp.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de df_TopColombia_gdp: {df_TopColombia_gdp.crs}\")\n",
    "\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "df_TopColombia_gdp = df_TopColombia_gdp.to_crs(epsg=32618)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "df_TopColombia_gdp['key'] = 1\n",
    "\n",
    "Distancia_Top = pd.merge(ciudades_unico, df_TopColombia_gdp, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "w_reviews = 0.6 # Vamos a asumir que las reviews tienen mas peso que la calificacion del lugar \n",
    "w_rating = 0.4\n",
    "\n",
    "Distancia_Top['distancia_km'] = Distancia_Top.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_Top[['distancia_km','Reviews', 'rating']] = scaler.fit_transform(\n",
    "    Distancia_Top[['distancia_km','Reviews', 'rating']]\n",
    ") # Normalizamos las variables para calcular una distancia ponderada con las mismas escalas\n",
    "\n",
    "Distancia_Top['distancia_ponderada'] = (Distancia_Top['distancia_km']) + ( w_reviews* Distancia_Top['Reviews']) + ( w_rating* Distancia_Top['rating'])\n",
    "\n",
    "Distancia_Ponderado_Top = Distancia_Top.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_reviews=('Reviews', 'sum'),\n",
    "    suma_rating=('rating', 'sum')).reset_index()\n",
    "\n",
    "Distancia_Ponderado_Top['distancia_ponderada_TOP'] = Distancia_Ponderado_Top['suma_ponderada'] / (Distancia_Ponderado_Top['suma_reviews']+Distancia_Ponderado_Top['suma_rating'])\n",
    "Distancia_Ponderado_Top_final = Distancia_Ponderado_Top[['Ciudad' , 'distancia_ponderada_TOP']]\n",
    "\n",
    "Distancia_Top = ciudades_unico.merge(Distancia_Ponderado_Top_final, on='Ciudad')\n",
    "final3 = pd.merge(final2, Distancia_Top, on='Ciudad', how='left').drop(['geometry_x' , 'key'] , axis=1)\n",
    "\n",
    "# Pobreza con proxy\n",
    "ciudades_poblacion = ciudades[['Ciudad' , 'population']]\n",
    "for i in ciudades_poblacion['Ciudad']:\n",
    "    indice = ciudades_poblacion[ciudades_poblacion['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_poblacion = ciudades_poblacion.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final4 = pd.merge(final3, ciudades_poblacion, on='Ciudad', how='left')\n",
    "final4['Proxy_Pobreza'] = final4['Pib Ponderado'] / final4['population']\n",
    "final4\n",
    "\n",
    "#Gasto promedio por dia de un turista\n",
    "gastos_diarios = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\Gasto Promedio Diario 2021.xlsx')\n",
    "gastos_diarios = arreglar_texto(gastos_diarios , 'Ciudad', 'Ciudad')\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_diarios = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "gastos_diarios_Nan = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_diarios_Nan = gpd.GeoDataFrame(pd.merge(gastos_diarios_Nan, ciudades_geometry, on='Ciudad', how='left').drop('geometry_x' , axis=1) , geometry='geometry')\n",
    "gastos_diarios_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_diarios_Nan=gastos_diarios_Nan.to_crs(epsg=32618)  \n",
    "variables = [i for i in gastos_diarios_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_diarios_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_diarios_Nan[gastos_diarios_Nan[variables].isnull().any(axis=1)]\n",
    "\n",
    "def kriging(df_con_info, variable, grid_size=100):\n",
    "    coords = np.array(list(zip(df_con_info.geometry.x, df_con_info.geometry.y)))\n",
    "    valores = df_con_info[variable].values\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = gastos_diarios_Nan.total_bounds\n",
    "    gridx = np.linspace(min_x, max_x, grid_size)\n",
    "    gridy = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    Krigg_O = OrdinaryKriging(\n",
    "        coords[:,0], coords[:,1], valores,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False\n",
    "    )\n",
    "    \n",
    "    z1, ss1 = Krigg_O.execute('grid', gridx, gridy)\n",
    "    \n",
    "    return Krigg_O, gridx, gridy, z1\n",
    "\n",
    "def estimar(Krigg, puntos):\n",
    "    x = puntos.geometry.x.values\n",
    "    y = puntos.geometry.y.values\n",
    "    estimados, ss = Krigg.execute('points', x, y)\n",
    "    return estimados\n",
    "\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual['Mes'] = (gastos_krigg_mensual.index % 12) + 1\n",
    "final5 = pd.merge(final4, gastos_krigg_mensual, on=['Mes', 'Ciudad'], how='left').drop(['geometry_x','population'] , axis=1)\n",
    "\n",
    "# Gastos de todo el viaje \n",
    "gastos_viaje = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2021\\\\Gasto Pormedio Viaje.xlsx')\n",
    "gastos_viaje = arreglar_texto(gastos_viaje , 'Ciudad', 'Ciudad')\n",
    "\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_viaje = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='left')\n",
    "gastos_viaje_Nan = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_viaje_Nan = gpd.GeoDataFrame(pd.merge(gastos_viaje_Nan, ciudades_geometry, on='Ciudad', how='left') , geometry='geometry')\n",
    "gastos_viaje_Nan = gastos_viaje_Nan.drop('geometry_x' , axis=1)\n",
    "\n",
    "gastos_viaje_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_viaje_Nan=gastos_viaje_Nan.to_crs(epsg=32618) \n",
    "variables = [i for i in gastos_viaje_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_viaje_Nan.dropna()\n",
    "gastos_con_Nan = gastos_viaje_Nan[gastos_viaje_Nan[variables].isnull().any(axis=1)]\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual_viaje = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual_viaje['Mes'] = (gastos_krigg_mensual_viaje.index % 12) + 1\n",
    "gastos_krigg_mensual_viaje\n",
    "Base_2021 = pd.merge(final5, gastos_krigg_mensual_viaje, on=['Mes', 'Ciudad'], how='left').drop('geometry_y' , axis=1)\n",
    "\n",
    "# Agregar inflacion\n",
    "inflacion = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Inflacion.xlsx')\n",
    "inflacion['Fecha'] = pd.to_datetime(inflacion['Fecha'])\n",
    "inflacion = inflacion[inflacion['Fecha'].dt.year == 2021].rename(columns={'Fecha':'Mes'})\n",
    "inflacion['Mes'] = inflacion['Mes'].dt.month\n",
    "Base_2021  = pd.merge(Base_2021 , inflacion, on='Mes', how='left')\n",
    "\n",
    "#Agregar Vias\n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2021 = pd.merge(Base_2021 , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "# Agregar Eventos\n",
    "eventos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Eventos Turisticos\\\\Eventos 2021.xlsx').fillna(0)\n",
    "eventos = arreglar_texto(eventos ,'Departamento' , 'Departamento')\n",
    "eventos['Departamento'] = eventos['Departamento'].str.replace('sanandres', 'archipielagodesanandresprovidenciaysantacatalina', regex=False)\n",
    "Base_2021 = pd.merge(Base_2021 , eventos , on=['Departamento' ,'Mes'] , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see 2021 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte  Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos  Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cienaga</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>magdalena</td>\n",
       "      <td>22.672996</td>\n",
       "      <td>3478.11</td>\n",
       "      <td>55.531683</td>\n",
       "      <td>...</td>\n",
       "      <td>38309.988310</td>\n",
       "      <td>509576.010704</td>\n",
       "      <td>94227.742607</td>\n",
       "      <td>114452.575274</td>\n",
       "      <td>126513.416828</td>\n",
       "      <td>198360.186342</td>\n",
       "      <td>POINT (581933.159 1216844.759)</td>\n",
       "      <td>1.59721</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leticia</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>3478.11</td>\n",
       "      <td>23.000426</td>\n",
       "      <td>...</td>\n",
       "      <td>38349.247334</td>\n",
       "      <td>642297.592149</td>\n",
       "      <td>155336.389361</td>\n",
       "      <td>101229.841007</td>\n",
       "      <td>138644.470640</td>\n",
       "      <td>269015.023058</td>\n",
       "      <td>POINT (1063012.099 -467914.527)</td>\n",
       "      <td>1.59721</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bello</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>7</td>\n",
       "      <td>158</td>\n",
       "      <td>22</td>\n",
       "      <td>antioquia</td>\n",
       "      <td>21.064175</td>\n",
       "      <td>3478.11</td>\n",
       "      <td>258.040403</td>\n",
       "      <td>...</td>\n",
       "      <td>22500.262354</td>\n",
       "      <td>409266.901336</td>\n",
       "      <td>69171.990677</td>\n",
       "      <td>72707.583734</td>\n",
       "      <td>156302.284798</td>\n",
       "      <td>117579.038487</td>\n",
       "      <td>POINT (437321.773 700082.696)</td>\n",
       "      <td>1.59721</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barranquilla</td>\n",
       "      <td>1</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>23</td>\n",
       "      <td>764</td>\n",
       "      <td>58</td>\n",
       "      <td>atlantico</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>3478.11</td>\n",
       "      <td>1411.317456</td>\n",
       "      <td>...</td>\n",
       "      <td>46960.260000</td>\n",
       "      <td>797692.580000</td>\n",
       "      <td>161345.770000</td>\n",
       "      <td>143819.680000</td>\n",
       "      <td>243722.200000</td>\n",
       "      <td>248804.920000</td>\n",
       "      <td>POINT (521642.463 1214140.036)</td>\n",
       "      <td>1.59721</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartagena</td>\n",
       "      <td>1</td>\n",
       "      <td>7563.0</td>\n",
       "      <td>20</td>\n",
       "      <td>439</td>\n",
       "      <td>50</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>22.497558</td>\n",
       "      <td>3478.11</td>\n",
       "      <td>1160.904575</td>\n",
       "      <td>...</td>\n",
       "      <td>18030.146000</td>\n",
       "      <td>390658.100000</td>\n",
       "      <td>40006.560000</td>\n",
       "      <td>95969.190000</td>\n",
       "      <td>148800.860000</td>\n",
       "      <td>105881.480000</td>\n",
       "      <td>POINT (445269.937 1149681.547)</td>\n",
       "      <td>1.59721</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>inirida</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>guainia</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>3981.16</td>\n",
       "      <td>47.053040</td>\n",
       "      <td>...</td>\n",
       "      <td>37186.376345</td>\n",
       "      <td>667988.742264</td>\n",
       "      <td>163647.571594</td>\n",
       "      <td>106103.938719</td>\n",
       "      <td>154151.458844</td>\n",
       "      <td>256585.689974</td>\n",
       "      <td>POINT (1287613.509 430529.596)</td>\n",
       "      <td>5.62267</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>puertocarreno</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>vichada</td>\n",
       "      <td>21.652402</td>\n",
       "      <td>3981.16</td>\n",
       "      <td>27.312103</td>\n",
       "      <td>...</td>\n",
       "      <td>36986.929789</td>\n",
       "      <td>674590.994187</td>\n",
       "      <td>164518.617859</td>\n",
       "      <td>105557.797928</td>\n",
       "      <td>157322.460242</td>\n",
       "      <td>258695.331397</td>\n",
       "      <td>POINT (1333897.888 690164.666)</td>\n",
       "      <td>5.62267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>mitu</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>vaupes</td>\n",
       "      <td>21.652402</td>\n",
       "      <td>3981.16</td>\n",
       "      <td>27.794043</td>\n",
       "      <td>...</td>\n",
       "      <td>31866.679879</td>\n",
       "      <td>580733.566611</td>\n",
       "      <td>133979.208194</td>\n",
       "      <td>109251.027751</td>\n",
       "      <td>135601.667940</td>\n",
       "      <td>215172.536627</td>\n",
       "      <td>POINT (1037614.182 132922.769)</td>\n",
       "      <td>5.62267</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>palermo</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>huila</td>\n",
       "      <td>21.652402</td>\n",
       "      <td>3981.16</td>\n",
       "      <td>99.608632</td>\n",
       "      <td>...</td>\n",
       "      <td>23004.827084</td>\n",
       "      <td>424225.932035</td>\n",
       "      <td>87017.473048</td>\n",
       "      <td>90239.961293</td>\n",
       "      <td>106987.787639</td>\n",
       "      <td>120250.704847</td>\n",
       "      <td>POINT (451378.305 319631.823)</td>\n",
       "      <td>5.62267</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>lajaguadeibirico</td>\n",
       "      <td>12</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>cesar</td>\n",
       "      <td>21.652402</td>\n",
       "      <td>3981.16</td>\n",
       "      <td>613.087544</td>\n",
       "      <td>...</td>\n",
       "      <td>20474.493975</td>\n",
       "      <td>500004.084276</td>\n",
       "      <td>83747.309945</td>\n",
       "      <td>113581.149700</td>\n",
       "      <td>153175.467502</td>\n",
       "      <td>132628.940586</td>\n",
       "      <td>POINT (682924.172 1057948.201)</td>\n",
       "      <td>5.62267</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ciudad  Mes  Extranjeros no Residentes  Homicidios  Hurtos  \\\n",
       "0             cienaga    1                        9.0           9      13   \n",
       "1             leticia    1                       48.0           2       5   \n",
       "2               bello    1                      166.0           7     158   \n",
       "3        barranquilla    1                     2212.0          23     764   \n",
       "4           cartagena    1                     7563.0          20     439   \n",
       "..                ...  ...                        ...         ...     ...   \n",
       "967           inirida   12                        5.0           1       7   \n",
       "968     puertocarreno   12                       21.0           0       3   \n",
       "969              mitu   12                        1.0           0       6   \n",
       "970           palermo   12                       10.0           0       4   \n",
       "971  lajaguadeibirico   12                       38.0           0      10   \n",
       "\n",
       "     Delitos Sexuales Departamento  Temperatura    Dolar  Pib Ponderado  ...  \\\n",
       "0                   4    magdalena    22.672996  3478.11      55.531683  ...   \n",
       "1                   5     amazonas    24.700000  3478.11      23.000426  ...   \n",
       "2                  22    antioquia    21.064175  3478.11     258.040403  ...   \n",
       "3                  58    atlantico    25.800000  3478.11    1411.317456  ...   \n",
       "4                  50      bolivar    22.497558  3478.11    1160.904575  ...   \n",
       "..                ...          ...          ...      ...            ...  ...   \n",
       "967                 3      guainia    25.600000  3981.16      47.053040  ...   \n",
       "968                 0      vichada    21.652402  3981.16      27.312103  ...   \n",
       "969                 3       vaupes    21.652402  3981.16      27.794043  ...   \n",
       "970                 0        huila    21.652402  3981.16      99.608632  ...   \n",
       "971                 4        cesar    21.652402  3981.16     613.087544  ...   \n",
       "\n",
       "     Otros Gastos  Diario  Gasto Promedio Viaje  Gasto Alojamiento Viaje  \\\n",
       "0            38309.988310         509576.010704             94227.742607   \n",
       "1            38349.247334         642297.592149            155336.389361   \n",
       "2            22500.262354         409266.901336             69171.990677   \n",
       "3            46960.260000         797692.580000            161345.770000   \n",
       "4            18030.146000         390658.100000             40006.560000   \n",
       "..                    ...                   ...                      ...   \n",
       "967          37186.376345         667988.742264            163647.571594   \n",
       "968          36986.929789         674590.994187            164518.617859   \n",
       "969          31866.679879         580733.566611            133979.208194   \n",
       "970          23004.827084         424225.932035             87017.473048   \n",
       "971          20474.493975         500004.084276             83747.309945   \n",
       "\n",
       "     Gasto Transporte  Viaje  Gasto alimetos Viaje  Otros Gastos  Viaje  \\\n",
       "0              114452.575274         126513.416828        198360.186342   \n",
       "1              101229.841007         138644.470640        269015.023058   \n",
       "2               72707.583734         156302.284798        117579.038487   \n",
       "3              143819.680000         243722.200000        248804.920000   \n",
       "4               95969.190000         148800.860000        105881.480000   \n",
       "..                       ...                   ...                  ...   \n",
       "967            106103.938719         154151.458844        256585.689974   \n",
       "968            105557.797928         157322.460242        258695.331397   \n",
       "969            109251.027751         135601.667940        215172.536627   \n",
       "970             90239.961293         106987.787639        120250.704847   \n",
       "971            113581.149700         153175.467502        132628.940586   \n",
       "\n",
       "                            geometry  Inflacion  carreteras_cercanas  Eventos  \n",
       "0     POINT (581933.159 1216844.759)    1.59721                    1      0.0  \n",
       "1    POINT (1063012.099 -467914.527)    1.59721                    1      0.0  \n",
       "2      POINT (437321.773 700082.696)    1.59721                    3      0.0  \n",
       "3     POINT (521642.463 1214140.036)    1.59721                   10      0.0  \n",
       "4     POINT (445269.937 1149681.547)    1.59721                    5      0.0  \n",
       "..                               ...        ...                  ...      ...  \n",
       "967   POINT (1287613.509 430529.596)    5.62267                    0      0.0  \n",
       "968   POINT (1333897.888 690164.666)    5.62267                    1      1.0  \n",
       "969   POINT (1037614.182 132922.769)    5.62267                    0      0.0  \n",
       "970    POINT (451378.305 319631.823)    5.62267                    2      0.0  \n",
       "971   POINT (682924.172 1057948.201)    5.62267                    1      0.0  \n",
       "\n",
       "[972 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte  Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos  Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [Ciudad, Mes, Extranjeros no Residentes, Homicidios, Hurtos, Delitos Sexuales, Departamento, Temperatura, Dolar, Pib Ponderado, Entradas Extranjeros Zona, distancia_ponderada_km, importancia accesos, Establecimientos, HABITACIONES, CAMAS, distancia_ponderada_TOP, Proxy_Pobreza, Gasto Promedio Diario, Gasto Alojamiento Diario, Gasto Transporte  Diario, Gasto alimetos  Diario, Otros Gastos  Diario, Gasto Promedio Viaje, Gasto Alojamiento Viaje, Gasto Transporte  Viaje, Gasto alimetos Viaje, Otros Gastos  Viaje, geometry, Inflacion, carreteras_cercanas, Eventos]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2021[Base_2021.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicio proceso\n",
    "df= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Visitantes_No_Residentes.csv')\n",
    "df1 = df[df[\"Año\"] == 2022]\n",
    "df1= arreglar_texto(df1 , 'Ciudad' , 'Ciudad')\n",
    "Homicidios= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\homicidios_7.xls').dropna()\n",
    "Homicidos1 = bases_crimenes(Homicidios , 'FECHA HECHO' , 'CANTIDAD' , 'Homicidios')\n",
    "Hurto= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\hurto_a_personas_17.xlsx').dropna()\n",
    "Hurto1 = bases_crimenes(Hurto , 'FECHA HECHO' , 'CANTIDAD' , 'Hurtos')\n",
    "sexuales= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\delitos_sexuales_11.xls').dropna()\n",
    "sexuales1 = bases_crimenes(sexuales , 'FECHA HECHO' , 'CANTIDAD' , 'Delitos Sexuales')\n",
    "ciudades= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\ciudades.csv')\n",
    "ciudades = arreglar_texto(ciudades, 'city' , \"Ciudad\")\n",
    "ciudades['admin_name'] = ciudades['admin_name'].astype(str)\n",
    "ciudades.at[68, 'admin_name'] = 'Atlantico'\n",
    "Total_18= completar_meses(df1 , 'Ciudad' , 'Mes' ,'Extranjeros no Residentes' , 1)\n",
    "Total_18 = pd.merge(Total_18, Homicidos1[['Ciudad', 'Homicidios' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, Hurto1[['Ciudad', 'Hurtos' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, sexuales1[['Ciudad', 'Delitos Sexuales' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18['Homicidios'] = Total_18['Homicidios'].fillna(0)\n",
    "Total_18['Hurtos'] = Total_18['Hurtos'].fillna(0)\n",
    "Total_18['Delitos Sexuales'] = Total_18['Delitos Sexuales'].fillna(0)\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('bogotadc', 'bogota', regex=False)\n",
    "\n",
    "#Seleccionar Ciudades que vamos a trabajar\n",
    "ciudades1= set(ciudades['Ciudad'])\n",
    "ciudades2= set(Total_18['Ciudad'])\n",
    "grandes_ciudades=list(ciudades1.intersection(ciudades2))\n",
    "l=['bogota' , 'tumaco']\n",
    "grandes_ciudades = grandes_ciudades + l\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "for i in Total_18['Ciudad']:\n",
    "    indice = Total_18[Total_18['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Total_18 = Total_18.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Poner Ubicaciones\n",
    "ciudades['geometry'] = ciudades.apply(lambda i: Point(i['lng'], i['lat']), axis=1)\n",
    "ciudades_geometry= gpd.GeoDataFrame(ciudades, geometry='geometry')\n",
    "Total_18_Geometry= pd.merge(Total_18, ciudades_geometry[['Ciudad', 'geometry']], on='Ciudad' , how='left')\n",
    "Total_18_Geometry= gpd.GeoDataFrame(Total_18_Geometry, geometry='geometry')\n",
    "\n",
    "# Poner departamentos\n",
    "Departamentos = gpd.read_file(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Colombia.json\")\n",
    "Departamentos = arreglar_texto(Departamentos, 'NOMBRE_DPT' , \"Departamento\")\n",
    "Departamentos[\"Departamento\"] = Departamentos[\"Departamento\"].str.replace('santafedebogota', 'bogotadc', regex=False)\n",
    "\n",
    "if Total_18_Geometry.crs is None:\n",
    "    Total_18_Geometry = Total_18_Geometry.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Total_18_Geometry = gpd.sjoin_nearest(Total_18_Geometry,  Departamentos, how='left', distance_col='distancia').drop(['AREA' , 'PERIMETER' , 'HECTARES' , 'DPTO','index_right' , 'distancia'] , axis=1)\n",
    "Total_18_Geometry\n",
    "Total_18_Geometry[Total_18_Geometry.isnull().any(axis=1)]\n",
    "\n",
    "#Agregar Clima\n",
    "clima_2018 = clima[clima['FechaObservacion'].dt.year == 2022]\n",
    "clima_2018 = arreglar_texto(clima_2018 , 'Municipio', 'Ciudad')\n",
    "clima_2018= completar_meses(clima_2018 , 'Ciudad' , 'Mes' ,'ValorObservado' , 0)\n",
    "Total_18_Clima= pd.merge(Total_18_Geometry, clima_2018[['Ciudad', 'ValorObservado' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18_Clima = Total_18_Clima.rename(columns={'ValorObservado': 'Temperatura'})\n",
    "\n",
    "#Krigging para el clima \n",
    "df_kriging = meses_a_numeros(Total_18_Clima , 'Mes')\n",
    "df_kriging.set_crs(epsg=4326, inplace=True)\n",
    "df_kriging=df_kriging.to_crs(epsg=32618)  \n",
    "\n",
    "meses_krig = df_kriging['Mes'].unique()\n",
    "\n",
    "for i in meses_krig:\n",
    "    print('Procesando Mes:' ,i)\n",
    "    \n",
    "    df_kriging_mes = df_kriging[df_kriging['Mes'] == i] # Vamos a realizar el kriging por mes\n",
    "    df_kriging_known = df_kriging_mes.dropna(subset=['Temperatura']) # Los datos para los que tenemos temperatura\n",
    "    df_kriging_missing = df_kriging_mes[df_kriging_mes ['Temperatura'].isna()] # Los datos para los NO que tenemos temperatura (Variable a predecir)\n",
    "    \n",
    "    if df_kriging_missing.empty:\n",
    "        print('No hay datos faltantes en el mes ' , i) # Si algun mes esta completo para todas las ciudades, no hacer nada \n",
    "        continue\n",
    "    \n",
    "    # Nuestras variables para predecir\n",
    "    x_known = df_kriging_known.geometry.x.values\n",
    "    y_known = df_kriging_known.geometry.y.values\n",
    "    z_known = df_kriging_known['Temperatura'].values\n",
    "    \n",
    "    # Nuestros datos a predecir\n",
    "    x_missing = df_kriging_missing.geometry.x.values\n",
    "    y_missing = df_kriging_missing.geometry.y.values\n",
    "    \n",
    "    # Crear el modelo \n",
    "    Krigg = OrdinaryKriging(\n",
    "        x_known, y_known, z_known,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False)\n",
    "    \n",
    "    # Realizar predicciones con el krigging\n",
    "    z_pred, ss = Krigg.execute('points', x_missing, y_missing)\n",
    "    \n",
    "    # Introducir en el DF los valores\n",
    "    df_kriging.loc[df_kriging_missing.index, 'Temperatura'] = z_pred\n",
    "\n",
    "#Agregar precio dolar\n",
    "Dolar = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Dolar.xlsx')\n",
    "Dolar['Fecha'] = pd.to_datetime(Dolar['Fecha'], errors='coerce')\n",
    "Dolar.set_index('Fecha', inplace=True)\n",
    "Dolar = Dolar.resample('M').median()\n",
    "Dolar = Dolar.reset_index()\n",
    "Dolar_2018=Dolar[Dolar['Fecha'].dt.year == 2022]\n",
    "Dolar_2018['Mes'] = range(1, 13)\n",
    "Base_2018=pd.merge(df_kriging, Dolar_2018, on= 'Mes', how='right').drop('Fecha' , axis=1)\n",
    "Base_2018\n",
    "\n",
    "#Interpolar PIB mensual\n",
    "\n",
    "PIB = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\PIB - Miles de millones de pesos  - 2022p.xlsx')\n",
    "PIB= arreglar_texto(PIB, 'DEPARTAMENTO' , 'Departamento')\n",
    "PIB['VALOR (unidades)'] = PIB['VALOR (unidades)'].str.replace(',', '.')\n",
    "PIB['VALOR (unidades)'] = pd.to_numeric(PIB['VALOR (unidades)'], errors='coerce')\n",
    "# Usaremos el metodo de LOESS para descomponer el PIB mensualmente \n",
    "meses_loees= np.arange(1, 13)\n",
    "tendencia_mensual_inflacion = [6.94 ,8.01, 8.53 , 9.23 , 9.07 , 9.67 , 10.21 , 10.84 , 11.44, 12.22 , 12.53 , 13.12] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual_inflacion) for valor in tendencia_mensual_inflacion]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "# La idea es crear algun tipo de ruido sobre nuestro patron, para asi tratar de simular efectos reales economicos.\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) #  Asegurarnos que todos las fulctuaciones sean positivas. \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "\n",
    "def descomponer_pib_loess(pib_anual, patron):\n",
    "    def asignar_pib_mensual(k, patron):\n",
    "        pib_mensual = patron * k['VALOR (unidades)']\n",
    "        return pib_mensual\n",
    "\n",
    "    df_mensual = pd.DataFrame()\n",
    "    \n",
    "    for i, k in pib_anual.iterrows():\n",
    "        pib_mensual = asignar_pib_mensual(k, patron)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Departamento': k['Departamento'],\n",
    "            'Mes': np.arange(1, 13),\n",
    "            'PIB_Mensual': pib_mensual\n",
    "        })\n",
    "        \n",
    "        df_mensual = pd.concat([df_mensual, df_temp], ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "pib_mensual = descomponer_pib_loess(PIB, patron_smooth)\n",
    "importancia_pesos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\importancia-municipal.xlsx')\n",
    "\n",
    "#Dado que encontrar una serie completa desde 2018 hasta 2024 de el valor del PIB por ciudad no es facil, primero usaremos la descomposicon por mes que hicimos departamental y la ponderaremos \n",
    "#por la importancia de cada ciudad en el departamento para encontrar un aproximando significativo. pdta= la base que nos pasaste profe no tenia todos los anos por eso hacemos esta aproximacion\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Municipio / Distrito' , 'Ciudad')\n",
    "importancia_pesos['Departamento'] = importancia_pesos['Departamento'].astype(str)\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Departamento' , 'Departamento')\n",
    "\n",
    "# Dejar solo las ciudades que estamos trabajando.\n",
    "for i in importancia_pesos['Ciudad']:\n",
    "    indice = importancia_pesos[importancia_pesos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        importancia_pesos = importancia_pesos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "importancia_pesos_mensual = importancia_pesos.loc[importancia_pesos.index.repeat(12)].reset_index(drop=True)\n",
    "importancia_pesos_mensual['Mes'] = (importancia_pesos_mensual.index % 12) + 1\n",
    "pib_pesos_ciudades1 = pd.merge(importancia_pesos_mensual, pib_mensual, on=['Departamento', 'Mes'], how='left')\n",
    "pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] /100\n",
    "pib_pesos_ciudades1['Pib Ponderado'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] * pib_pesos_ciudades1['PIB_Mensual']\n",
    "fusion_left = pd.merge(Base_2018, pib_pesos_ciudades1[['Pib Ponderado' , 'Ciudad', 'Mes']], on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Agregar puntos de llegadas internacionales\n",
    "entradas = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Entradas_de_extranjeros_a_Colombia_20241006.csv')\n",
    "entradas_2018= entradas[entradas['Año']==2022]\n",
    "entradas_2018 = entradas_2018[entradas_2018['Latitud - Longitud'] != 'No Aplica,No Aplica']\n",
    "entradas_2018 =traducir(entradas_2018 , 'Mes')\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "entradas_2018 =completar_meses(entradas_2018, 'Latitud - Longitud' , 'Mes' , 'Total' ,1 )\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "\n",
    "entradas_geometry = convertir_ubicacion(entradas_2018 , 'Latitud - Longitud')\n",
    "Entradas = gpd.GeoDataFrame(entradas_geometry, geometry='geometry')\n",
    "\n",
    "if Entradas.crs is None:\n",
    "    Entradas = Entradas.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Entradas = gpd.sjoin_nearest(Entradas,  Departamentos, how='left', distance_col='distancia').drop(['index_right' , 'DPTO' , 'AREA' , 'PERIMETER' , 'HECTARES' ,'distancia'] , axis=1)\n",
    "Entradas_Departamentos = Entradas.groupby(['Mes', 'Departamento'])['Total'].sum().reset_index()\n",
    "final = pd.merge(fusion_left, Entradas_Departamentos, on=['Departamento', 'Mes'], how='left').rename(columns={'Total': 'Entradas Extranjeros Zona'})\n",
    "final['Entradas Extranjeros Zona'] = final['Entradas Extranjeros Zona'].fillna(0)\n",
    "final[final['Ciudad'] == 'medellin']\n",
    "\n",
    "#Distancias desde los puntos de llegadas internacionales ponderadas \n",
    "for i in ciudades['Ciudad']:\n",
    "    indice = ciudades[ciudades['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_unico = ciudades.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unico = ciudades_unico.iloc[:, [0, -1]]\n",
    "ciudades_unico= gpd.GeoDataFrame(ciudades_unico, geometry='geometry')\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if Migracion_Unico.crs is None:\n",
    "    Migracion_Unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de Migracion_Unico: {Migracion_Unico.crs}\")\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "Migracion_Unico = Migracion_Unico.to_crs(epsg=32618)\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "Migracion_Unico['key'] = 1\n",
    "\n",
    "Distancia_combinado = pd.merge(ciudades_unico, Migracion_Unico, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "Distancia_combinado['distancia_km'] = Distancia_combinado.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_combinado['distancia_ponderada'] = Distancia_combinado['distancia_km'] * Distancia_combinado['Total']\n",
    "Distancia_ponderado = Distancia_combinado.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_migrantes=('Total', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "Distancia_ponderado['distancia_ponderada_km'] = Distancia_ponderado['suma_ponderada'] / Distancia_ponderado['suma_migrantes']\n",
    "Distancia_ponderado_final = Distancia_ponderado[['Ciudad' , 'distancia_ponderada_km']]\n",
    "\n",
    "Distancia_ciudades = ciudades_unico.merge(Distancia_ponderado_final, on='Ciudad')\n",
    "final1 = pd.merge(final, Distancia_ciudades, on='Ciudad', how='left').drop(['geometry_y' , 'key'] , axis=1)\n",
    "\n",
    "# Score importancia puntos entrada\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "columnas = ['geometry' , 'Departamento' ,'Total' ]\n",
    "Migracion_Unico_Dept = gpd.sjoin_nearest(Migracion_Unico, Departamentos, how='left', distance_col='distancia')[columnas]\n",
    "Total_Migracion = Migracion_Unico_Dept.groupby('Departamento').agg(\n",
    "    puntos=('Departamento', 'size'),  \n",
    "    total_personas=('Total', 'sum')  \n",
    ").reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "Total_Migracion[['puntos_norm', 'total_norm']] = scaler.fit_transform(Total_Migracion[['puntos', 'total_personas']])\n",
    "Total_Migracion['importancia accesos'] = 0.3 * Total_Migracion['puntos_norm'] + 0.7 * Total_Migracion['total_norm'] # Asumimos que es mas importante cuanta gente llega a que tantos puntos hay.\n",
    "final1 = pd.merge(final1, Total_Migracion, on='Departamento', how='left').drop(['puntos' , 'total_personas' , 'puntos_norm' , 'total_norm'] , axis=1)\n",
    "final1['importancia accesos'] = final1['importancia accesos'].fillna(0)\n",
    "\n",
    "\n",
    "#Numero establecimientos de turismo, camas y habitaciones para turistas.\n",
    "hoteles = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Hist_rico_Registro_Nacional_de_Turismo_-_RNT_20241007.csv')\n",
    "establecimientos_2018 = hoteles[hoteles['AÑO']==2022]\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('PUERTO INIRIDA', 'Inirida', regex=False)\n",
    "establecimientos_2018['NOMBRE-MUNI'] = establecimientos_2018['NOMBRE-MUNI'].str.replace('BUGA', 'guadalajaradebuga', regex=False)\n",
    "\n",
    "Establecimientos = establecimientos_2018.groupby('NOMBRE-MUNI').agg({'CATEGORIA': 'count','HABITACIONES': 'sum', 'CAMAS': 'sum'}).reset_index().rename(columns={'CATEGORIA': 'Establecimientos'})\n",
    "Establecimientos = arreglar_texto(Establecimientos, 'NOMBRE-MUNI' , 'Municipios')\n",
    "for i in Establecimientos['Municipios']:\n",
    "    indice = Establecimientos[Establecimientos['Municipios'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Establecimientos = Establecimientos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "Establecimientos=Establecimientos.rename(columns={'Municipios': 'Ciudad'})\n",
    "meses_loees = np.arange(1, 13)\n",
    "tendencia_mensual = [56, 58, 62, 57, 59, 62, 65, 72, 75, 77, 80, 82] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual) for valor in tendencia_mensual]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "def descomponer_variables_loess(df_anual, patron, variables):\n",
    "    def asignar_valores_mensuales(fila, patron, variables):\n",
    "        valores_mensuales = {}\n",
    "        for i in variables:\n",
    "            valores_mensuales[i] = patron * fila[i]\n",
    "        return valores_mensuales\n",
    "\n",
    "    data_mensual = []\n",
    "    for i, fila in df_anual.iterrows():\n",
    "        valores_mensuales = asignar_valores_mensuales(fila, patron, variables)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Ciudad': fila['Ciudad'],\n",
    "            'Mes': np.arange(1, 13)\n",
    "        })\n",
    "        \n",
    "        for k in variables:\n",
    "            df_temp[k] = valores_mensuales[k]\n",
    "        \n",
    "        data_mensual.append(df_temp)\n",
    "    \n",
    "    df_mensual = pd.concat(data_mensual, ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "Establecimientos_mensual = descomponer_variables_loess(Establecimientos, patron_smooth , ['Establecimientos' , 'HABITACIONES' , 'CAMAS'])\n",
    "final2 = pd.merge(final1, Establecimientos_mensual, on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Distancias al TOP de colombia \n",
    "df_TopColombia = pd.DataFrame.from_dict(Top_Colombia, orient='index', columns=['coordinates','Reviews', 'rating', 'eliminar'])\n",
    "df_TopColombia = df_TopColombia.reset_index().rename(columns={'index': 'lugar'}).drop('eliminar' , axis=1)\n",
    "df_TopColombia['geometry'] = df_TopColombia['coordinates'].apply(lambda x: Point(x[1], x[0]))\n",
    "df_TopColombia_gdp = gpd.GeoDataFrame(df_TopColombia, geometry='geometry').drop('coordinates' , axis=1)\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if df_TopColombia_gdp.crs is None:\n",
    "    df_TopColombia_gdp.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de df_TopColombia_gdp: {df_TopColombia_gdp.crs}\")\n",
    "\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "df_TopColombia_gdp = df_TopColombia_gdp.to_crs(epsg=32618)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "df_TopColombia_gdp['key'] = 1\n",
    "\n",
    "Distancia_Top = pd.merge(ciudades_unico, df_TopColombia_gdp, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "w_reviews = 0.6 # Vamos a asumir que las reviews tienen mas peso que la calificacion del lugar \n",
    "w_rating = 0.4\n",
    "\n",
    "Distancia_Top['distancia_km'] = Distancia_Top.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_Top[['distancia_km','Reviews', 'rating']] = scaler.fit_transform(\n",
    "    Distancia_Top[['distancia_km','Reviews', 'rating']]\n",
    ") # Normalizamos las variables para calcular una distancia ponderada con las mismas escalas\n",
    "\n",
    "Distancia_Top['distancia_ponderada'] = (Distancia_Top['distancia_km']) + ( w_reviews* Distancia_Top['Reviews']) + ( w_rating* Distancia_Top['rating'])\n",
    "\n",
    "Distancia_Ponderado_Top = Distancia_Top.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_reviews=('Reviews', 'sum'),\n",
    "    suma_rating=('rating', 'sum')).reset_index()\n",
    "\n",
    "Distancia_Ponderado_Top['distancia_ponderada_TOP'] = Distancia_Ponderado_Top['suma_ponderada'] / (Distancia_Ponderado_Top['suma_reviews']+Distancia_Ponderado_Top['suma_rating'])\n",
    "Distancia_Ponderado_Top_final = Distancia_Ponderado_Top[['Ciudad' , 'distancia_ponderada_TOP']]\n",
    "\n",
    "Distancia_Top = ciudades_unico.merge(Distancia_Ponderado_Top_final, on='Ciudad')\n",
    "final3 = pd.merge(final2, Distancia_Top, on='Ciudad', how='left').drop(['geometry_x' , 'key'] , axis=1)\n",
    "\n",
    "# Pobreza con proxy\n",
    "ciudades_poblacion = ciudades[['Ciudad' , 'population']]\n",
    "for i in ciudades_poblacion['Ciudad']:\n",
    "    indice = ciudades_poblacion[ciudades_poblacion['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_poblacion = ciudades_poblacion.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final4 = pd.merge(final3, ciudades_poblacion, on='Ciudad', how='left')\n",
    "final4['Proxy_Pobreza'] = final4['Pib Ponderado'] / final4['population']\n",
    "final4\n",
    "\n",
    "#Gasto promedio por dia de un turista\n",
    "gastos_diarios = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\Gastos Diarios 2022.xlsx')\n",
    "gastos_diarios = arreglar_texto(gastos_diarios , 'Ciudad', 'Ciudad')\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_diarios = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "gastos_diarios_Nan = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_diarios_Nan = gpd.GeoDataFrame(pd.merge(gastos_diarios_Nan, ciudades_geometry, on='Ciudad', how='left').drop('geometry_x' , axis=1) , geometry='geometry')\n",
    "gastos_diarios_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_diarios_Nan=gastos_diarios_Nan.to_crs(epsg=32618)  \n",
    "variables = [i for i in gastos_diarios_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_diarios_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_diarios_Nan[gastos_diarios_Nan[variables].isnull().any(axis=1)]\n",
    "\n",
    "def kriging(df_con_info, variable, grid_size=100):\n",
    "    coords = np.array(list(zip(df_con_info.geometry.x, df_con_info.geometry.y)))\n",
    "    valores = df_con_info[variable].values\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = gastos_diarios_Nan.total_bounds\n",
    "    gridx = np.linspace(min_x, max_x, grid_size)\n",
    "    gridy = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    Krigg_O = OrdinaryKriging(\n",
    "        coords[:,0], coords[:,1], valores,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False\n",
    "    )\n",
    "    \n",
    "    z1, ss1 = Krigg_O.execute('grid', gridx, gridy)\n",
    "    \n",
    "    return Krigg_O, gridx, gridy, z1\n",
    "\n",
    "def estimar(Krigg, puntos):\n",
    "    x = puntos.geometry.x.values\n",
    "    y = puntos.geometry.y.values\n",
    "    estimados, ss = Krigg.execute('points', x, y)\n",
    "    return estimados\n",
    "\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual['Mes'] = (gastos_krigg_mensual.index % 12) + 1\n",
    "final5 = pd.merge(final4, gastos_krigg_mensual, on=['Mes', 'Ciudad'], how='left').drop(['geometry_x','population'] , axis=1)\n",
    "\n",
    "# Gastos de todo el viaje \n",
    "gastos_viaje = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2022\\\\Gastos Viaje 2022.xlsx')\n",
    "gastos_viaje = arreglar_texto(gastos_viaje , 'Ciudad', 'Ciudad')\n",
    "\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_viaje = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='left')\n",
    "gastos_viaje_Nan = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_viaje_Nan = gpd.GeoDataFrame(pd.merge(gastos_viaje_Nan, ciudades_geometry, on='Ciudad', how='left') , geometry='geometry')\n",
    "gastos_viaje_Nan = gastos_viaje_Nan.drop('geometry_x' , axis=1)\n",
    "\n",
    "gastos_viaje_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_viaje_Nan=gastos_viaje_Nan.to_crs(epsg=32618) \n",
    "variables = [i for i in gastos_viaje_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_viaje_Nan.dropna()\n",
    "gastos_con_Nan = gastos_viaje_Nan[gastos_viaje_Nan[variables].isnull().any(axis=1)]\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual_viaje = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual_viaje['Mes'] = (gastos_krigg_mensual_viaje.index % 12) + 1\n",
    "gastos_krigg_mensual_viaje\n",
    "Base_2022 = pd.merge(final5, gastos_krigg_mensual_viaje, on=['Mes', 'Ciudad'], how='left').drop('geometry_y' , axis=1)\n",
    "\n",
    "# Agregar inflacion\n",
    "inflacion = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Inflacion.xlsx')\n",
    "inflacion['Fecha'] = pd.to_datetime(inflacion['Fecha'])\n",
    "inflacion = inflacion[inflacion['Fecha'].dt.year == 2022].rename(columns={'Fecha':'Mes'})\n",
    "inflacion['Mes'] = inflacion['Mes'].dt.month\n",
    "Base_2022  = pd.merge(Base_2022 , inflacion, on='Mes', how='left')\n",
    "\n",
    "#Agregar Cantidad de vias \n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2022 = pd.merge(Base_2022 , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "#Agregar Vias\n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2022 = pd.merge(Base_2022 , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "# Agregar Eventos\n",
    "eventos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Eventos Turisticos\\\\Eventos 2023.xlsx').fillna(0)\n",
    "eventos = arreglar_texto(eventos ,'Departamento' , 'Departamento')\n",
    "eventos['Departamento'] = eventos['Departamento'].str.replace('sanandres', 'archipielagodesanandresprovidenciaysantacatalina', regex=False)\n",
    "Base_2022 = pd.merge(Base_2022 , eventos , on=['Departamento' ,'Mes'] , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see 2022 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte  Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas_x</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ipiales</td>\n",
       "      <td>1</td>\n",
       "      <td>662.0</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "      <td>narino</td>\n",
       "      <td>21.19639</td>\n",
       "      <td>3987.32</td>\n",
       "      <td>107.664827</td>\n",
       "      <td>...</td>\n",
       "      <td>32859.977774</td>\n",
       "      <td>414930.568037</td>\n",
       "      <td>85339.410173</td>\n",
       "      <td>81456.596608</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>166329.823144</td>\n",
       "      <td>POINT (205670.004 91871.64)</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sogamoso</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>boyaca</td>\n",
       "      <td>19.50000</td>\n",
       "      <td>3987.32</td>\n",
       "      <td>224.009782</td>\n",
       "      <td>...</td>\n",
       "      <td>36557.359071</td>\n",
       "      <td>432151.277957</td>\n",
       "      <td>83777.318179</td>\n",
       "      <td>86829.017931</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>146312.971893</td>\n",
       "      <td>POINT (730269.76 632304.448)</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>villavicencio</td>\n",
       "      <td>1</td>\n",
       "      <td>369.0</td>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>35</td>\n",
       "      <td>meta</td>\n",
       "      <td>26.85000</td>\n",
       "      <td>3987.32</td>\n",
       "      <td>957.694236</td>\n",
       "      <td>...</td>\n",
       "      <td>25404.702000</td>\n",
       "      <td>520055.783000</td>\n",
       "      <td>82656.411000</td>\n",
       "      <td>146138.129000</td>\n",
       "      <td>130711.24400</td>\n",
       "      <td>160549.999000</td>\n",
       "      <td>POINT (651697.732 458838.689)</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cali</td>\n",
       "      <td>1</td>\n",
       "      <td>10522.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1414</td>\n",
       "      <td>72</td>\n",
       "      <td>valledelcauca</td>\n",
       "      <td>15.40000</td>\n",
       "      <td>3987.32</td>\n",
       "      <td>3799.338865</td>\n",
       "      <td>...</td>\n",
       "      <td>46615.889000</td>\n",
       "      <td>684311.314000</td>\n",
       "      <td>161859.618000</td>\n",
       "      <td>78320.118000</td>\n",
       "      <td>193990.36800</td>\n",
       "      <td>250141.209000</td>\n",
       "      <td>POINT (330897.116 378217.634)</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasto</td>\n",
       "      <td>1</td>\n",
       "      <td>412.0</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>narino</td>\n",
       "      <td>11.40000</td>\n",
       "      <td>3987.32</td>\n",
       "      <td>414.182292</td>\n",
       "      <td>...</td>\n",
       "      <td>29348.193000</td>\n",
       "      <td>367035.791000</td>\n",
       "      <td>54313.047000</td>\n",
       "      <td>76923.127000</td>\n",
       "      <td>95936.82900</td>\n",
       "      <td>139862.787000</td>\n",
       "      <td>POINT (246593.462 133604.578)</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>piedecuesta</td>\n",
       "      <td>12</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>santander</td>\n",
       "      <td>21.60000</td>\n",
       "      <td>4780.17</td>\n",
       "      <td>414.508319</td>\n",
       "      <td>...</td>\n",
       "      <td>25463.461156</td>\n",
       "      <td>517058.891202</td>\n",
       "      <td>107775.602005</td>\n",
       "      <td>92543.117839</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>135485.158165</td>\n",
       "      <td>POINT (720906.443 783432.99)</td>\n",
       "      <td>13.12247</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>cartago</td>\n",
       "      <td>12</td>\n",
       "      <td>524.0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>valledelcauca</td>\n",
       "      <td>22.45000</td>\n",
       "      <td>4780.17</td>\n",
       "      <td>377.728402</td>\n",
       "      <td>...</td>\n",
       "      <td>42700.702452</td>\n",
       "      <td>445954.853897</td>\n",
       "      <td>81813.678105</td>\n",
       "      <td>71490.134752</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>193287.643915</td>\n",
       "      <td>POINT (398330.654 519569.549)</td>\n",
       "      <td>13.12247</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>uribia</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>laguajira</td>\n",
       "      <td>26.20000</td>\n",
       "      <td>4780.17</td>\n",
       "      <td>148.087212</td>\n",
       "      <td>...</td>\n",
       "      <td>54748.566907</td>\n",
       "      <td>729532.882737</td>\n",
       "      <td>88332.548939</td>\n",
       "      <td>138476.840738</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>344938.481437</td>\n",
       "      <td>POINT (826814.742 1319110.428)</td>\n",
       "      <td>13.12247</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>inirida</td>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>guainia</td>\n",
       "      <td>21.20039</td>\n",
       "      <td>4780.17</td>\n",
       "      <td>42.175835</td>\n",
       "      <td>...</td>\n",
       "      <td>52419.185547</td>\n",
       "      <td>626627.417683</td>\n",
       "      <td>88332.548939</td>\n",
       "      <td>99990.243989</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>309797.236065</td>\n",
       "      <td>POINT (1287613.509 430529.596)</td>\n",
       "      <td>13.12247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>tumaco</td>\n",
       "      <td>12</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>narino</td>\n",
       "      <td>23.70000</td>\n",
       "      <td>4780.17</td>\n",
       "      <td>250.360561</td>\n",
       "      <td>...</td>\n",
       "      <td>42835.253871</td>\n",
       "      <td>510434.140071</td>\n",
       "      <td>88332.548939</td>\n",
       "      <td>79139.227566</td>\n",
       "      <td>135766.83125</td>\n",
       "      <td>233764.255344</td>\n",
       "      <td>POINT (80986.963 200129.782)</td>\n",
       "      <td>13.12247</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ciudad  Mes  Extranjeros no Residentes  Homicidios  Hurtos  \\\n",
       "0          ipiales    1                      662.0           2     106   \n",
       "1         sogamoso    1                       64.0           0      67   \n",
       "2    villavicencio    1                      369.0           3     375   \n",
       "3             cali    1                    10522.0          74    1414   \n",
       "4            pasto    1                      412.0           4     317   \n",
       "..             ...  ...                        ...         ...     ...   \n",
       "967    piedecuesta   12                      137.0           3     106   \n",
       "968        cartago   12                      524.0          10      45   \n",
       "969         uribia   12                        5.0           2       8   \n",
       "970        inirida   12                       13.0           0       7   \n",
       "971         tumaco   12                       50.0          25      35   \n",
       "\n",
       "     Delitos Sexuales   Departamento  Temperatura    Dolar  Pib Ponderado  \\\n",
       "0                  16         narino     21.19639  3987.32     107.664827   \n",
       "1                   5         boyaca     19.50000  3987.32     224.009782   \n",
       "2                  35           meta     26.85000  3987.32     957.694236   \n",
       "3                  72  valledelcauca     15.40000  3987.32    3799.338865   \n",
       "4                  41         narino     11.40000  3987.32     414.182292   \n",
       "..                ...            ...          ...      ...            ...   \n",
       "967                 2      santander     21.60000  4780.17     414.508319   \n",
       "968                 4  valledelcauca     22.45000  4780.17     377.728402   \n",
       "969                 1      laguajira     26.20000  4780.17     148.087212   \n",
       "970                 2        guainia     21.20039  4780.17      42.175835   \n",
       "971                 1         narino     23.70000  4780.17     250.360561   \n",
       "\n",
       "     ...  Otros Gastos  Diario  Gasto Promedio Viaje  Gasto Alojamiento Viaje  \\\n",
       "0    ...          32859.977774         414930.568037             85339.410173   \n",
       "1    ...          36557.359071         432151.277957             83777.318179   \n",
       "2    ...          25404.702000         520055.783000             82656.411000   \n",
       "3    ...          46615.889000         684311.314000            161859.618000   \n",
       "4    ...          29348.193000         367035.791000             54313.047000   \n",
       "..   ...                   ...                   ...                      ...   \n",
       "967  ...          25463.461156         517058.891202            107775.602005   \n",
       "968  ...          42700.702452         445954.853897             81813.678105   \n",
       "969  ...          54748.566907         729532.882737             88332.548939   \n",
       "970  ...          52419.185547         626627.417683             88332.548939   \n",
       "971  ...          42835.253871         510434.140071             88332.548939   \n",
       "\n",
       "     Gasto Transporte  Viaje  Gasto alimetos Viaje  Otros Gastos Viaje  \\\n",
       "0               81456.596608          135766.83125       166329.823144   \n",
       "1               86829.017931          135766.83125       146312.971893   \n",
       "2              146138.129000          130711.24400       160549.999000   \n",
       "3               78320.118000          193990.36800       250141.209000   \n",
       "4               76923.127000           95936.82900       139862.787000   \n",
       "..                       ...                   ...                 ...   \n",
       "967             92543.117839          135766.83125       135485.158165   \n",
       "968             71490.134752          135766.83125       193287.643915   \n",
       "969            138476.840738          135766.83125       344938.481437   \n",
       "970             99990.243989          135766.83125       309797.236065   \n",
       "971             79139.227566          135766.83125       233764.255344   \n",
       "\n",
       "                           geometry  Inflacion  carreteras_cercanas_x  Eventos  \n",
       "0       POINT (205670.004 91871.64)    6.94460                      5      1.0  \n",
       "1      POINT (730269.76 632304.448)    6.94460                      6      2.0  \n",
       "2     POINT (651697.732 458838.689)    6.94460                     11      4.0  \n",
       "3     POINT (330897.116 378217.634)    6.94460                     11      1.0  \n",
       "4     POINT (246593.462 133604.578)    6.94460                      9      1.0  \n",
       "..                              ...        ...                    ...      ...  \n",
       "967    POINT (720906.443 783432.99)   13.12247                      4      0.0  \n",
       "968   POINT (398330.654 519569.549)   13.12247                     10      2.0  \n",
       "969  POINT (826814.742 1319110.428)   13.12247                      0      1.0  \n",
       "970  POINT (1287613.509 430529.596)   13.12247                      0      0.0  \n",
       "971    POINT (80986.963 200129.782)   13.12247                      1      3.0  \n",
       "\n",
       "[972 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2022 = Base_2022.drop('carreteras_cercanas_y' , axis=1)\n",
    "Base_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte  Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas_x</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [Ciudad, Mes, Extranjeros no Residentes, Homicidios, Hurtos, Delitos Sexuales, Departamento, Temperatura, Dolar, Pib Ponderado, Entradas Extranjeros Zona, distancia_ponderada_km, importancia accesos, Establecimientos, HABITACIONES, CAMAS, distancia_ponderada_TOP, Proxy_Pobreza, Gasto Promedio Diario, Gasto Alojamiento Diario, Gasto Transporte  Diario, Gasto alimetos  Diario, Otros Gastos  Diario, Gasto Promedio Viaje, Gasto Alojamiento Viaje, Gasto Transporte  Viaje, Gasto alimetos Viaje, Otros Gastos Viaje, geometry, Inflacion, carreteras_cercanas_x, Eventos]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Base_2022[Base_2022.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicio proceso\n",
    "df= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Visitantes_No_Residentes.csv')\n",
    "df1 = df[df[\"Año\"] == 2023]\n",
    "df1= arreglar_texto(df1 , 'Ciudad' , 'Ciudad')\n",
    "Homicidios= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\homicidio intencional.xlsx').dropna()\n",
    "Homicidos1 = bases_crimenes(Homicidios , 'FECHA HECHO' , 'CANTIDAD' , 'Homicidios')\n",
    "Hurto= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\hurto a personas.xlsx').dropna()\n",
    "Hurto1 = bases_crimenes(Hurto , 'FECHA HECHO' , 'CANTIDAD' , 'Hurtos')\n",
    "sexuales= pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\delitos sexuales.xlsx').dropna()\n",
    "sexuales1 = bases_crimenes(sexuales , 'FECHA HECHO' , 'CANTIDAD' , 'Delitos Sexuales')\n",
    "ciudades= pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\ciudades.csv')\n",
    "ciudades = arreglar_texto(ciudades, 'city' , \"Ciudad\")\n",
    "ciudades['admin_name'] = ciudades['admin_name'].astype(str)\n",
    "ciudades.at[68, 'admin_name'] = 'Atlantico'\n",
    "Total_18= completar_meses(df1 , 'Ciudad' , 'Mes' ,'Extranjeros no Residentes' , 1)\n",
    "Total_18 = pd.merge(Total_18, Homicidos1[['Ciudad', 'Homicidios' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, Hurto1[['Ciudad', 'Hurtos' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18 = pd.merge(Total_18, sexuales1[['Ciudad', 'Delitos Sexuales' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18['Homicidios'] = Total_18['Homicidios'].fillna(0)\n",
    "Total_18['Hurtos'] = Total_18['Hurtos'].fillna(0)\n",
    "Total_18['Delitos Sexuales'] = Total_18['Delitos Sexuales'].fillna(0)\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('bogotadc', 'bogota', regex=False)\n",
    "\n",
    "#Seleccionar Ciudades que vamos a trabajar\n",
    "ciudades1= set(ciudades['Ciudad'])\n",
    "ciudades2= set(Total_18['Ciudad'])\n",
    "grandes_ciudades=list(ciudades1.intersection(ciudades2))\n",
    "l=['bogota' , 'tumaco']\n",
    "grandes_ciudades = grandes_ciudades + l\n",
    "Total_18['Ciudad'] = Total_18['Ciudad'].str.replace('sanandresdetumaco', 'tumaco', regex=False)\n",
    "for i in Total_18['Ciudad']:\n",
    "    indice = Total_18[Total_18['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Total_18 = Total_18.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Poner Ubicaciones\n",
    "ciudades['geometry'] = ciudades.apply(lambda i: Point(i['lng'], i['lat']), axis=1)\n",
    "ciudades_geometry= gpd.GeoDataFrame(ciudades, geometry='geometry')\n",
    "Total_18_Geometry= pd.merge(Total_18, ciudades_geometry[['Ciudad', 'geometry']], on='Ciudad' , how='left')\n",
    "Total_18_Geometry= gpd.GeoDataFrame(Total_18_Geometry, geometry='geometry')\n",
    "\n",
    "# Poner departamentos\n",
    "Departamentos = gpd.read_file(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Colombia.json\")\n",
    "Departamentos = arreglar_texto(Departamentos, 'NOMBRE_DPT' , \"Departamento\")\n",
    "Departamentos[\"Departamento\"] = Departamentos[\"Departamento\"].str.replace('santafedebogota', 'bogotadc', regex=False)\n",
    "\n",
    "if Total_18_Geometry.crs is None:\n",
    "    Total_18_Geometry = Total_18_Geometry.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Total_18_Geometry = gpd.sjoin_nearest(Total_18_Geometry,  Departamentos, how='left', distance_col='distancia').drop(['AREA' , 'PERIMETER' , 'HECTARES' , 'DPTO','index_right' , 'distancia'] , axis=1)\n",
    "Total_18_Geometry\n",
    "Total_18_Geometry[Total_18_Geometry.isnull().any(axis=1)]\n",
    "\n",
    "#Agregar Clima\n",
    "clima2=pd.read_csv(\"C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\Datos_Hidrometeorol_gicos_Crudos_-_Red_de_Estaciones_IDEAM___Temperatura_20241009.csv\")\n",
    "clima2['FechaObservacion'] = pd.to_datetime(clima2['FechaObservacion'])\n",
    "clima2['Mes'] = clima2['FechaObservacion'].dt.month_name()\n",
    "\n",
    "clima_2018 = clima2[clima2['FechaObservacion'].dt.year == 2023]\n",
    "clima_2018 = arreglar_texto(clima_2018 , 'Municipio', 'Ciudad')\n",
    "clima_2018= completar_meses(clima_2018 , 'Ciudad' , 'Mes' ,'ValorObservado' , 0)\n",
    "Total_18_Clima= pd.merge(Total_18_Geometry, clima_2018[['Ciudad', 'ValorObservado' ,'Mes']], on=['Ciudad' ,'Mes'], how='left')\n",
    "Total_18_Clima = Total_18_Clima.rename(columns={'ValorObservado': 'Temperatura'})\n",
    "\n",
    "#Krigging para el clima \n",
    "df_kriging = meses_a_numeros(Total_18_Clima , 'Mes')\n",
    "df_kriging.set_crs(epsg=4326, inplace=True)\n",
    "df_kriging=df_kriging.to_crs(epsg=32618)  \n",
    "\n",
    "meses_krig = df_kriging['Mes'].unique()\n",
    "\n",
    "for i in meses_krig:\n",
    "    df_kriging_mes = df_kriging[df_kriging['Mes'] == i] # Vamos a realizar el kriging por mes\n",
    "    df_kriging_known = df_kriging_mes.dropna(subset=['Temperatura']) # Los datos para los que tenemos temperatura\n",
    "    df_kriging_missing = df_kriging_mes[df_kriging_mes ['Temperatura'].isna()] # Los datos para los NO que tenemos temperatura (Variable a predecir)\n",
    "    \n",
    "    if df_kriging_missing.empty:\n",
    "        print('No hay datos faltantes en el mes ' , i) # Si algun mes esta completo para todas las ciudades, no hacer nada \n",
    "        continue\n",
    "    \n",
    "    # Nuestras variables para predecir\n",
    "    x_known = df_kriging_known.geometry.x.values\n",
    "    y_known = df_kriging_known.geometry.y.values\n",
    "    z_known = df_kriging_known['Temperatura'].values\n",
    "    \n",
    "    # Nuestros datos a predecir\n",
    "    x_missing = df_kriging_missing.geometry.x.values\n",
    "    y_missing = df_kriging_missing.geometry.y.values\n",
    "    \n",
    "    # Crear el modelo \n",
    "    Krigg = OrdinaryKriging(\n",
    "        x_known, y_known, z_known,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False)\n",
    "    \n",
    "    # Realizar predicciones con el krigging\n",
    "    z_pred, ss = Krigg.execute('points', x_missing, y_missing)\n",
    "    \n",
    "    # Introducir en el DF los valores\n",
    "    df_kriging.loc[df_kriging_missing.index, 'Temperatura'] = z_pred\n",
    "\n",
    "#Agregar precio dolar\n",
    "Dolar = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Dolar.xlsx')\n",
    "Dolar['Fecha'] = pd.to_datetime(Dolar['Fecha'], errors='coerce')\n",
    "Dolar.set_index('Fecha', inplace=True)\n",
    "Dolar = Dolar.resample('M').median()\n",
    "Dolar = Dolar.reset_index()\n",
    "Dolar_2018=Dolar[Dolar['Fecha'].dt.year == 2023]\n",
    "Dolar_2018['Mes'] = range(1, 13)\n",
    "Base_2018=pd.merge(df_kriging, Dolar_2018, on= 'Mes', how='right').drop('Fecha' , axis=1)\n",
    "Base_2018\n",
    "\n",
    "#Interpolar PIB mensual\n",
    "\n",
    "PIB = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\PIB - Miles de millones de pesos  - 2023pr.xlsx')\n",
    "PIB= arreglar_texto(PIB, 'DEPARTAMENTO' , 'Departamento')\n",
    "PIB['VALOR (unidades)'] = PIB['VALOR (unidades)'].str.replace(',', '.')\n",
    "PIB['VALOR (unidades)'] = pd.to_numeric(PIB['VALOR (unidades)'], errors='coerce')\n",
    "# Usaremos el metodo de LOESS para descomponer el PIB mensualmente \n",
    "meses_loees= np.arange(1, 13)\n",
    "tendencia_mensual_inflacion = [13.25 ,13.28, 13.34 , 12.82 , 12.36 , 12.13 , 11.78 , 11.43 , 10.09, 10.48 , 10.15 , 9.28] # Esta tendencia se puede ver en la imagen \n",
    "patron_estacional = np.array([valor / sum(tendencia_mensual_inflacion) for valor in tendencia_mensual_inflacion]) \n",
    "patron_estacional = patron_estacional / patron_estacional.sum()\n",
    "\n",
    "# La idea es crear algun tipo de ruido sobre nuestro patron, para asi tratar de simular efectos reales economicos.\n",
    "np.random.seed(42)\n",
    "patron_ruido = patron_estacional + np.random.normal(0, 0.005, 12)\n",
    "patron_ruido = np.clip(patron_ruido, 0.01, None) #  Asegurarnos que todos las fulctuaciones sean positivas. \n",
    "patron_ruido = patron_ruido / patron_ruido.sum()\n",
    "\n",
    "loess_result = lowess(patron_ruido, meses_loees, frac=0.4)\n",
    "meses_smooth = loess_result[:, 0]\n",
    "patron_smooth = loess_result[:, 1]\n",
    "patron_smooth = patron_smooth / patron_smooth.sum()\n",
    "\n",
    "\n",
    "def descomponer_pib_loess(pib_anual, patron):\n",
    "    def asignar_pib_mensual(k, patron):\n",
    "        pib_mensual = patron * k['VALOR (unidades)']\n",
    "        return pib_mensual\n",
    "\n",
    "    df_mensual = pd.DataFrame()\n",
    "    \n",
    "    for i, k in pib_anual.iterrows():\n",
    "        pib_mensual = asignar_pib_mensual(k, patron)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            'Departamento': k['Departamento'],\n",
    "            'Mes': np.arange(1, 13),\n",
    "            'PIB_Mensual': pib_mensual\n",
    "        })\n",
    "        \n",
    "        df_mensual = pd.concat([df_mensual, df_temp], ignore_index=True)\n",
    "    \n",
    "    return df_mensual\n",
    "\n",
    "pib_mensual = descomponer_pib_loess(PIB, patron_smooth)\n",
    "importancia_pesos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\importancia-municipal.xlsx')\n",
    "\n",
    "#Dado que encontrar una serie completa desde 2018 hasta 2024 de el valor del PIB por ciudad no es facil, primero usaremos la descomposicon por mes que hicimos departamental y la ponderaremos \n",
    "#por la importancia de cada ciudad en el departamento para encontrar un aproximando significativo. pdta= la base que nos pasaste profe no tenia todos los anos por eso hacemos esta aproximacion\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Municipio / Distrito' , 'Ciudad')\n",
    "importancia_pesos['Departamento'] = importancia_pesos['Departamento'].astype(str)\n",
    "importancia_pesos = arreglar_texto(importancia_pesos , 'Departamento' , 'Departamento')\n",
    "\n",
    "# Dejar solo las ciudades que estamos trabajando.\n",
    "for i in importancia_pesos['Ciudad']:\n",
    "    indice = importancia_pesos[importancia_pesos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        importancia_pesos = importancia_pesos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "importancia_pesos_mensual = importancia_pesos.loc[importancia_pesos.index.repeat(12)].reset_index(drop=True)\n",
    "importancia_pesos_mensual['Mes'] = (importancia_pesos_mensual.index % 12) + 1\n",
    "pib_pesos_ciudades1 = pd.merge(importancia_pesos_mensual, pib_mensual, on=['Departamento', 'Mes'], how='left')\n",
    "pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] /100\n",
    "pib_pesos_ciudades1['Pib Ponderado'] = pib_pesos_ciudades1['Peso relativo municipal en el valor agregado departamental %'] * pib_pesos_ciudades1['PIB_Mensual']\n",
    "fusion_left = pd.merge(Base_2018, pib_pesos_ciudades1[['Pib Ponderado' , 'Ciudad', 'Mes']], on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Agregar puntos de llegadas internacionales\n",
    "entradas = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Entradas_de_extranjeros_a_Colombia_20241006.csv')\n",
    "entradas_2018= entradas[entradas['Año']==2022]\n",
    "entradas_2018 = entradas_2018[entradas_2018['Latitud - Longitud'] != 'No Aplica,No Aplica']\n",
    "entradas_2018 =traducir(entradas_2018 , 'Mes')\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "entradas_2018 =completar_meses(entradas_2018, 'Latitud - Longitud' , 'Mes' , 'Total' ,1 )\n",
    "entradas_2018 =meses_a_numeros(entradas_2018 , 'Mes' )\n",
    "\n",
    "entradas_geometry = convertir_ubicacion(entradas_2018 , 'Latitud - Longitud')\n",
    "Entradas = gpd.GeoDataFrame(entradas_geometry, geometry='geometry')\n",
    "\n",
    "if Entradas.crs is None:\n",
    "    Entradas = Entradas.set_crs(Departamentos.crs, allow_override=True)\n",
    "\n",
    "Entradas = gpd.sjoin_nearest(Entradas,  Departamentos, how='left', distance_col='distancia').drop(['index_right' , 'DPTO' , 'AREA' , 'PERIMETER' , 'HECTARES' ,'distancia'] , axis=1)\n",
    "Entradas_Departamentos = Entradas.groupby(['Mes', 'Departamento'])['Total'].sum().reset_index()\n",
    "final = pd.merge(fusion_left, Entradas_Departamentos, on=['Departamento', 'Mes'], how='left').rename(columns={'Total': 'Entradas Extranjeros Zona'})\n",
    "final['Entradas Extranjeros Zona'] = final['Entradas Extranjeros Zona'].fillna(0)\n",
    "\n",
    "#Distancias desde los puntos de llegadas internacionales ponderadas \n",
    "for i in ciudades['Ciudad']:\n",
    "    indice = ciudades[ciudades['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_unico = ciudades.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unico = ciudades_unico.iloc[:, [0, -1]]\n",
    "ciudades_unico= gpd.GeoDataFrame(ciudades_unico, geometry='geometry')\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if Migracion_Unico.crs is None:\n",
    "    Migracion_Unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de Migracion_Unico: {Migracion_Unico.crs}\")\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "Migracion_Unico = Migracion_Unico.to_crs(epsg=32618)\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "Migracion_Unico['key'] = 1\n",
    "\n",
    "Distancia_combinado = pd.merge(ciudades_unico, Migracion_Unico, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "Distancia_combinado['distancia_km'] = Distancia_combinado.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_combinado['distancia_ponderada'] = Distancia_combinado['distancia_km'] * Distancia_combinado['Total']\n",
    "Distancia_ponderado = Distancia_combinado.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_migrantes=('Total', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "Distancia_ponderado['distancia_ponderada_km'] = Distancia_ponderado['suma_ponderada'] / Distancia_ponderado['suma_migrantes']\n",
    "Distancia_ponderado_final = Distancia_ponderado[['Ciudad' , 'distancia_ponderada_km']]\n",
    "\n",
    "Distancia_ciudades = ciudades_unico.merge(Distancia_ponderado_final, on='Ciudad')\n",
    "final1 = pd.merge(final, Distancia_ciudades, on='Ciudad', how='left').drop(['geometry_y' , 'key'] , axis=1)\n",
    "\n",
    "# Score importancia puntos entrada\n",
    "Migracion_Unico = entradas_2018.groupby('Latitud - Longitud')['Total'].sum().reset_index().iloc[:-1, :]\n",
    "Migracion_Unico = convertir_ubicacion(Migracion_Unico , 'Latitud - Longitud')\n",
    "Migracion_Unico = gpd.GeoDataFrame(Migracion_Unico, geometry='geometry')\n",
    "columnas = ['geometry' , 'Departamento' ,'Total' ]\n",
    "Migracion_Unico_Dept = gpd.sjoin_nearest(Migracion_Unico, Departamentos, how='left', distance_col='distancia')[columnas]\n",
    "Total_Migracion = Migracion_Unico_Dept.groupby('Departamento').agg(\n",
    "    puntos=('Departamento', 'size'),  \n",
    "    total_personas=('Total', 'sum')  \n",
    ").reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "Total_Migracion[['puntos_norm', 'total_norm']] = scaler.fit_transform(Total_Migracion[['puntos', 'total_personas']])\n",
    "Total_Migracion['importancia accesos'] = 0.3 * Total_Migracion['puntos_norm'] + 0.7 * Total_Migracion['total_norm'] # Asumimos que es mas importante cuanta gente llega a que tantos puntos hay.\n",
    "final1 = pd.merge(final1, Total_Migracion, on='Departamento', how='left').drop(['puntos' , 'total_personas' , 'puntos_norm' , 'total_norm'] , axis=1)\n",
    "final1['importancia accesos'] = final1['importancia accesos'].fillna(0)\n",
    "\n",
    "\n",
    "#Numero establecimientos de turismo, camas y habitaciones para turistas.\n",
    "hoteles = pd.read_csv('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\Prestadores_de_servicios_Tur_sticos_20241009.csv')\n",
    "hoteles['MUNICIPIO'] = hoteles['MUNICIPIO'].str.replace('PUERTO INIRIDA', 'Inirida', regex=False)\n",
    "hoteles['MUNICIPIO'] = hoteles['MUNICIPIO'].str.replace('BUGA', 'guadalajaradebuga', regex=False)\n",
    "\n",
    "Establecimientos = hoteles.groupby(['MUNICIPIO' , 'MES']).agg({'CATEGORIA': 'count','NÚMERO DE HABIATACIONES': 'sum', 'NÚMERO DE CAMAS': 'sum'}).reset_index().rename(columns={'CATEGORIA': 'Establecimientos'})\n",
    "Establecimientos = arreglar_texto(Establecimientos, 'MUNICIPIO' , 'Municipios')\n",
    "\n",
    "Establecimientos=Establecimientos.rename(columns={'Municipios': 'Ciudad'})\n",
    "Establecimientos=Establecimientos.rename(columns={'MES': 'Mes'})\n",
    "\n",
    "for i in Establecimientos['Ciudad']:\n",
    "    indice = Establecimientos[Establecimientos['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        Establecimientos = Establecimientos.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ciudades_unicas = Establecimientos['Ciudad'].unique()\n",
    "meses_completos = pd.DataFrame({'Mes': range(1, 13)})\n",
    "Establecimientos_completo = pd.MultiIndex.from_product([ciudades_unicas, range(1, 13)], names=['Ciudad', 'Mes']).to_frame(index=False)\n",
    "Establecimientos_completo = pd.merge(Establecimientos_completo, Establecimientos , how='outer', on=['Ciudad', 'Mes'])\n",
    "Establecimientos_completo \n",
    "\n",
    "final2 = pd.merge(final1, Establecimientos_completo  , on=['Ciudad', 'Mes'], how='left')\n",
    "\n",
    "#Distancias al TOP de colombia \n",
    "df_TopColombia = pd.DataFrame.from_dict(Top_Colombia, orient='index', columns=['coordinates','Reviews', 'rating', 'eliminar'])\n",
    "df_TopColombia = df_TopColombia.reset_index().rename(columns={'index': 'lugar'}).drop('eliminar' , axis=1)\n",
    "df_TopColombia['geometry'] = df_TopColombia['coordinates'].apply(lambda x: Point(x[1], x[0]))\n",
    "df_TopColombia_gdp = gpd.GeoDataFrame(df_TopColombia, geometry='geometry').drop('coordinates' , axis=1)\n",
    "if ciudades_unico.crs is None:\n",
    "    ciudades_unico.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de ciudades_unico: {ciudades_unico.crs}\")\n",
    "\n",
    "if df_TopColombia_gdp.crs is None:\n",
    "    df_TopColombia_gdp.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    print(f\"CRS de df_TopColombia_gdp: {df_TopColombia_gdp.crs}\")\n",
    "\n",
    "\n",
    "ciudades_unico = ciudades_unico.to_crs(epsg=32618)\n",
    "df_TopColombia_gdp = df_TopColombia_gdp.to_crs(epsg=32618)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ciudades_unico['key'] = 1\n",
    "df_TopColombia_gdp['key'] = 1\n",
    "\n",
    "Distancia_Top = pd.merge(ciudades_unico, df_TopColombia_gdp, on='key', suffixes=('_ciudad', '_punto')).drop('key', axis=1)\n",
    "\n",
    "w_reviews = 0.6 # Vamos a asumir que las reviews tienen mas peso que la calificacion del lugar \n",
    "w_rating = 0.4\n",
    "\n",
    "Distancia_Top['distancia_km'] = Distancia_Top.apply(lambda x: x['geometry_punto'].distance(x['geometry_ciudad']) / 1000, axis=1) # Calcular la distancia \n",
    "\n",
    "Distancia_Top[['distancia_km','Reviews', 'rating']] = scaler.fit_transform(\n",
    "    Distancia_Top[['distancia_km','Reviews', 'rating']]\n",
    ") # Normalizamos las variables para calcular una distancia ponderada con las mismas escalas\n",
    "\n",
    "Distancia_Top['distancia_ponderada'] = (Distancia_Top['distancia_km']) + ( w_reviews* Distancia_Top['Reviews']) + ( w_rating* Distancia_Top['rating'])\n",
    "\n",
    "Distancia_Ponderado_Top = Distancia_Top.groupby('Ciudad').agg(\n",
    "    suma_ponderada=('distancia_ponderada', 'sum'),\n",
    "    suma_reviews=('Reviews', 'sum'),\n",
    "    suma_rating=('rating', 'sum')).reset_index()\n",
    "\n",
    "Distancia_Ponderado_Top['distancia_ponderada_TOP'] = Distancia_Ponderado_Top['suma_ponderada'] / (Distancia_Ponderado_Top['suma_reviews']+Distancia_Ponderado_Top['suma_rating'])\n",
    "Distancia_Ponderado_Top_final = Distancia_Ponderado_Top[['Ciudad' , 'distancia_ponderada_TOP']]\n",
    "\n",
    "Distancia_Top = ciudades_unico.merge(Distancia_Ponderado_Top_final, on='Ciudad')\n",
    "final3 = pd.merge(final2, Distancia_Top, on='Ciudad', how='left').drop(['geometry_x' , 'key'] , axis=1)\n",
    "\n",
    "# Pobreza con proxy\n",
    "ciudades_poblacion = ciudades[['Ciudad' , 'population']]\n",
    "for i in ciudades_poblacion['Ciudad']:\n",
    "    indice = ciudades_poblacion[ciudades_poblacion['Ciudad'] == i].index\n",
    "    if i not in grandes_ciudades:\n",
    "        ciudades_poblacion = ciudades_poblacion.drop(index=indice)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final4 = pd.merge(final3, ciudades_poblacion, on='Ciudad', how='left')\n",
    "final4['Proxy_Pobreza'] = final4['Pib Ponderado'] / final4['population']\n",
    "final4\n",
    "\n",
    "#Gasto promedio por dia de un turista\n",
    "gastos_diarios = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\Gasto Diario 2023.xlsx')\n",
    "gastos_diarios = arreglar_texto(gastos_diarios , 'Ciudad', 'Ciudad')\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_diarios = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='left')\n",
    "\n",
    "gastos_diarios_Nan = pd.merge(gastos_diarios, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_diarios_Nan = gpd.GeoDataFrame(pd.merge(gastos_diarios_Nan, ciudades_geometry, on='Ciudad', how='left').drop('geometry_x' , axis=1) , geometry='geometry')\n",
    "gastos_diarios_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_diarios_Nan=gastos_diarios_Nan.to_crs(epsg=32618)  \n",
    "variables = [i for i in gastos_diarios_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_diarios_Nan.dropna(subset=variables)\n",
    "gastos_con_Nan = gastos_diarios_Nan[gastos_diarios_Nan[variables].isnull().any(axis=1)]\n",
    "\n",
    "def kriging(df_con_info, variable, grid_size=100):\n",
    "    coords = np.array(list(zip(df_con_info.geometry.x, df_con_info.geometry.y)))\n",
    "    valores = df_con_info[variable].values\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = gastos_diarios_Nan.total_bounds\n",
    "    gridx = np.linspace(min_x, max_x, grid_size)\n",
    "    gridy = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    Krigg_O = OrdinaryKriging(\n",
    "        coords[:,0], coords[:,1], valores,\n",
    "        variogram_model='spherical',\n",
    "        verbose=False,\n",
    "        enable_plotting=False\n",
    "    )\n",
    "    \n",
    "    z1, ss1 = Krigg_O.execute('grid', gridx, gridy)\n",
    "    \n",
    "    return Krigg_O, gridx, gridy, z1\n",
    "\n",
    "def estimar(Krigg, puntos):\n",
    "    x = puntos.geometry.x.values\n",
    "    y = puntos.geometry.y.values\n",
    "    estimados, ss = Krigg.execute('points', x, y)\n",
    "    return estimados\n",
    "\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual['Mes'] = (gastos_krigg_mensual.index % 12) + 1\n",
    "final5 = pd.merge(final4, gastos_krigg_mensual, on=['Mes', 'Ciudad'], how='left').drop(['geometry_x','population'] , axis=1)\n",
    "\n",
    "# Gastos de todo el viaje \n",
    "gastos_viaje = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Bases 2023\\\\Gastos Viaje.xlsx')\n",
    "gastos_viaje = arreglar_texto(gastos_viaje , 'Ciudad', 'Ciudad')\n",
    "\n",
    "ciudades_geometry = Total_18_Geometry[['Ciudad' , 'geometry']].drop_duplicates()\n",
    "gastos_viaje = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='left')\n",
    "gastos_viaje_Nan = pd.merge(gastos_viaje, ciudades_geometry, on='Ciudad', how='outer').drop('geometry_y' , axis=1)\n",
    "gastos_viaje_Nan = gpd.GeoDataFrame(pd.merge(gastos_viaje_Nan, ciudades_geometry, on='Ciudad', how='left') , geometry='geometry')\n",
    "gastos_viaje_Nan = gastos_viaje_Nan.drop('geometry_x' , axis=1)\n",
    "\n",
    "gastos_viaje_Nan.set_crs(epsg=4326, inplace=True)\n",
    "gastos_viaje_Nan=gastos_viaje_Nan.to_crs(epsg=32618) \n",
    "variables = [i for i in gastos_viaje_Nan.columns][1:-1]\n",
    "gastos_sin_Nan = gastos_viaje_Nan.dropna()\n",
    "gastos_con_Nan = gastos_viaje_Nan[gastos_viaje_Nan[variables].isnull().any(axis=1)]\n",
    "for var in variables:\n",
    "    OK, gridx, gridy, z1 = kriging(gastos_sin_Nan, var)\n",
    "    \n",
    "    estimados = estimar(OK, gastos_con_Nan)\n",
    "    gastos_con_Nan[var] = estimados\n",
    "\n",
    "gastos_krigg = pd.concat([gastos_con_Nan, gastos_sin_Nan], ignore_index=True)\n",
    "gastos_krigg_mensual_viaje = gastos_krigg.loc[gastos_krigg.index.repeat(12)].reset_index(drop=True)\n",
    "gastos_krigg_mensual_viaje['Mes'] = (gastos_krigg_mensual_viaje.index % 12) + 1\n",
    "gastos_krigg_mensual_viaje\n",
    "Base_2023 = pd.merge(final5, gastos_krigg_mensual_viaje, on=['Mes', 'Ciudad'], how='left').drop('geometry_y' , axis=1)\n",
    "\n",
    "# Agregar inflacion\n",
    "inflacion = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Inflacion.xlsx')\n",
    "inflacion['Fecha'] = pd.to_datetime(inflacion['Fecha'])\n",
    "inflacion = inflacion[inflacion['Fecha'].dt.year == 2023].rename(columns={'Fecha':'Mes'})\n",
    "inflacion['Mes'] = inflacion['Mes'].dt.month\n",
    "Base_2023  = pd.merge(Base_2023  , inflacion, on='Mes', how='left')\n",
    "\n",
    "\n",
    "#Agregar Cantidad de vias \n",
    "vias = gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\RedVial.zip')\n",
    "vias['distancia'] = abs(vias['distanciaf'] - vias['distanciai'])\n",
    "vias_imp = vias[['distancia' , 'geometry']]\n",
    "ciudades_geom= gpd.read_file('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Ciudades Colombia Geometry.geojson')\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=4326)\n",
    "vias_imp = vias_imp.to_crs(epsg=4326)\n",
    "ciudades_geom = ciudades_geom.to_crs(epsg=32617)\n",
    "vias_imp = vias_imp.to_crs(epsg=32617)\n",
    "\n",
    "buffer_distancia = 10000 \n",
    "\n",
    "ciudades_geom['buffer'] = ciudades_geom.geometry.buffer(buffer_distancia)\n",
    "ciudades_buffer = gpd.GeoDataFrame(ciudades_geom, geometry='buffer', crs=ciudades_geom.crs).drop('geometry' , axis=1)\n",
    "\n",
    "join = gpd.sjoin(vias_imp, ciudades_buffer, how='inner', predicate='intersects')\n",
    "conteo_carreteras = join.groupby('Ciudades').size().reset_index(name='carreteras_cercanas')\n",
    "ciudades_geom = ciudades_geom.merge(conteo_carreteras, on='Ciudades', how='left')\n",
    "ciudades_geom['carreteras_cercanas'] = ciudades_geom['carreteras_cercanas'].fillna(0).astype(int)\n",
    "ciudades_geom =  arreglar_texto(ciudades_geom, 'Ciudades' , 'Ciudad')\n",
    "\n",
    "Base_2023 = pd.merge(Base_2023 , ciudades_geom[['Ciudad' , 'carreteras_cercanas']] , on='Ciudad' , how='left')\n",
    "\n",
    "# Agregar Eventos\n",
    "eventos = pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Eventos Turisticos\\\\Eventos 2023.xlsx').fillna(0)\n",
    "eventos = arreglar_texto(eventos ,'Departamento' , 'Departamento')\n",
    "eventos['Departamento'] = eventos['Departamento'].str.replace('sanandres', 'archipielagodesanandresprovidenciaysantacatalina', regex=False)\n",
    "Base_2023 = pd.merge(Base_2023 , eventos , on=['Departamento' ,'Mes'] , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see 2023 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Extranjeros no Residentes</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Otros Gastos  Diario</th>\n",
       "      <th>Gasto Promedio Viaje</th>\n",
       "      <th>Gasto Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>carreteras_cercanas</th>\n",
       "      <th>Eventos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>envigado</td>\n",
       "      <td>1</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>antioquia</td>\n",
       "      <td>21.314463</td>\n",
       "      <td>4692.04</td>\n",
       "      <td>1315.923830</td>\n",
       "      <td>...</td>\n",
       "      <td>41115.318939</td>\n",
       "      <td>469234.311565</td>\n",
       "      <td>85042.863721</td>\n",
       "      <td>76311.721879</td>\n",
       "      <td>146377.089587</td>\n",
       "      <td>165951.596867</td>\n",
       "      <td>POINT (437301.941 681665.313)</td>\n",
       "      <td>13.25198</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pereira</td>\n",
       "      <td>1</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>5</td>\n",
       "      <td>349</td>\n",
       "      <td>27</td>\n",
       "      <td>risaralda</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>4692.04</td>\n",
       "      <td>1495.867681</td>\n",
       "      <td>...</td>\n",
       "      <td>28310.677000</td>\n",
       "      <td>300839.919000</td>\n",
       "      <td>64017.664000</td>\n",
       "      <td>54227.832000</td>\n",
       "      <td>78897.842000</td>\n",
       "      <td>103696.581000</td>\n",
       "      <td>POINT (422977.411 532176.544)</td>\n",
       "      <td>13.25198</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malambo</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>atlantico</td>\n",
       "      <td>21.314463</td>\n",
       "      <td>4692.04</td>\n",
       "      <td>317.118690</td>\n",
       "      <td>...</td>\n",
       "      <td>36597.729686</td>\n",
       "      <td>474340.266423</td>\n",
       "      <td>92645.185569</td>\n",
       "      <td>94965.322047</td>\n",
       "      <td>144763.300117</td>\n",
       "      <td>187671.794038</td>\n",
       "      <td>POINT (527324.757 1199405.166)</td>\n",
       "      <td>13.25198</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bucaramanga</td>\n",
       "      <td>1</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>11</td>\n",
       "      <td>833</td>\n",
       "      <td>21</td>\n",
       "      <td>santander</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>4692.04</td>\n",
       "      <td>2893.910694</td>\n",
       "      <td>...</td>\n",
       "      <td>31245.180000</td>\n",
       "      <td>485356.241000</td>\n",
       "      <td>90652.926000</td>\n",
       "      <td>86058.169000</td>\n",
       "      <td>155661.876000</td>\n",
       "      <td>152983.271000</td>\n",
       "      <td>POINT (720882.544 788963.63)</td>\n",
       "      <td>13.25198</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>armenia</td>\n",
       "      <td>1</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>quindio</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>4692.04</td>\n",
       "      <td>687.543890</td>\n",
       "      <td>...</td>\n",
       "      <td>21342.029000</td>\n",
       "      <td>346819.887000</td>\n",
       "      <td>77283.026000</td>\n",
       "      <td>84550.779000</td>\n",
       "      <td>88250.654000</td>\n",
       "      <td>96735.428000</td>\n",
       "      <td>POINT (424566.064 500746.928)</td>\n",
       "      <td>13.25198</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>inirida</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>guainia</td>\n",
       "      <td>26.650000</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>28.530179</td>\n",
       "      <td>...</td>\n",
       "      <td>66570.629446</td>\n",
       "      <td>775630.771711</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>80971.122105</td>\n",
       "      <td>148406.448920</td>\n",
       "      <td>398169.400513</td>\n",
       "      <td>POINT (1287613.509 430529.596)</td>\n",
       "      <td>9.27605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>lajaguadeibirico</td>\n",
       "      <td>12</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>cesar</td>\n",
       "      <td>24.466558</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>417.451225</td>\n",
       "      <td>...</td>\n",
       "      <td>29560.223758</td>\n",
       "      <td>551409.688748</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>115538.308052</td>\n",
       "      <td>147201.698640</td>\n",
       "      <td>180503.209527</td>\n",
       "      <td>POINT (682924.172 1057948.201)</td>\n",
       "      <td>9.27605</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>quibdo</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>choco</td>\n",
       "      <td>23.795814</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>131.489163</td>\n",
       "      <td>...</td>\n",
       "      <td>37083.408000</td>\n",
       "      <td>576955.167000</td>\n",
       "      <td>32778.482000</td>\n",
       "      <td>98407.282000</td>\n",
       "      <td>165761.578000</td>\n",
       "      <td>280007.826000</td>\n",
       "      <td>POINT (316373.42 629443.463)</td>\n",
       "      <td>9.27605</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>mitu</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>vaupes</td>\n",
       "      <td>23.726524</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>16.948123</td>\n",
       "      <td>...</td>\n",
       "      <td>58859.141274</td>\n",
       "      <td>634676.114547</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>81662.941349</td>\n",
       "      <td>144525.028720</td>\n",
       "      <td>336723.130284</td>\n",
       "      <td>POINT (1037614.182 132922.769)</td>\n",
       "      <td>9.27605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>palermo</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>huila</td>\n",
       "      <td>23.697940</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>64.252151</td>\n",
       "      <td>...</td>\n",
       "      <td>60219.676715</td>\n",
       "      <td>593804.545733</td>\n",
       "      <td>93934.760071</td>\n",
       "      <td>109926.998780</td>\n",
       "      <td>136286.534220</td>\n",
       "      <td>229866.016217</td>\n",
       "      <td>POINT (451378.305 319631.823)</td>\n",
       "      <td>9.27605</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ciudad  Mes  Extranjeros no Residentes  Homicidios  Hurtos  \\\n",
       "0            envigado    1                     1180.0           0     119   \n",
       "1             pereira    1                     3032.0           5     349   \n",
       "2             malambo    1                       11.0           4      38   \n",
       "3         bucaramanga    1                     1966.0          11     833   \n",
       "4             armenia    1                     1262.0           7     194   \n",
       "..                ...  ...                        ...         ...     ...   \n",
       "967           inirida   12                        9.0           0       5   \n",
       "968  lajaguadeibirico   12                       49.0           1       7   \n",
       "969            quibdo   12                       28.0           5      72   \n",
       "970              mitu   12                        1.0           0       3   \n",
       "971           palermo   12                        2.0           0       8   \n",
       "\n",
       "     Delitos Sexuales Departamento  Temperatura    Dolar  Pib Ponderado  ...  \\\n",
       "0                   4    antioquia    21.314463  4692.04    1315.923830  ...   \n",
       "1                  27    risaralda    19.700000  4692.04    1495.867681  ...   \n",
       "2                   4    atlantico    21.314463  4692.04     317.118690  ...   \n",
       "3                  21    santander    21.700000  4692.04    2893.910694  ...   \n",
       "4                  12      quindio    19.800000  4692.04     687.543890  ...   \n",
       "..                ...          ...          ...      ...            ...  ...   \n",
       "967                 2      guainia    26.650000  3956.76      28.530179  ...   \n",
       "968                 0        cesar    24.466558  3956.76     417.451225  ...   \n",
       "969                 7        choco    23.795814  3956.76     131.489163  ...   \n",
       "970                 3       vaupes    23.726524  3956.76      16.948123  ...   \n",
       "971                 1        huila    23.697940  3956.76      64.252151  ...   \n",
       "\n",
       "     Otros Gastos  Diario  Gasto Promedio Viaje  Gasto Alojamiento Viaje  \\\n",
       "0            41115.318939         469234.311565             85042.863721   \n",
       "1            28310.677000         300839.919000             64017.664000   \n",
       "2            36597.729686         474340.266423             92645.185569   \n",
       "3            31245.180000         485356.241000             90652.926000   \n",
       "4            21342.029000         346819.887000             77283.026000   \n",
       "..                    ...                   ...                      ...   \n",
       "967          66570.629446         775630.771711             96724.213292   \n",
       "968          29560.223758         551409.688748             96724.213292   \n",
       "969          37083.408000         576955.167000             32778.482000   \n",
       "970          58859.141274         634676.114547             96724.213292   \n",
       "971          60219.676715         593804.545733             93934.760071   \n",
       "\n",
       "     Gasto Transporte Viaje  Gasto alimetos Viaje  Otros Gastos Viaje  \\\n",
       "0              76311.721879         146377.089587       165951.596867   \n",
       "1              54227.832000          78897.842000       103696.581000   \n",
       "2              94965.322047         144763.300117       187671.794038   \n",
       "3              86058.169000         155661.876000       152983.271000   \n",
       "4              84550.779000          88250.654000        96735.428000   \n",
       "..                      ...                   ...                 ...   \n",
       "967            80971.122105         148406.448920       398169.400513   \n",
       "968           115538.308052         147201.698640       180503.209527   \n",
       "969            98407.282000         165761.578000       280007.826000   \n",
       "970            81662.941349         144525.028720       336723.130284   \n",
       "971           109926.998780         136286.534220       229866.016217   \n",
       "\n",
       "                           geometry  Inflacion  carreteras_cercanas  Eventos  \n",
       "0     POINT (437301.941 681665.313)   13.25198                    6      3.0  \n",
       "1     POINT (422977.411 532176.544)   13.25198                   14      0.0  \n",
       "2    POINT (527324.757 1199405.166)   13.25198                    8      0.0  \n",
       "3      POINT (720882.544 788963.63)   13.25198                    9      3.0  \n",
       "4     POINT (424566.064 500746.928)   13.25198                   11      1.0  \n",
       "..                              ...        ...                  ...      ...  \n",
       "967  POINT (1287613.509 430529.596)    9.27605                    0      0.0  \n",
       "968  POINT (682924.172 1057948.201)    9.27605                    1      0.0  \n",
       "969    POINT (316373.42 629443.463)    9.27605                    2      0.0  \n",
       "970  POINT (1037614.182 132922.769)    9.27605                    0      0.0  \n",
       "971   POINT (451378.305 319631.823)    9.27605                    2      0.0  \n",
       "\n",
       "[972 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Establecimientos', 'NÚMERO DE HABIATACIONES', 'NÚMERO DE CAMAS']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_2023.columns[Base_2023 .isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all years by adding the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_2018_Final = Base_2018_Final.drop('geometry_x' , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columnas_Nombres=['Ciudad', 'Mes', 'Nmero Extranjeros', 'Homicidios', 'Hurtos',\n",
    "       'Delitos Sexuales', 'Departamento', 'Temperatura', 'Dolar',\n",
    "       'Pib Ponderado', 'Entradas Extranjeros Zona', 'Distancia a accseos','importancia accesos',\n",
    "       'Establecimientos de turismo', 'N Habitaciones', 'N Camas', 'Distancia al TOP',\n",
    "       'Proxy Pobreza', 'Gasto Promedio Diario', 'Gasto Alojamiento Diario',\n",
    "       'Gasto Transporte Diario', 'Gasto alimetos Diario',\n",
    "       'Otros Gastos Diario', 'Gasto Promedio Viaje',\n",
    "       'Gasto  Alojamiento Viaje', 'Gasto Transporte Viaje',\n",
    "       'Gasto alimetos Viaje', 'Otros Gastos Viaje' ,'geometry', 'Inflacion' , 'Nmero Vias' , 'Eventos']\n",
    "\n",
    "bases=[Base_2018_Final, Base_2019, Base_2021, Base_2022 , Base_2023]\n",
    "\n",
    "for i in bases:\n",
    "       i.columns=Columnas_Nombres\n",
    "       if any(i[col].tolist() == 'geometry' for col in i.columns):\n",
    "              i.drop(columns=['geometry'], inplace=True)\n",
    "       else:\n",
    "              pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We load the image data to include them in the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La funcion demoro 0.0026547908782958984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datos_imagenes=pd.read_excel('C:\\\\Users\\\\alejo\\\\OneDrive\\\\Escritorio\\\\Universidaad\\\\Colab Notebooks\\\\Ia en economia\\\\Proyecto\\\\Areas_Finales.xlsx')\n",
    "datos_imagenes= arreglar_texto(datos_imagenes , 'ciudad' , 'Ciudad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_imagenes(df , imagenes , c):\n",
    "    imagenes = imagenes[imagenes['año'] ==c]\n",
    "    df1 = pd.merge(df , imagenes, on='Ciudad' , how='left')\n",
    "    return df1\n",
    "\n",
    "Base_2018_img = agregar_imagenes(Base_2018_Final , datos_imagenes , 2018)\n",
    "Base_2019_img = agregar_imagenes(Base_2019 , datos_imagenes , 2019)\n",
    "Base_2021_img = agregar_imagenes(Base_2021 , datos_imagenes , 2021)\n",
    "Base_2022_img = agregar_imagenes(Base_2022 , datos_imagenes , 2022)\n",
    "Base_2023_img = agregar_imagenes(Base_2023 , datos_imagenes , 2023)\n",
    "\n",
    "Base_2018_img['Mes'] = Base_2018_img['Mes'].astype(str).str.cat(['-2018']*len(Base_2018_img), sep='')\n",
    "Base_2019_img['Mes'] = Base_2019_img['Mes'].astype(str).str.cat(['-2019']*len(Base_2019_img), sep='')\n",
    "Base_2021_img['Mes'] = Base_2021_img['Mes'].astype(str).str.cat(['-2021']*len(Base_2021_img), sep='')\n",
    "Base_2022_img['Mes'] = Base_2022_img['Mes'].astype(str).str.cat(['-2022']*len(Base_2022_img), sep='')\n",
    "Base_2023_img['Mes'] = Base_2023_img['Mes'].astype(str).str.cat(['-2023']*len(Base_2023_img), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Turismo_PD = pd.concat([Base_2018_img, Base_2019_img, Base_2021_img, Base_2022_img , Base_2023_img], ignore_index=True).drop(['año' ,'geometry'] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final database with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Nmero Extranjeros</th>\n",
       "      <th>Homicidios</th>\n",
       "      <th>Hurtos</th>\n",
       "      <th>Delitos Sexuales</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Dolar</th>\n",
       "      <th>Pib Ponderado</th>\n",
       "      <th>...</th>\n",
       "      <th>Gasto  Alojamiento Viaje</th>\n",
       "      <th>Gasto Transporte Viaje</th>\n",
       "      <th>Gasto alimetos Viaje</th>\n",
       "      <th>Otros Gastos Viaje</th>\n",
       "      <th>Inflacion</th>\n",
       "      <th>Nmero Vias</th>\n",
       "      <th>Eventos</th>\n",
       "      <th>Area Urbana</th>\n",
       "      <th>Area Rural</th>\n",
       "      <th>Area Agua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pitalito</td>\n",
       "      <td>1-2018</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>huila</td>\n",
       "      <td>18.055550</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>151.999238</td>\n",
       "      <td>...</td>\n",
       "      <td>51427.415415</td>\n",
       "      <td>83910.734197</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>129164.039202</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.793593</td>\n",
       "      <td>0.818258</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>riohacha</td>\n",
       "      <td>1-2018</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>laguajira</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>245.473018</td>\n",
       "      <td>...</td>\n",
       "      <td>44746.452735</td>\n",
       "      <td>105537.118267</td>\n",
       "      <td>85981.834594</td>\n",
       "      <td>169633.602119</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.565825</td>\n",
       "      <td>2.974838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rionegro</td>\n",
       "      <td>1-2018</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>antioquia</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>343.717029</td>\n",
       "      <td>...</td>\n",
       "      <td>51759.383143</td>\n",
       "      <td>56151.273165</td>\n",
       "      <td>86719.142328</td>\n",
       "      <td>88352.122091</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.596442</td>\n",
       "      <td>1.608628</td>\n",
       "      <td>0.046204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bogota</td>\n",
       "      <td>1-2018</td>\n",
       "      <td>99767.0</td>\n",
       "      <td>83</td>\n",
       "      <td>7149</td>\n",
       "      <td>426</td>\n",
       "      <td>bogotadc</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>23953.819812</td>\n",
       "      <td>...</td>\n",
       "      <td>95874.495457</td>\n",
       "      <td>75289.853012</td>\n",
       "      <td>116471.723062</td>\n",
       "      <td>170536.499037</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.975333</td>\n",
       "      <td>37.850345</td>\n",
       "      <td>0.808401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>piedecuesta</td>\n",
       "      <td>1-2018</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>santander</td>\n",
       "      <td>22.523648</td>\n",
       "      <td>2855.86</td>\n",
       "      <td>258.755835</td>\n",
       "      <td>...</td>\n",
       "      <td>59438.480482</td>\n",
       "      <td>63676.087723</td>\n",
       "      <td>86267.558458</td>\n",
       "      <td>96363.989201</td>\n",
       "      <td>3.679528</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.862518</td>\n",
       "      <td>0.983587</td>\n",
       "      <td>0.003875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>inirida</td>\n",
       "      <td>12-2023</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>guainia</td>\n",
       "      <td>26.650000</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>28.530179</td>\n",
       "      <td>...</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>80971.122105</td>\n",
       "      <td>148406.448920</td>\n",
       "      <td>398169.400513</td>\n",
       "      <td>9.276050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.846943</td>\n",
       "      <td>1.160703</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>lajaguadeibirico</td>\n",
       "      <td>12-2023</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>cesar</td>\n",
       "      <td>24.466558</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>417.451225</td>\n",
       "      <td>...</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>115538.308052</td>\n",
       "      <td>147201.698640</td>\n",
       "      <td>180503.209527</td>\n",
       "      <td>9.276050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169964</td>\n",
       "      <td>0.579078</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>quibdo</td>\n",
       "      <td>12-2023</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>choco</td>\n",
       "      <td>23.795814</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>131.489163</td>\n",
       "      <td>...</td>\n",
       "      <td>32778.482000</td>\n",
       "      <td>98407.282000</td>\n",
       "      <td>165761.578000</td>\n",
       "      <td>280007.826000</td>\n",
       "      <td>9.276050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.329747</td>\n",
       "      <td>1.570298</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>mitu</td>\n",
       "      <td>12-2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>vaupes</td>\n",
       "      <td>23.726524</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>16.948123</td>\n",
       "      <td>...</td>\n",
       "      <td>96724.213292</td>\n",
       "      <td>81662.941349</td>\n",
       "      <td>144525.028720</td>\n",
       "      <td>336723.130284</td>\n",
       "      <td>9.276050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990406</td>\n",
       "      <td>0.395778</td>\n",
       "      <td>1.431370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>palermo</td>\n",
       "      <td>12-2023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>huila</td>\n",
       "      <td>23.697940</td>\n",
       "      <td>3956.76</td>\n",
       "      <td>64.252151</td>\n",
       "      <td>...</td>\n",
       "      <td>93934.760071</td>\n",
       "      <td>109926.998780</td>\n",
       "      <td>136286.534220</td>\n",
       "      <td>229866.016217</td>\n",
       "      <td>9.276050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572339</td>\n",
       "      <td>0.188116</td>\n",
       "      <td>0.005539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ciudad      Mes  Nmero Extranjeros  Homicidios  Hurtos  \\\n",
       "0             pitalito   1-2018               33.0           2      61   \n",
       "1             riohacha   1-2018              108.0           4      49   \n",
       "2             rionegro   1-2018              271.0           2      51   \n",
       "3               bogota   1-2018            99767.0          83    7149   \n",
       "4          piedecuesta   1-2018               28.0           1      66   \n",
       "...                ...      ...                ...         ...     ...   \n",
       "4855           inirida  12-2023                9.0           0       5   \n",
       "4856  lajaguadeibirico  12-2023               49.0           1       7   \n",
       "4857            quibdo  12-2023               28.0           5      72   \n",
       "4858              mitu  12-2023                1.0           0       3   \n",
       "4859           palermo  12-2023                2.0           0       8   \n",
       "\n",
       "      Delitos Sexuales Departamento  Temperatura    Dolar  Pib Ponderado  ...  \\\n",
       "0                   15        huila    18.055550  2855.86     151.999238  ...   \n",
       "1                    8    laguajira    26.700000  2855.86     245.473018  ...   \n",
       "2                    7    antioquia    15.500000  2855.86     343.717029  ...   \n",
       "3                  426     bogotadc    12.600000  2855.86   23953.819812  ...   \n",
       "4                   13    santander    22.523648  2855.86     258.755835  ...   \n",
       "...                ...          ...          ...      ...            ...  ...   \n",
       "4855                 2      guainia    26.650000  3956.76      28.530179  ...   \n",
       "4856                 0        cesar    24.466558  3956.76     417.451225  ...   \n",
       "4857                 7        choco    23.795814  3956.76     131.489163  ...   \n",
       "4858                 3       vaupes    23.726524  3956.76      16.948123  ...   \n",
       "4859                 1        huila    23.697940  3956.76      64.252151  ...   \n",
       "\n",
       "      Gasto  Alojamiento Viaje  Gasto Transporte Viaje  Gasto alimetos Viaje  \\\n",
       "0                 51427.415415            83910.734197          86719.142328   \n",
       "1                 44746.452735           105537.118267          85981.834594   \n",
       "2                 51759.383143            56151.273165          86719.142328   \n",
       "3                 95874.495457            75289.853012         116471.723062   \n",
       "4                 59438.480482            63676.087723          86267.558458   \n",
       "...                        ...                     ...                   ...   \n",
       "4855              96724.213292            80971.122105         148406.448920   \n",
       "4856              96724.213292           115538.308052         147201.698640   \n",
       "4857              32778.482000            98407.282000         165761.578000   \n",
       "4858              96724.213292            81662.941349         144525.028720   \n",
       "4859              93934.760071           109926.998780         136286.534220   \n",
       "\n",
       "      Otros Gastos Viaje  Inflacion  Nmero Vias  Eventos  Area Urbana  \\\n",
       "0          129164.039202   3.679528           6      0.0     2.793593   \n",
       "1          169633.602119   3.679528           2      0.0     6.565825   \n",
       "2           88352.122091   3.679528          12      3.0     6.596442   \n",
       "3          170536.499037   3.679528          13      0.0   189.975333   \n",
       "4           96363.989201   3.679528           4      3.0     3.862518   \n",
       "...                  ...        ...         ...      ...          ...   \n",
       "4855       398169.400513   9.276050           0      0.0     3.846943   \n",
       "4856       180503.209527   9.276050           1      0.0     2.169964   \n",
       "4857       280007.826000   9.276050           2      0.0     7.329747   \n",
       "4858       336723.130284   9.276050           0      0.0     0.990406   \n",
       "4859       229866.016217   9.276050           2      0.0     0.572339   \n",
       "\n",
       "      Area Rural  Area Agua  \n",
       "0       0.818258   0.005400  \n",
       "1       2.974838   0.000000  \n",
       "2       1.608628   0.046204  \n",
       "3      37.850345   0.808401  \n",
       "4       0.983587   0.003875  \n",
       "...          ...        ...  \n",
       "4855    1.160703   0.001200  \n",
       "4856    0.579078   0.007900  \n",
       "4857    1.570298   0.017300  \n",
       "4858    0.395778   1.431370  \n",
       "4859    0.188116   0.005539  \n",
       "\n",
       "[4860 rows x 34 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Base_Turismo_PD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables for which we will make KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Establecimientos de turismo',\n",
       " 'N Habitaciones',\n",
       " 'N Camas',\n",
       " 'Area Urbana',\n",
       " 'Area Rural',\n",
       " 'Area Agua']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Base_Turismo_PD.columns[Base_Turismo_PD.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform KNN to complete missing data for variables ('Tourism Establishments', 'N Rooms', 'N Beds', and the image variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alejo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categoricas = ['Ciudad' , 'Departamento' , 'Mes']\n",
    "numericas = ['Nmero Extranjeros', 'Homicidios', 'Hurtos',\n",
    "       'Delitos Sexuales', 'Temperatura', 'Dolar',\n",
    "       'Pib Ponderado', 'Entradas Extranjeros Zona', 'Distancia a accseos','importancia accesos',\n",
    "       'Establecimientos de turismo', 'N Habitaciones', 'N Camas', 'Distancia al TOP',\n",
    "       'Proxy Pobreza', 'Gasto Promedio Diario', 'Gasto Alojamiento Diario',\n",
    "       'Gasto Transporte Diario', 'Gasto alimetos Diario',\n",
    "       'Otros Gastos Diario', 'Gasto Promedio Viaje',\n",
    "       'Gasto  Alojamiento Viaje', 'Gasto Transporte Viaje',\n",
    "       'Gasto alimetos Viaje', 'Otros Gastos Viaje' , 'Inflacion' , 'Nmero Vias','Eventos' , 'Area Urbana' , 'Area Rural' , 'Area Agua']\n",
    "\n",
    "# Separar las columnas a imputar\n",
    "imputar = ['Establecimientos de turismo', 'N Habitaciones', 'N Camas', 'Area Urbana' , 'Area Rural' , 'Area Agua']\n",
    "\n",
    "# Crear el preprocesador para manejar las columnas categóricas y numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse=False), categoricas),\n",
    "        ('num', StandardScaler(), numericas)], remainder='passthrough' )\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer(n_neighbors=5, weights='uniform'))])\n",
    "\n",
    "KNN1 = pipeline.fit_transform(Base_Turismo_PD)\n",
    "\n",
    "# Proceso para recuperar los datos sin escala\n",
    "encoder = preprocessor.named_transformers_['cat']\n",
    "columnas_encoded = encoder.get_feature_names_out(categoricas)\n",
    "finales = list(columnas_encoded) + numericas \n",
    "base_imputada = pd.DataFrame(KNN1, columns=finales)\n",
    "scaler = preprocessor.named_transformers_['num']\n",
    "mean = scaler.mean_\n",
    "scale = scaler.scale_\n",
    "\n",
    "for i, var in enumerate(numericas):    \n",
    "    base_imputada[var] = base_imputada[var] * scale[i] + mean[i]\n",
    "\n",
    "# Reemplazar las columnas imputadas en el DataFrame original\n",
    "Base_Turismo_PD1 = Base_Turismo_PD.copy()\n",
    "Base_Turismo_PD1[imputar] = base_imputada[imputar]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can verify that there is no longer missing data in the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos comprobar que ya no hay datos faltantes en el DF\n",
    "Base_Turismo_PD1.columns[Base_Turismo_PD1.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We finished the database for all years, now we are going to export it and use it for the model and the final descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Turismo_PD1.to_csv('Base Final1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pablo Reyes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
